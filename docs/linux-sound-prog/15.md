# 十五、使用 Gtk 和 FFmpeg 以叠加方式显示视频

这一章与声音无关。视频通常伴随着音频。Karaoke 经常在视频上覆盖歌词。构建一个包含视频和音频的应用会将您带入图形用户界面(GUI)的领域。这本身就是一个复杂的领域，值得(而且已经！)很多书，包括我自己多年前写的关于 X Window 系统和 Motif 的书。这一章是关于编程的视频方面，使用 FFmpeg，Gtk，Cairo 和 Pango。我假设您熟悉窗口小部件、事件、事件处理程序等概念，它们是当前所有 GUI 框架的基础。

Motif 很久以前就失去了作为 Linux/Unix 系统主要 GUI 的地位。现在有很多替代方案，包括 Gtk(Gimp 工具包)、tcl/Tk、Java Swing、KDE、XFCE 等等。每一种都有自己的追随者、使用领域、怪癖、特质等等。没有一个单一的 GUI 能满足所有人。

在这一章中，我处理 Gtk。原因有三。

*   它有一个 C 库。它也有一个 Python 库，这很好，我可能有一天会用到它。最重要的是，它不是基于 C++的。C++是我最不喜欢的语言之一。我曾经碰到过一句名言(source lost)“c++是一个逃脱的实验室实验”，我完全同意那个评价。
*   对 i18n(国际化)有很好的支持。我希望能够播放中文Karaoke 文件，所以这对我很重要。
*   它不是基于 Java 的。不要误解我，我真的很喜欢 Java，并且已经用它编程很多年了。MIDI API 相当不错，当然其他东西比如 i18n 也很棒。但是对于 MIDI 来说，它是一个 CPU 占用率很高的设备，不能在低功耗设备上使用，比如 Raspberry Pi，而且通常音频/视频 API 已经多年没有进步了。

然而，当我努力理解 Gtk 版本 2.0 与 3.0、Cairo、Pango、Glib 等等的区别时，我认为修复 Java MIDI 引擎可能更容易！这不是一次愉快的经历，续集将会展示这一点。

## FFmpeg

要播放 MPEG 文件、OGV 文件或类似文件，您需要一个解码器。主要竞争者似乎是 GStreamer 和 FFmpeg。没有特别的原因，我选择了 FFmpeg。

下面的程序读取视频文件并将前五帧存储到磁盘。直接摘自斯蒂芬·德朗格的《一个 FFmpeg 和 SDL 教程》( [`http://dranger.com/ffmpeg/`](http://dranger.com/ffmpeg/) )。程序是`play_video.c`，如下图:

```sh
// tutorial01.c
// Code based on a tutorial by Martin Bohme (boehme@inb.uni-luebeckREMOVETHIS.de)
// Tested on Gentoo, CVS version 5/01/07 compiled with GCC 4.1.1
// With updates from https://github.com/chelyaev/ffmpeg-tutorial
// Updates tested on:
// LAVC 54.59.100, LAVF 54.29.104, LSWS 2.1.101
// on GCC 4.7.2 in Debian February 2015

#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>

/* Requires
   libavcodec-dev
   libavformat-dev
   libswscale
*/

void SaveFrame(AVFrame *pFrame, int width, int height, int iFrame) {
    FILE *pFile;
    char szFilename[32];
    int  y;

    // Open file
    sprintf(szFilename, "frame%d.ppm", iFrame);
    pFile=fopen(szFilename, "wb");
    if(pFile==NULL)
        return;

    // Write header
    fprintf(pFile, "P6\n%d %d\n255\n", width, height);

    // Write pixel data
    for(y=0; y<height; y++)
        fwrite(pFrame->data[0]+y*pFrame->linesize[0], 1, width*3, pFile);

    // Close file
    fclose(pFile);
}

main(int argc, cha
r **argv) {
    AVFormatContext *pFormatCtx = NULL;
    int i, videoStream;
    AVCodecContext *pCodecCtx = NULL;
    AVCodec *pCodec = NULL;
    AVFrame *pFrame = NULL;
    AVFrame *pFrameRGB = NULL;
    AVPacket packet;
    int frameFinished;
    int numBytes;
    uint8_t *buffer = NULL;

    AVDictionary *optionsDict = NULL;
    struct SwsContext *sws_ctx = NULL;

    if(argc < 2) {
        printf("Please provide a movie file\n");
        return -1;
    }
    // Register all formats and codecs
    av_register_all();

    // Open video file
    if(avformat_open_input(&pFormatCtx, argv[1], NULL, NULL)!=0)
        return -1; // Couldn't open file

    // Retrieve stream information
    if(avformat_find_stream_info(pFormatCtx, NULL)<0)
        return -1; // Couldn't find stream information

    // Dump information about file onto standard error
    av_dump_format(pFormatCtx, 0, argv[1], 0);

    // Find the first video stream
    videoStream=-1;
    for(i=0; i<pFormatCtx->nb_streams; i++)
        if(pFormatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO) {
            videoStream=i;
            break;
        }
    if(videoStream==-1)
        return -1; // Didn't find a video stream

    // Get a pointer to the code
c context for the video stream
    pCodecCtx=pFormatCtx->streams[videoStream]->codec;

    // Find the decoder for the video stream
    pCodec=avcodec_find_decoder(pCodecCtx->codec_id);
    if(pCodec==NULL) {
        fprintf(stderr, "Unsupported codec!\n");
        return -1; // Codec not found
    }
    // Open codec
    if(avcodec_open2(pCodecCtx, pCodec, &optionsDict)<0)
        return -1; // Could not open codec

    // Allocate video frame
    pFrame=avcodec_alloc_frame();

    // Allocate an AVFrame structure
    pFrameRGB=avcodec_alloc_frame();
    if(pFrameRGB==NULL)
        return -1;

    // Determine required buffer size and allocate buffer
    numBytes=avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width,
                                pCodecCtx->height);
    buffer=(uint8_t *)av_malloc(numBytes*sizeof(uint8_t));

    sws_ctx =
        sws_getContext
        (
         pCodecCtx->width,
         pCodecCtx->height,
         pCodecCtx->pix_fmt,
         pCodecCtx->width,
         pCodecCtx->height,
         PIX_FMT_RGB24,
         SWS_BILINEAR,
         NULL,
         NULL,
         NULL
         );

    // Assign appropriat
e parts of buffer to image planes in pFrameRGB
    // Note that pFrameRGB is an AVFrame, but AVFrame is a superset
    // of AVPicture
    avpicture_fill((AVPicture *)pFrameRGB, buffer, PIX_FMT_RGB24,
                   pCodecCtx->width, pCodecCtx->height);

    // Read frames and save first five frames to disk
    i=0;
    while(av_read_frame(pFormatCtx, &packet)>=0) {
        // Is this a packet from the video stream?
        if(packet.stream_index==videoStream) {
            // Decode video frame
            avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished,
                                  &packet);

            // Did we get a video frame?
            if(frameFinished) {
                // Convert the image from its native format to RGB
                sws_scale
                    (
                     sws_ctx,
                     (uint8_t const * const *)pFrame->data,
                     pFrame->linesize,
                     0,
                     pCodecCtx->height,
                     pFrameRGB->data,
                     pFrameRGB->linesize
                     );

                printf("Read frame\n");
                // Save the frame to disk
                if(++i<=5)
                    SaveFrame(pFrameRGB, pCodecCtx->width, pCodecCtx->height,
                              i);
                else
                    break;
            }
        }

        // Free the packet that was allocated by av_read_frame
        av_free_packet(&packet);
    }

    // Free the RGB image
    av_free(buffer);
    av_free(pFrameRGB);

    // Free the YUV frame
    av_free(pFrame);

    // Close the codec
    avcodec_close(pCodecCtx);

    // Close the video file
    avformat_close_input(&pFormatCtx);

    return 0;

}

```

## 基本 Gtk

Gtk 是一个相当标准的 GUI 工具包。简单的程序在《GTK+》([`http://zetcode.com/tutorials/gtktutorial/firstprograms/`](http://zetcode.com/tutorials/gtktutorial/firstprograms/))等很多教程中都有描述。有关 Gtk 编程的基础知识，请参考此类教程。

我在没有解释的情况下包括了下面的例子；它使用了三个子部件、两个按钮和一个标签。标签将保存一个整数。按钮将增加或减少这个数字。

```sh
        #include <gtk/gtk.h>

        gint count = 0;
        char buf[5];

        void increase(GtkWidget *widget, gpointer label)
        {
            count++;

            sprintf(buf, "%d", count);
            gtk_label_set_text(GTK_LABEL(label), buf);
        }

        void decrease(GtkWidget *widget, gpointer label)
        {
            count--;

            sprintf(buf, "%d", count);
            gtk_label_set_text(GTK_LABEL(label), buf);
        }

        int main(int argc, char** argv) {

            GtkWidget *label;
            GtkWidget *window;
            GtkWidget *frame;
            GtkWidget *plus;
            GtkWidget *minus;

            gtk_init(&argc, &argv);

            window = gtk_window_new(GTK_WINDOW_TOPLEVEL);
            gtk_window_set_position(GTK_WINDOW(window), GTK_WIN_POS_CENTER);
            gtk_window_set_default_size(GTK_WINDOW(window), 250, 180);
            gtk_window_set_title(GTK_WINDOW(window), "+-");

            frame = gtk_fixed_new();
            gtk_container_add(GTK_CONTAINER(window), frame);

            plus = gtk_button_new_with_label("+");
            gtk_widget_set_size_request(plus, 80, 35);
            gtk_fixed_put(GTK_FIXED(frame), plus, 50, 20);

            minus = gtk_button_new_with_label("-");
            gtk_widget_set_size_request(minus, 80, 35);
            gtk_fixed_put(GTK_FIXED(frame), minus, 50, 80);

            label = gtk_label_new("0");
            gtk_fixed_put(GTK_FIXED(frame), label, 190, 58);

            gtk_widget_show_all(window);

            g_signal_connect(window, "destroy",
            G_CALLBACK (gtk_main_quit), NULL);

            g_signal_connect(plus, "clicked",
            G_CALLBACK(increase), label);

            g_signal_connect(minus, "clicked",
            G_CALLBACK(decrease), label);

            gtk_main();

            return 0;
        }

```

Gtk 和其他 GUI 工具包一样，有大量的小部件。这些都列在 GTK+ 3 参考手册中( [`https://developer.gnome.org/gtk3/3.0/`](https://developer.gnome.org/gtk3/3.0/) )。这包括小部件 GtkImage ( [`https://developer.gnome.org/gtk3/3.0/GtkImage.html`](https://developer.gnome.org/gtk3/3.0/GtkImage.html) )。顾名思义，它可以从某个地方获取一组像素，并将它们构建成可以显示的图像。

以下示例显示了从文件加载的图像:

```sh
#include <gtk/gtk.h>

int main( int argc, char *argv[])
{
    GtkWidget *window, *image;

    gtk_init(&argc, &argv);

    window = gtk_window_new(GTK_WINDOW_TOPLEVEL);

    image = gtk_image_new_from_file("jan-small.png");
    gtk_container_add(GTK_CONTAINER(window), image);

    g_signal_connect(G_OBJECT(window), "destroy", G_CALLBACK(gtk_main_quit), NULL);
    gtk_widget_show(image);
    gtk_widget_show(window);
    gtk_main();

    return 0;
}

```

## Gtk 的版本

Gtk 目前(截至 2016 年 11 月)有主要版本 2 和 3。宏`GTK_MAJOR_VERSION`可用于检测版本 2 或 3。然而，Gtk 还依赖于许多其他的库，并且很难确定应该查看哪些文档页面。以下是主要库及其主要 API 页面的列表:

Gtk 3 ( [`https://developer.gnome.org/gtk3/3.0/`](https://developer.gnome.org/gtk3/3.0/)

*   Gdk 3 ( [`https://developer.gnome.org/gdk3/stable/`](https://developer.gnome.org/gdk3/stable/)
*   开罗 1 ( [`http://cairographics.org/manual/`](http://cairographics.org/manual/) )
*   庞 1 ( [`https://developer.gnome.org/pango/stable/`](https://developer.gnome.org/pango/stable/)
*   gdk pixbuf 2()
*   油嘴滑舌 2 ( [`https://developer.gnome.org/glib/`](https://developer.gnome.org/glib/) )
*   Freetype 2 ( [`www.freetype.org/freetype2/docs/reference/ft2-toc.html`](http://www.freetype.org/freetype2/docs/reference/ft2-toc.html)

Gtk 2

*   Gdk 2 ( [`https://developer.gnome.org/gdk2/2.24/`](https://developer.gnome.org/gdk2/2.24/)
*   开罗 1 ( [`http://cairographics.org/manual/`](http://cairographics.org/manual/) )
*   庞 1 ( [`https://developer.gnome.org/pango/stable/`](https://developer.gnome.org/pango/stable/)
*   油嘴滑舌 2 ( [`https://developer.gnome.org/glib/`](https://developer.gnome.org/glib/) )
*   Freetype 2 ( [`www.freetype.org/freetype2/docs/reference/ft2-toc.html`](http://www.freetype.org/freetype2/docs/reference/ft2-toc.html)

## 使用 Gtk 显示视频

比如你想把 FFmpeg 产生的图像作为`AVFrame` s，显示在一个`GtkImage`里。你不希望使用从文件中读取的代码，因为以每秒 30 帧的速度读写文件是荒谬的。相反，您希望将一些内存中的帧表示加载到`GtkImage`中。

这里是您遇到第一个障碍的地方:在 Gtk 2.0 和 Gtk 3.0 之间，合适的内存表示发生了不兼容的变化。我只打算用 X Window 系统的语言来说，因为我不了解其他底层系统，比如微软的 Windows。

参见“从 GTK+ 2.x 迁移到 GTK+3”([`https://developer.gnome.org/gtk3/3.5/gtk-migrating-2-to-3.html`](https://developer.gnome.org/gtk3/3.5/gtk-migrating-2-to-3.html))了解这些版本之间的一些变化。

### 像素地图

X Window 系统架构模型是一个客户机-服务器模型，它让客户机(应用)与服务器(带有图形显示和输入设备的设备)进行对话。在最低层(Xlib)，客户端将向服务器发送基本请求，如“从这里到那里画一条线”。服务器将使用服务器端的信息绘制线条，例如当前线条的粗细、颜色等。

如果你想用一个像素数组来表示一个图像，那么这个数组通常保存在 X Window 服务器的一个 pixmap 中。应用可以通过从客户机向服务器发送消息来创建和修改位图。即使是简单的修改，如更改单个像素的值，也需要网络往返，如果经常进行，这显然会变得非常昂贵。

### Pixbufs

Pixbufs 是客户端的 pixmaps 的等价物。客户端可以操纵它们，而无需往返于 X Window 服务器。这减少了操作它们的时间和网络开销。然而，这意味着原本保存在服务器上的信息现在必须在客户端应用端构建和维护。

### x、韦兰和和平号

X Window 系统已经有将近 30 年的历史了。在此期间，它已经发展到满足硬件和软件需求的变化，同时仍然保持向后兼容性。

在这 30 年中，硬件发生了重大变化:多核系统现在很普遍，GPU 带来了视频处理的变化。通常，内存量(缓存和 RAM)意味着内存不再是一个问题。

与此同时，软件方面也发生了变化。现在普遍使用 Compiz 这样的“合成窗口管理器”,这样你就可以制作出像摇晃的窗口这样的效果。这对于 X 窗口模型来说并不好:来自应用的请求发送到 X 服务器，但是请求的图像必须传递到合成窗口管理器，它将执行它的效果，然后将图像发送回 X 服务器。这是网络流量的巨大增长，X 服务器现在只是扮演显示者的角色，而不是合成器。

应用库现在已经得到了发展，以前由 X 服务器完成的许多工作现在可以由 Cairo、Pixman、Freetype、Fontconfig 和 Pango 等库在应用端完成。

所有这些变化导致了对新的后端服务器的建议，它们在这个不断发展的世界中协同工作。这是由 Wayland ( [`http://wayland.freedesktop.org/`](http://wayland.freedesktop.org/) )的开发引发的，但被 Ubuntu 分叉这个来开发 Mir ( [`https://wiki.ubuntu.com/Mir/`](https://wiki.ubuntu.com/Mir/) )有点搞砸了。不要相信这些争论。谷歌一下米尔和韦兰就知道了。

从简单的意义上来说，这意味着在未来，当 pixbufs 出现时，pixmaps 将会退出。

### Gtk 3.0

随着 Gtk 3.0 的出现，像素贴图不再存在。数据结构`GdkPixbuf`中只有 pixbufs。要显示 FFmpeg 解码的视频，您需要在图像被转码为`picture_RGB`后，将其转换为`GdkPixbuf`，并创建`GtkImage`。

```sh
        pixbuf = gdk_pixbuf_new_from_data(picture_RGB->data[0], GDK_COLORSPACE_RGB,
                                          0, 8, width, height,
                                          picture_RGB->linesize[0],
                                          pixmap_destroy_notify,
                                          NULL);
        gtk_image_set_from_pixbuf((GtkImage*) image, pixbuf);

```

### Gtk 2.0

Gtk 2.0 在结构`GdkPixmap`中仍然有 pixmaps。理论上，应该可以使用函数`GdkPixmap *gdk_pixmap_create_from_data(GdkDrawable *drawable, const gchar *data, gint width, gint height, gint depth, const GdkColor *fg, const GdkColor *bg)`编写类似于 Gtk 3.0 代码的代码，该函数在《GDK 2 参考手册》的“位图和像素图”( [`https://developer.gnome.org/gdk/unstable/gdk-Bitmaps-and-Pixmaps.html#gdk-pixmap-create-from-data`](https://developer.gnome.org/gdk/unstable/gdk-Bitmaps-and-Pixmaps.html#gdk-pixmap-create-from-data) )，然后调用`void gtk_image_set_from_pixmap(GtkImage *image, GdkPixmap *pixmap, GdkBitmap *mask)`，该函数在 GtkImage ( [`www.gtk.org/api/2.6/gtk/GtkImage.html#gtk-image-set-from-pixmap`](http://www.gtk.org/api/2.6/gtk/GtkImage.html#gtk-image-set-from-pixmap) )的 Gtk 2.6 参考手册中有记载。

唯一的问题是我无法让函数`gdk_pixmap_create_from_data`工作。无论我为 drawable 尝试什么参数，调用总是在类型或值上出错。例如，记录的值是`NULL`，但这总是会导致断言错误(“不应为空”)。

那么，什么有效呢？嗯，我能找到的只是 pixmap 和 pixbuf 的一点混乱:创建一个充满视频数据的 pixbuf，创建一个 pixmap，将 pix buf 数据写入 pixmap，然后用 pix map 数据填充图像。

```sh
        pixbuf = gdk_pixbuf_new_from_data(picture_RGB->data[0], GDK_COLORSPACE_RGB,
                                          0, 8, width, height,
                                          picture_RGB->linesize[0],
                                          pixmap_destroy_notify,
                                          NULL);
        pixmap = gdk_pixmap_new(window->window, width, height, -1);
        gdk_draw_pixbuf((GdkDrawable *) pixmap, NULL,
                        pixbuf,
                        0, 0, 0, 0, wifth, height,
                        GDK_RGB_DITHER_NORMAL, 0, 0);

        gtk_image_set_from_pixmap((GtkImage*) image, pixmap, NULL);

```

### 螺纹和 Gtk

视频将需要在自己的线程中播放。Gtk 将在其线程中建立一个 GUI 处理循环。既然这是 Linux，你就用 Posix `pthreads`。视频线程需要通过以下方式明确启动:

```sh
        pthread_t tid;
        pthread_create(&tid, NULL, play_background, NULL);

```

这里函数`play_background`调用 FFmpeg 代码来解码视频文件。请注意，在应用实现之前，不应该启动线程，否则它会试图在不存在的窗口中绘图。

Gtk 线程将通过调用以下内容来启动:

```sh
        gtk_main();

```

这很简单。但是现在您必须处理调用 GUI 线程的视频线程，以便绘制图像。我在这方面找到的最好的文档是“GTK+线程安全吗？我如何编写多线程 GTK+应用？”( [`https://developer.gnome.org/gtk-faq/stable/x481.html`](https://developer.gnome.org/gtk-faq/stable/x481.html) )。基本上，它声明影响 Gtk 线程的代码应该用一个`gdk_threads_enter() … gdk_threads_leave()`对括起来。

对于 Gtk 2.0 来说还可以。Gtk 3.0 呢？呜！这些调用现在已被否决。那么，你该怎么办？到目前为止(截至 2013 年 7 月)，所有似乎存在的都是开发者对话，例如在 [`https://mail.gnome.org/archives/gtk-devel-list/2012-August/msg00020.html`](https://mail.gnome.org/archives/gtk-devel-list/2012-August/msg00020.html) ，其中写道:

> "We never seem to explain when gdk_threads_enter/leave is needed. Therefore, during the checkout process of my jhbuild, many key parts I saw were unnecessary. If your application does not call gdk_threads_init or gdk_threads_set_lock_functions, there is no need to use enter/leave. Of course, the library is another matter. "

实际的解决方法是不同的方向，解决方法如 [`https://developer.gnome.org/gdk3/stable/gdk3-Threads.html`](https://developer.gnome.org/gdk3/stable/gdk3-Threads.html) 所示:Gtk 不是线程安全的。Gtk 线程内的调用是安全的，但是大多数来自不同线程的 Gtk 调用并不安全。如果您需要从另一个线程调用 Gtk，那么调用`gdk_threads_add_idle()`来调用将在 Gtk 线程中运行的函数。与该延迟呼叫相关的数据可能会作为另一个参数传递给`gdk_threads_add_idle()`。

在本章的剩余部分，你将只考虑 Gtk 3 而不考虑 Gtk 2。

### 《守则》

最后，是时候看看在与 Gtk 3.0 兼容的 Gtk 应用中播放视频的代码了。我会把它打碎。

播放视频的函数作为后台线程运行。它使用 Gtk 3 读取帧并创建一个 pixbuf。内容如下:

```sh
  static gboolean draw_image(gpointer user_data) {
      GdkPixbuf *pixbuf = (GdkPixbuf *) user_data;

      gtk_image_set_from_pixbuf((GtkImage *) image, pixbuf);
      gtk_widget_queue_draw(image);
      g_object_unref(pixbuf);

      return G_SOURCE_REMOVE;
  }
   static gpointer play_background(gpointer args) {

    int i;
    AVPacket packet;
    int frameFinished;
    AVFrame *pFrame = NULL;

    /* initialize packet, set data to NULL, let the demuxer fill it */
    /* http://ffmpeg.org/doxygen/trunk/doc_2examples_2demuxing_8c-example.html#a80 */
    av_init_packet(&packet);
    packet.data = NULL;
    packet.size = 0;

    int bytesDecoded;
    GdkPixbuf *pixbuf;
    AVFrame *picture_RGB;
    char *buffer;

    pFrame=avcodec_alloc_frame();

    i=0;
    picture_RGB = avcodec_alloc_frame();
    buffer = malloc (avpicture_get_size(PIX_FMT_RGB24, WIDTH, HEIGHT));
    avpicture_fill((AVPicture *)picture_RGB, buffer, PIX_FMT_RGB24, WIDTH, HEIGHT);

    while(av_read_frame(pFormatCtx, &packet)>=0) {
        if(packet.stream_index==videoStream) {
            usleep(33670);  // 29.7 frames per second
            // Decode video frame
            avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished,
                                  &packet);

            int width = pCodecCtx->width;
            int height = pCodecCtx->height;

            sws_ctx = sws_getContext(width, height, pCodecCtx->pix_fmt, width, height,
                                     PIX_FMT_RGB24, SWS_BICUBIC, NULL, NULL, NULL);

            if (frameFinished) {

                sws_scale(sws_ctx,  (uint8_t const * const *) pFrame->data, pFrame->linesize, 0, height,
                                picture_RGB->data, picture_RGB->linesize);

                printf("old width %d new width %d\n",  pCodecCtx->width, picture_RGB->width);
                pixbuf = gdk_pixbuf_new_from_data(picture_RGB->data[0], GDK_COLORSPACE_RGB,
                                                  0, 8, width, height,
                                                  picture_RGB->linesize[0], pixmap_destroy_notify,
                                                  NULL);
                gdk_threads_add_idle(draw_image, pixbuf);

                gtk_image_set_from_pixbuf((GtkImage*) image, pixbuf);

            }
            sws_freeContext(sws_ctx);
        }
        av_free_packet(&packet);
        g_thread_yield();
    }

    printf("Video over!\n");
    exit(0);
}

```

这个函数被设置为在它自己的线程中运行，并且有一个窗口供它绘制。

```sh
/* Called when the windows

are realized
 */
static void realize_cb (GtkWidget *widget, gpointer data) {
    /* start the video playing in its own thread */
    GThread *tid;
    tid = g_thread_new("video",
                       play_background,
                       NULL);
}

```

main 函数负责初始化 FFmpeg 环境以读取视频，然后设置 Gtk 窗口以供其绘制。内容如下:

```sh
int main(int argc, char** argv)
{

    int i;

    /* FFMpeg stuff */

    AVFrame *pFrame = NULL;
    AVPacket packet;

    AVDictionary *optionsDict = NULL;

    av_register_all();

    if(avformat_open_input(&pFormatCtx, "/home/httpd/html/ComputersComputing/simpson.mpg", NULL, NULL)!=0)
        return -1; // Couldn't open file

    // Retrieve stream information
    if(avformat_find_stream_info(pFormatCtx, NULL)<0)
        return -1; // Couldn't find stream information

    // Dump information about file onto standard error
    av_dump_format(pFormatCtx, 0, argv[1], 0);

    // Find the first video stream
    videoStream=-1;
    for(i=0; i<pFormatCtx->nb_streams; i++)
        if(pFormatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO) {
            videoStream=i;
            break;
        }
    if(videoStream==-1)
        return -1; // Didn't find a video stream

    for(i=0; i<pFormatCtx->nb_streams; i++)
        if(pFormatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_AUDIO) {
            printf("Found an audio stream too\n");
            break;
        }

    // Get a pointer to the codec context for the video stream
    pCodecCtx=pFormatCtx->streams[videoStream]->codec;

    // Find the decoder for the video stream
    pCodec=avcodec_find_decoder(pCodecCtx->codec_id);
    if(pCodec==NULL) {
        fprintf(stderr, "Unsupported codec!\n");
        return -1; // Codec not found
    }

    // Open codec
    if(avcodec_open2(pCodecCtx, pCodec, &optionsDict)<0)
        return -1; // Could not open codec

    width =  pCodecCtx->width;
    height =  pCodecCtx->height;

    sws_ctx =
        sws_getContext
        (
         pCodecCtx->width,
         pCodecCtx->height,
         pCodecCtx->pix_fmt,
         pCodecCtx->width,
         pCodecCtx->height,
         PIX_FMT_YUV420P,
         SWS_BILINEAR,
         NULL,
         NULL,
         NULL
         );

    /* GTK stuff now */

    gtk_init (&argc, &argv);

    window = gtk_window_new (GTK_WINDOW_TOPLEVEL);

    /* When the window is given the "delete-event" signal (this is given
     * by the window manager, usually by the "close" option, or on the
     * titlebar), we ask it to call the delete_event () function
     * as defined above. The data passed to the callback
     * function is NULL and is ignored in the callback function. */
    g_signal_connect (window, "delete-event",
                      G_CALLBACK (delete_event), NULL);

    /* Here we connect the "destroy" event to a signal handler.
     * This event occurs when we call gtk_widget_destroy() on the window,
     * or if we return FALSE in the "delete-event" callback. */
    g_signal_connect (window, "destroy",
                      G_CALLBACK (destroy), NULL);

    g_signal_connect (window, "realize", G_CALLBACK (realize_cb), NULL);

    /* Sets the border width of the window. */
    gtk_container_set_border_width (GTK_CONTAINER (window), 10);

    image = gtk_image_new();
    gtk_widget_show (image);

    /* This packs the button into the window (a gtk container). */
    gtk_container_add (GTK_CONTAINER (window), image);

    /* and the window */
    gtk_widget_show (window);

    /* All GTK applications
must have a gtk_main(). Control ends here
     * and waits for an event to occur (like a key press or
     * mouse event). */
    gtk_main ();

    return 0;
}

```

## 在图像上覆盖图像

在电视电影中，通常会看到一个固定的图像叠加在视频之上。字幕可以是动态图像的一个例子，但也可以是文本覆盖。本节只考虑一个图像在另一个图像之上。

在 Gtk 2.0 中，这非常简单:将一个 pixbuf 绘制到一个 pixmap 中，然后将叠加的 pixbuf 绘制到同一个 pixmap 中。

```sh
pixmap = gdk_pixmap_new(window->window, 720, 480, -1);

gdk_draw_pixbuf((GdkDrawable *) pixmap, NULL,
                pixbuf,
                0, 0, 0, 0, 720, 480,
                GDK_RGB_DITHER_NORMAL, 0, 0);

// overlay another pixbuf
gdk_draw_pixbuf((GdkDrawable *) pixmap, NULL,
                overlay_pixbuf,
                0, 0, 0, 0, overlay_width, overlay_height,
                GDK_RGB_DITHER_NORMAL, 0, 0);

gtk_image_set_from_pixmap((GtkImage*) image, pixmap, NULL);

gtk_widget_queue_draw(image);

```

Gtk 3.0 看起来并不那么简单，因为像素地图已经消失了。许多页面建议使用 Cairo 曲面，后面的章节将会介绍这一点。但是“GdkPixbuf 结构”( [`https://developer.gnome.org/gdk-pixbuf/unstable/gdk-pixbuf-The-GdkPixbuf-Structure.html`](https://developer.gnome.org/gdk-pixbuf/unstable/gdk-pixbuf-The-GdkPixbuf-Structure.html) )建议，只要把数据类型对齐，就可以把第二个图像的像素写入第一个图像的 Pixbuf 数据中。名为“Gdk-pix buf”([`http://openbooks.sourceforge.net/books/wga/graphics-gdk-pixbuf.html`](http://openbooks.sourceforge.net/books/wga/graphics-gdk-pixbuf.html))的页面(虽然很老)是一个关于 Gdk pixbufs 的有用教程。您必须正确处理的一个细节是每个图像的 rowstride:二维图像存储为字节的线性数组，rowstride 告诉您一行由多少个字节组成。通常每个像素有 3 或 4 个字节(对于 RGB 或 RGB+alpha)，并且这些也需要在图像之间匹配。

Gtk 3 叠加功能如下:

```sh
static void overlay(GdkPixbuf *pixbuf, GdkPixbuf *overlay_pixbuf,
                         int height_offset, int width_offset) {
    int overlay_width, overlay_height, overlay_rowstride, overlay_n_channels;
    guchar *overlay_pixels, *overlay_p;
    guchar red, green, blue, alpha;
    int m, n;
    int rowstride, n_channels, width, height;
    guchar *pixels, *p;

    if (overlay_pixbuf == NULL) {
        return;
    }

    /* get stuff out of overlay pixbuf */
    overlay_n_channels = gdk_pixbuf_get_n_channels (overlay_pixbuf);
    n_channels =  gdk_pixbuf_get_n_channels(pixbuf);
    printf("Overlay has %d channels, destination has %d channels\n",
           overlay_n_channels, n_channels);
    overlay_width = gdk_pixbuf_get_width (overlay_pixbuf);
    overlay_height = gdk_pixbuf_get_height (overlay_pixbuf);

    overlay_rowstride = gdk_pixbuf_get_rowstride (overlay_pixbuf);
    overlay_pixels = gdk_pixbuf_get_pixels (overlay_pixbuf);

    rowstride = gdk_pixbuf_get_rowstride (pixbuf);
    width = gdk_pixbuf_get_width (pixbuf);
    pixels = gdk_pixbuf_get_pixels (pixbuf);

    printf("Overlay: width %d str8ide %d\n", overlay_width, overlay_rowstride);
    printf("Dest: width  str8ide %d\n", rowstride);

    for (m = 0; m < overlay_width; m++) {
        for (n = 0; n < overlay_height; n++) {
            overlay_p = ove
rlay_pixels + n * overlay_rowstride + m * overlay_n_channels;
            red = overlay_p[0];
            green = overlay_p[1];
            blue = overlay_p[2];
            if (overlay_n_channels == 4)
                alpha = overlay_p[3];
            else
                alpha = 0;

            p = pixels + (n+height_offset) * rowstride + (m+width_offset) * n_channels;
            p[0] = red;
            p[1] = green;
            p[2] = blue;
            if (n_channels == 4)
                p[3] = alpha;
        }
    }
}

```

## 阿尔法通道

叠加图像中可能有一些“透明”部分。你不希望这样的部分被覆盖到下面的图像。但是这些部分需要在像素阵列中有一个值。连零都是一个值:黑！一些图像会为每个像素分配另一个字节作为 alpha 通道。这有一个显示像素透明度的值。值 255 表示完全不透明，值 0 表示完全透明。

将透明像素与底层像素合并的最简单方法就是不要这样做:不要动底层像素。维基百科“阿尔法合成”( [`http://en.wikipedia.org/wiki/Alpha_compositing`](http://en.wikipedia.org/wiki/Alpha_compositing) )页面指出了更复杂的算法。

使用函数`gdk_pixbuf_add_alpha`可以将没有 alpha 通道的图像转换成有 alpha 通道的图像。这也可以用于通过匹配颜色来设置 alpha 通道的值。例如，下面的代码应该将任何白色像素的 alpha 值设置为 0，将所有其他像素的 alpha 值设置为 255:

```sh
pixbuf = gdk_pixbuf_add_alpha(pixbuf, TRUE, 255, 255, 255);

```

不幸的是，它似乎想留下一个像素的“边缘”，应该标记为透明。

有了 alpha 标记，可以在覆盖功能中使用一个简单的测试来决定是否执行覆盖。

```sh
if (alpha < 128) {
    continue;
 }

```

仅仅为了几行改动就给出一个完整的程序是不值得的。是`gtk_play_video_overlay_alpha.c`。

## 使用 Cairo 绘制图像

随着 Gtk 3.0 中 pixmaps 的消失，Cairo 现在是将多个组件组装成一个图像的唯一真正的方法。您可以在 [`http://cairographics.org/documentation/`](http://cairographics.org/documentation/) 找到开罗的一般信息，在 [`http://zetcode.com/gfx/cairo/`](http://zetcode.com/gfx/cairo/) 找到教程，在 [`http://zetcode.com/gfx/cairo/cairoimg/`](http://zetcode.com/gfx/cairo/cairoimg/) 找到叠加到图像上的信息。

开罗需要来源和目的地。源可以改变，通常是从图像源到颜色源，等等。目的地是画出来的东西的最终目的地。

目的地可以在内存中，也可以在各种后端。您需要一个内存中的目的地，以便可以从中提取 pixbuf，所有操作都在客户端完成。您创建一个目的地作为类型为`cairo_surface_t`的表面，并使用以下内容将其设置到类型为`cairo_t`的 Cairo 上下文中:

```sh
cairo_surface_t *surface = cairo_image_surface_create (CAIRO_FORMAT_ARGB32,
                                                       width, height);
cairo_t *cr = cairo_create(surface);

```

Cairo 上下文`cr`随后用于设置源、执行绘制等等。最后，您将从`surface`中提取一个位图。

第一步是将视频的每一帧的源设置为 pixbuf，并使用以下代码将其绘制到目标:

```sh
gdk_cairo_set_source_pixbuf(cr, pixbuf, 0, 0);
cairo_paint (cr);

```

您可以在此基础上叠加另一个图像，方法是将源更改为叠加图像，并绘制:

```sh
gdk_cairo_set_source_pixbuf(cr, overlay_pixbuf, 300, 200);
cairo_paint (cr);

```

请注意，如果覆盖图有“透明”像素，Cairo 将进行任何所需的 alpha 混合。

要绘制文本，您需要将源重置为 RGB 表面，设置文本的所有参数，并将文本绘制到目标中。这是通过以下方式完成的:

```sh
// white text
cairo_set_source_rgb(cr, 1.0, 1.0, 1.0);
// this is a standard font for Cairo
cairo_select_font_face (cr, "cairo:serif",
                        CAIRO_FONT_SLANT_NORMAL,
                        CAIRO_FONT_WEIGHT_BOLD);
cairo_set_font_size (cr, 20);
cairo_move_to(cr, 10.0, 50.0);
cairo_show_text (cr, "hello");

```

最后，您要从目的地提取最终图像，并将其设置到`GdkImage`中进行显示。这里还有一个 Gtk 2.0 和 Gtk 3.0 的区别:Gtk 3.0 有一个函数`gdk_pixbuf_get_from_surface`，会返回一个`GdKPixbuf`；Gtk 2.0 没有这个功能。你会在这里看到 Gtk 3.0 版本。

```sh
pixbuf = gdk_pixbuf_get_from_surface(surface,
                                     0,
                                     0,
                                     width,
                                     height);

gdk_threads_add_idle(draw_image, pixbuf);

```

使用 Cairo 播放视频的修改函数如下:

```sh
static gboolean draw_image(gpointer user_data) {
    GdkPixbuf *pixbuf = (GdkPixbuf *) user_data;

    gtk_image_set_from_pixbuf((GtkImage *) image, pixbuf);
    gtk_widget_queue_draw(image);
    g_object_unref(pixbuf);

    return G_SOURCE_REMOVE;
}

static void *play_background(void *args) {

    int i;
    AVPacket packet;
    int frameFinished;
    AVFrame *pFrame = NULL;

    int bytesDecoded;
    GdkPixbuf *pixbuf;
    GdkPixbuf *overlay_pixbuf;
    AVFrame *picture_RGB;
    char *buffer;

    GError *error = NULL;
    overlay_pixbuf = gdk_pixbuf_new_from_file(OVERLAY_IMAGE, &error);
    if (!overlay_pixbuf) {
        fprintf(stderr, "%s\n", error->message);
        g_error_free(error);
        exit(1);
    }

    // add an alpha layer for a white background
    overlay_pixbuf = gdk_pixbuf_add_alpha(overlay_pixbuf, TRUE, 255, 255, 255);

    int overlay_width = gdk_pixbuf_get_width(overlay_pixbuf);
    int overlay_height =  gdk_pixbuf_get_height(overlay_pixbuf);

    pFrame=avcodec_alloc_frame();

    i=0;
    picture_RGB = avcodec_alloc_frame();
    buffer = malloc (avpicture_get_size(PIX_FMT_RGB24, 720, 576));
    avpicture_fill((AVPicture *)picture_RGB, buffer, PIX_FMT_RGB24, 720, 576);

    while(av_read_frame(pFormatCtx, &packet)>=0) {
        if(packet.stream_index==videoStream) {
            usleep(33670);  // 29.7 frames per second
            // Decode video frame
            avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished,
                                  &packet);

            int width = pCodecCtx->width;
            int height = pCodecCtx->height;

            sws_ctx = sws_getContext(width, height, pCodecCtx->pix_fmt, width, height,
                                     PIX_FMT_RGB24, SWS_BICUBIC, NULL, NULL, NULL);

            if (frameFinished) {
                printf("Frame %d\n", i++);

                sws_scale(sws_ctx,  (uint8_t const * const *) pFrame->data, pFrame->linesize, 0, height, picture_RGB->data, picture_RGB->linesize);

                printf("old width %d new width %d\n",  pCodecCtx->width, picture_RGB->width);
                pixbuf = gdk_pixbuf_new_from_data(picture_RGB->data[0], GDK_COLORSPACE_RGB,
                                                  0, 8, width, height,
                                                  picture_RGB->linesize[0], pixmap_destroy_notify,
                                                  NULL);

                // Create the destination surface
                cairo_surface_t *surface = cairo_image_surface_create (CAIRO_FORMAT_ARGB32,
                                                                       width, height);
                cairo_t *cr = cairo_create(surface);

                // draw the background image
                gdk_cairo_set_source_pixbuf(cr, pixbuf, 0, 0);
                cairo_paint (cr);

                // overlay an image on top
                // alpha blending will be done by Cairo
                gdk_cairo_set_source_pixbuf(cr, overlay_pixbuf, 300, 200);
                cairo_paint (cr);

                // draw some white text on top
                cairo_set_source_rgb(cr, 1.0, 1.0, 1.0);
                // this is a standard font for Cairo
                cairo_select_font_face (cr, "cairo:serif",
                                        CAIRO_FONT_SLANT_NORMAL,
                                        CAIRO_FONT_WEIGHT_BOLD);
                cairo_set_font_size (cr, 20);
                cairo_move_to(cr, 10.0, 50.0);
                cairo_show_text (cr, "hello");

                pixbuf = gdk_pixbuf_get_from_surface(surface,
                                                     0,
                                                     0,
                                                     width,
                                                     height);

                gdk_threads_add_idle(draw_image, pixbuf);

                sws_freeContext(sws_ctx);
                cairo_surface_destroy(surface);
                cairo_destroy(cr);

            }
        }
        av_free_packet(&packet);
    }

    printf("Video over!\n");
    exit(0);
}

```

## 使用 Pango 绘制文本

虽然 Cairo 可以绘制任何形式的文本，但像`cairo_show_text`这样的函数没有太大的灵活性。比如说，画多种颜色会涉及很多工作。Pango 是一个处理文本所有方面的库。在 [`https://developer.gnome.org/pango/stable/`](https://developer.gnome.org/pango/stable/) 有一本盘古参考手册。好的教程在 [`www.ibm.com/developerworks/library/l-u-pango2/`](http://www.ibm.com/developerworks/library/l-u-pango2/) 。

给文本着色(和一些其他效果)的最简单方法是创建用 HTML 标记的文本，如下所示:

```sh
gchar *markup_text = "<span foreground=\"red\">hello </span><span foreground=\"black\">world</span>";

```

红色的是“你好”，黑色的是“世界”。这然后被解析成文本“红黑”和一组属性标记。

```sh
gchar *markup_text = "<span foreground=\"red\">hello </span><span foreground=\"black\">world</span>";
PangoAttrList *attrs;
gchar *text;

pango_parse_markup (markup_text, -1,0, &attrs, &text, NULL, NULL);

```

这可以通过从 Cairo 上下文创建一个`PangoLayout`来呈现到 Cairo 上下文中，在 Pango 布局中布置文本及其属性，然后在 Cairo 上下文中显示这个布局。

```sh
PangoLayout *layout;
PangoFontDescription *desc;

cairo_move_to(cr, 300.0, 50.0);
layout = pango_cairo_create_layout (cr);
pango_layout_set_text (layout, text, -1);
pango_layout_set_attributes(layout, attrs);
pango_cairo_update_layout (cr, layout);
pango_cairo_show_layout (cr, layout);

```

(是的，在所有这些中，有很多在库之间跳来跳去！)

和前面一样，一旦所有内容都被绘制到 Cairo 上下文中，就可以从 Cairo 表面目的地提取出一个 pixbuf，设置到`GtkImage`中，并添加到 Gtk 事件队列中。

使用 Pango 绘制视频的修改函数如下:

```sh
static gboolean draw_image(gpointer user_data) {
    GdkPixbuf *pixbuf = (GdkPixbuf *) user_data;

    gtk_image_set_from_pixbuf((GtkImage *) image, pixbuf);
    gtk_widget_queue_draw(image);
    g_object_unref(pixbuf);

    return G_SOURCE_REMOVE;
}

static void *play_background(void *args) {

    int i;
    AVPacket packet;
    int frameFinished;
    AVFrame *pFrame = N
ULL;

    /* initialize packet, set data to NULL, let the demuxer fill it */
    /* http://ffmpeg.org/doxygen/trunk/doc_2examples_2demuxing_8c-example.html#a80 */
    av_init_packet(&packet);
    packet.data = NULL;
    packet.size = 0;

    int bytesDecoded;
    GdkPixbuf *pixbuf;
    GdkPixbuf *overlay_pixbuf;
    AVFrame *picture_RGB;
    char *buffer;

    // Pango marked up text, half red, half black
    gchar *markup_text = "<span foreground=\"red\">hello</span><span foreground=\"black\">world</span>";
    PangoAttrList *attrs;
    gchar *text;

    pango_parse_markup (markup_text, -1,0, &attrs, &text, NULL, NULL);

    GError *error = NULL;
    overlay_pixbuf = gdk_pixbuf_new_from_file(OVERLAY_IMAGE, &error);
    if (!overlay_pixbuf) {
        fprintf(stderr, "%s\n", error->message);
        g_error_free(error);
        exit(1);
    }

    // add an alpha lay
er for a white background
    overlay_pixbuf = gdk_pixbuf_add_alpha(overlay_pixbuf, TRUE, 255, 255, 255);

    int overlay_width = gdk_pixbuf_get_width(overlay_pixbuf);
    int overlay_height =  gdk_pixbuf_get_height(overlay_pixbuf);

    pFrame=avcodec_alloc_frame();

    i=0;
    picture_RGB = avcodec_alloc_frame();
    buffer = malloc (avpicture_get_size(PIX_FMT_RGB24, 720, 576));
    avpicture_fill((AVPicture *)picture_RGB, buffer, PIX_FMT_RGB24, 720, 576);

    while(av_read_frame(pFormatCtx, &packet)>=0) {
        if(packet.stream_index==videoStream) {
            usleep(33670);  // 29.7 frames per second
            // Decode video frame
            avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished,
                                  &packet);

            int width = pCodecCtx->width;
            int height = pCodecCtx->height;

            sws_ctx = sws_getContext(width, height, pCodecCtx->pix_fmt, width, height,
                                     PIX_FMT_RGB24, SWS_BICUBIC, NULL, NULL, NULL);

            if (frameFinished) {
                printf("Frame %d\n", i++);

                sws_scale(sws_ctx,  (uint8_t const * const *) pFrame->data, pFrame->linesize, 0, height,
                                picture_RGB->data, picture_RGB->linesize);

                printf("old width %d new width %d\n",  pCodecCtx->width, picture_RGB->width);
                pixbuf = gdk_pixbuf_new_from_data(picture_RGB->data[0], GDK_COLORSPACE_RGB,
                                                  0, 8, width, height,
                                                  picture_RGB->linesize[0], pixmap_destroy_notify,

                                                  NULL);

                // Create the destination surface
                cairo_surface_t *surface = cairo_image_surface_create (CAIRO_FORMAT_ARGB32,
                                                                       width, height);
                cairo_t *cr = cairo_create(surface);

                // draw the background image
                gdk_cairo_set_source_pixbuf(cr, pixbuf, 0, 0);
                cairo_paint (cr);

                // overlay an image on top
                // alpha blending will be done by Cairo
                gdk_cairo_set_source_pixbuf(cr, overlay_pixbuf, 300, 200);
                cairo_paint (cr);

                // draw some white text on top
                cairo_set_source_rgb(cr, 1.0, 1.0, 1.0);
                // this is a standard font for Cairo
                cairo_select_font_face (cr, "cairo:serif",
                                        CAIRO_FONT_SLANT_NORMAL,
                                        CAIRO_FONT_WEIGHT_BOLD);
                cairo_set_font_size (cr, 20);
                cairo_move_to(cr, 10.0, 50.0);
                cairo_show_text (cr, "hello");

                // draw Pango text
                PangoLayout *layout;
                PangoFontDescription *desc;

                cairo_move_to(cr, 300.0, 50.0);
                layout = pango_cairo_create_layout (cr);
                pango_layout_set_text (layout, text, -1);
                pango_layout_set_attributes(layout, attrs);
                pango_cairo_update_layout (cr, layout);
                pango_cairo_show_layout (cr, layout);

                pixbuf = gdk_pixbuf_get_from_surface(surface,
                                                     0,
                                                     0,
                                                     width,
                                                     height);

                gdk_threads_add
_idle(draw_image, pixbuf);

                sws_freeContext(sws_ctx);
                g_object_unref(layout);
                cairo_surface_destroy(surface);
                cairo_destroy(cr);

            }
        }
        av_free_packet(&packet);
    }

    printf("Vi
deo over!\n");
    exit(0);
}

```

## 结论

掌握 Gtk 工具包的某些方面并不容易。你将在后面的章节中用到这些材料，这也是为什么它被从本书的声音章节中抽出，放在它自己的章节中。那些对 Linux sound 不感兴趣的人可能会发现它很有用。