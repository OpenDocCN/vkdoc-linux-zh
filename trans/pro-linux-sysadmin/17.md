# 17.性能监控和优化

By Peter Lieverdink and Dennis Matotek

既然你的主机正在为你提供服务，那么继续这样做是很重要的。随着业务的增长，服务器上的工作负载也会增加。在本章中，我们将向您展示如何监控磁盘空间、处理器和 RAM 使用等资源。这将帮助您识别性能瓶颈，并更好地利用您拥有的资源。

少量的调优可以减少购买额外硬件的需求，因此监控性能可以帮助您节省资金和时间。

## 基本健康检查

在本节中，我们将看一些帮助您确定主机状态的基本工具。

### CPU 使用情况

当应用程序运行缓慢时，您应该检查的第一件事是系统是否真的在忙着做什么。最快的方法是通过`uptime`命令，如清单 [17-1](#Par5) 所示。

```
$ uptime
12:51:04 up 116 days, 7:09, 3 users, load average: 0.01, 0.07, 0.02
Listing 17-1.The uptime Command

```

该命令打印系统状态的简要概述，包括当前时间、系统已开启(或启动)的时间、登录用户的数量以及代表系统工作负载的三个数字。

在我们的示例中，系统上次启动是在 116 天 7 小时 9 分钟之前。如果您失去了与远程服务器的连接，这使您可以在重新登录后轻松确定系统是否重新启动。

登录用户的数量是当前通过终端控制台、X 和 SSH 登录的总数量。如果您登录两次，您将被计为两个用户。连接到 Samba 或 Apache 等服务的用户在这里不计算在内。

最后，系统负载以三个数字显示。这些数字形成了一个指数，表明在过去的 1 分钟、5 分钟和 15 分钟内，CPU 计划完成的工作与实际完成的工作的平均比率。

负载为 1.00 意味着被调度的工作量等于 CPU 可以处理的工作量。令人困惑的是，如果一台主机包含多个 CPU，每个 CPU 的负载相加得到一个总数；在具有四个 CPU 内核的主机上，4.00 的负载与单核系统上 1.00 的负载具有相同的含义。

在我们的示例中，过去一分钟的平均工作负载约为 1%。一些额外的任务正在运行，可能在几分钟前完成，因为过去 5 分钟的平均工作负载为 7%。

尽管这些数字绝不应该被视为真理，但它们确实提供了一种快速检查系统是否健康的方法。如果在一个有八个 CPU 内核的主机上，系统负载是 6.00，那么许多任务可能刚刚运行完。如果负载为 60，则存在问题。

这个问题可能是主机正在运行几个独占 CPU 的进程，不允许其他进程有足够的周期。稍后我们将向您展示如何使用`top`实用程序找到这些进程。或者，您的主机可能试图运行远远超出其处理能力的进程，同样没有为它们留下足够的 CPU 周期。如果写得不好的应用程序或守护进程不断产生自己的副本，就会发生这种情况。有关更多信息，请参见“Fork Bomb”侧栏。稍后我们将向您展示如何使用`ulimit`命令来防止这种情况。

最后，可能有一个进程正在等待主机执行一个不能被中断的任务，比如将数据移入或移出磁盘。如果此任务必须在进程继续之前完成，则称该进程处于不可中断的睡眠状态。它将计入更高的平均负载，但实际上不会使用 CPU。稍后，我们将在“高级工具”部分向您展示如何检查磁盘的使用量。

Fork Bomb

我们在第 5 章[中解释过，当一个守护进程或服务在后台运行时，它会派生出一个子进程，并使`init`成为父进程，而原来的进程会退出。对于一个行为不端的应用程序来说，做错误的事情并继续派生子进程而不是退出是完全可能的。这叫做叉形炸弹。](05.html)

fork bomb 会在宿主允许的情况下尽快创建自己的新副本。一个进程产生两个进程，两个进程产生两个进程，四个进程产生八个进程，以此类推，从而耗尽其他进程的资源，比如 CPU 周期，最终耗尽 RAM。

### 内存使用

性能降低的另一个原因是内存使用过多。如果一个任务开始使用大量内存，主机将被迫通过将其他任务放入交换内存来释放内存。与访问 RAM 相比，访问交换内存的速度非常慢，毕竟交换内存只是一块磁盘，就像内存一样使用。

您可以通过`free`命令快速检查主机正在使用多少 RAM 和交换内存。我们将把`-h`(人类可读)选项传递给它，这样它就可以用千兆字节(`-g`)、兆字节(`-m`)或千字节(`-k`)来显示大小，如清单 [17-2](#Par19) 所示。

```
$ free -h
               total        used        free      shared       buff/cache     available
Mem:           3.1G         59M         2.7G      13M          350M           2.8G
Swap:          1.5G         0B          1.5G
Listing 17-2.The free Command

```

该列表让您可以快速了解系统的可用内存是否不足。第一行告诉您 RAM 使用的状态。总数是该主机可用的 RAM 量。然后，这被分成正在使用的 RAM 和空闲的 RAM。不同版本的自由程序可能在同一系统上显示不同的内存值。

`shared`是指共享内存，主要是`tmpfs`。这与`/proc/meminfo Shmem`值(内核使用的空间)相匹配。

buffers 列告诉您内核用作磁盘写缓冲区的内存量。这个缓冲区允许应用程序快速写入数据，并让内核在后台处理写入磁盘的数据。也可以从这个缓冲器中读取数据，进一步提高速度。最后一列`cached`，告诉您内核使用了多少内存作为高速缓存来快速访问信息。

缓冲区和高速缓存都根据需要调整大小。如果应用程序需要更多的 RAM，内核将释放部分缓存或缓冲区空间，并重新分配内存。如果交换空间可用，内核可以将不活动的内存移动到交换空间。

最后，最后一行告诉我们主机使用了多少交换空间。随着时间的推移，这个数字会略有上升，因为没有被使用的服务可以被内核放在交换空间中。这样做允许它回收空闲的 RAM，并将其用作缓冲区或缓存。

这意味着让您的主机使用交换空间不一定是一件坏事。但是，如果所有的内存和所有的交换空间都在使用中，显然就有问题了。在我们的示例中，我们没有使用任何交换空间，因此它显示为可用的 1.5GB 空间中的 0。

Note

在 Linux 上，空闲内存意味着浪费内存，因为它没有被利用，甚至没有作为缓冲区或缓存。

我们将在“高级工具”部分向您展示如何找出单个任务使用了多少内存。

### 磁盘空间

计算机系统拥有的其他有限资源是磁盘空间和磁盘速度。一般来说，当磁盘变满时，系统不会变慢，但服务可能会崩溃并给用户带来痛苦，因此关注使用情况并在需要时提供更多存储空间是值得的。

我们将在下一节向您展示如何检查磁盘速度问题。

Note

我们在第 [9](09.html) 章中介绍了用于检查可用和已用磁盘空间的`df`和`du`工具。

### 日志

最后，如果应用程序或内核发生了问题，您可能会在系统或内核日志中找到一个日志条目。您当然希望重启任何崩溃的服务，但是检查问题原因的日志将帮助您防止同样的事情再次发生。

如果日志守护进程本身已经停止，您仍然可以通过`dmesg`命令检查内核日志缓冲区。

Note

我们将在第 [18](18.html) 章中详细介绍日志记录。

## 高级工具

基本工具为您提供快速概述，但不提供任何信息来帮助您确定问题的原因(如果有的话)。为此，我们将向您展示一些可以帮助您查明瓶颈的工具。

### CPU 和内存使用

为了列出当前运行任务的详细信息，Linux 提供了`top`实用程序。这类似于你可能习惯于从 Windows 或 macOS 上的活动监视器使用的任务管理器，但它在终端窗口中运行，如图 [17-1](#Fig1) 所示。它提供了主机上正在运行的进程和线程的可排序和可配置列表。您可以使用以下命令来访问它:

![A185439_2_En_17_Fig1_HTML.jpg](A185439_2_En_17_Fig1_HTML.jpg)

图 17-1。

The top utility

```
$ top

```

输出的顶部给出了几个标题行，其中包括来自`uptime`的信息，以及来自`free`和`vmstat`命令的一些汇总数据，稍后我们将在“交换空间使用”和“磁盘访问”部分讨论这些数据。您可以打开和关闭这些标题。L 键切换平均负载线的显示。您可以通过 T 键切换任务摘要，通过 m 键切换内存信息。

显示屏的其余部分由几列关于正在运行的进程和线程的信息组成。您在这里看到的列是默认显示的，但是您也可以启用或禁用其他列。我们在表 [17-1](#Tab1) 中列出了它们的标题和含义。

表 17-1。

top Column Headers

<colgroup><col> <col></colgroup> 
| 页眉 | 意义 |
| --- | --- |
| `PID` | 任务的进程 ID。这个唯一的标识符允许您操作任务。 |
| `USER` | 任务所有者的用户名；它运行的帐户。 |
| `PR` | 任务优先级。 |
| `NI` | 任务精细度；表示该任务愿意将 CPU 周期让给其他任务的程度。较低或负面的好意味着高优先级。 |
| `VIRT` | 任务分配的内存总量，包括共享内存和交换内存。 |
| `RES` | 任务使用的物理内存总量，不包括交换内存。 |
| `SHR` | 任务使用的共享内存量。这种内存通常由库分配，也可供其他任务使用。 |
| `S` | 任务状态。这表明任务是正在运行(`R`)、休眠(`D`或`S`)、停止(`T`)还是僵死(`Z`)。 |
| `%` `CPU` | 自上次屏幕更新以来，该任务使用的 CPU 周期的百分比。 |
| `%MEM` | 该任务使用的可用 RAM 的百分比。 |
| `TIME+` | 任务自启动以来使用的总 CPU 时间。 |
| `COMMAND` | 被监视的任务的名称。 |

您可以在`man top`手册页中获得这些和所有其他可用字段的完整描述。

默认情况下，任务按降序显示，并按`%CPU`排序。消耗 CPU 时间最多的进程将位于列表的顶部，这对解决问题非常有用。

我们可以对`top`中的许多列进行排序。为了对 CPU 使用情况进行排序，我们需要对`%CPU`列进行排序。我们可以通过按 F 键选择要排序的列，这将弹出一个可用列的列表，如图 [17-2](#Fig2) 所示。

![A185439_2_En_17_Fig2_HTML.jpg](A185439_2_En_17_Fig2_HTML.jpg)

图 17-2。

Choosing a sort field

第一行告诉我们当前的排序字段`%CPU`。下面是如何选择不同排序字段的说明。向上和向下箭头导航到不同的字段。如果您按 s，您将看到该字段现在已被选中。d 键和空格键切换是否显示该字段。您可以使用 q 或 Escape 键返回到您的选择的顶部屏幕。我们可以按 s 使`%CPU`列成为我们的排序字段，然后按 q 返回到任务列表。现在所有的进程都是按照它们使用的 CPU 周期数来排序的，所以如果一个进程正在疯狂运行，你将能够很容易地发现它。

Note

可以选择比屏幕显示更多的字段。如果发生这种情况，您将需要取消选择一些其他字段来腾出空间。

Orphans and Zombies: Undead Tasks

除了初始进程`systemd`或`init`之外，Linux 主机上的每个任务都由一个父进程控制，当它完成执行时，它向这个父进程报告它的状态。

但是，有时事情会出错，父进程可能会崩溃，留下一个已完成的子进程等待向其父进程报告其状态。这就创建了一个孤儿进程，它被`systemd`(或`init`)采用。当它完成时，它报告并被收获(或清理)。

僵死进程是一个已经终止但仍存在于进程表中的子进程，等待其父进程读取其退出状态。每个子进程都是这样结束的。父进程将向子进程发送一个等待系统调用来读取其退出状态。如果没有发生这种情况，该进程就不能从进程列表中删除并保留在那里。这不一定是一个问题，因为它最终应该由父代或由`systemd` ( `init`)获得。在这种状态下，它已经释放了内存，并且没有使用 CPU。然而，它可以指出一个程序的问题，该程序的父程序崩溃了，没有得到它的子程序。

您可以通过查看进程列表输出来查看僵尸进程。

```
$ ps aux |grep Z
USER    PID    %CPU %MEM   VSZ   RSS   TTY     STAT    START   TIME   COMMAND
ubuntu  7814   0.0  0.0    0     0     pts/0   Z+      11:52   0:00   [zombie] <defunct>

```

你可以在 [`http://en.wikipedia.org/wiki/Zombie_process`](http://en.wikipedia.org/wiki/Zombie_process) 阅读更多关于僵尸的内容。

在`top`中有更多的显示选项，您可以在帮助菜单中找到它们。新闻？去访问它。当您根据自己的喜好定制了`top`显示信息的方式后，您可以按 w 保存配置。这将把设置写入您的主目录中一个名为`.toprc`的文件。

如果发现一个行为不端的任务，可以用`top`退出。为此，请按 k 并输入相关任务的 PID。然后会要求您输入发送给进程的信号。使进程正常终止的信号是 15。如果这不起作用，您可能想尝试发送信号 3，这是有点严厉，或信号 9，这是类似于斧头谋杀过程。

要了解更多关于信号的信息，请阅读“杀人并不总是谋杀”侧栏。

Note

您必须是流程所有者或根用户，才能向流程发送信号。

Killing Is Not Always Murder

尽管向进程发送信号的行为被称为终止，并且通常是通过`kill`命令完成的，但它不一定会退出进程。它使用内核中的工具向进程发送信号。

提供的服务已被设计为侦听此信号；可以让他们执行一个动作。最常用的是信号 1，也称为 HUP。这个信号会导致大多数服务重新加载它们的配置文件，不再需要停止和重新启动它们。

如果你想让一个应用程序或进程退出，你可以通过向它发送`SIGTERM`或`SIGQUIT`信号来请求它退出，这两个信号分别是 15 和 3。一个无视礼貌的停止请求的任务可能会通过 9 或`SIGKILL`信号被强制停止。

发送`SIGKILL`将立即停止进程，不管它正在做什么。这可能会使您的流程(可能还有数据)处于混乱状态，所以要小心使用。`SIGTERM`将允许进程在退出前正常关闭。

您可以在`man 7 signal`手册页中阅读更多关于信号及其功能的信息。

如果你有一个进程占用了太多的 CPU 时间并且中断了更重要的进程，你可以通过降低它的优先级来让它变得更好。这意味着它将更容易让位于其他进程，允许它们使用分配给它的一些 CPU 周期。您可以通过按 R 键来更改加工精度。`top`将询问您进程 ID 和新的 niceness 值。

除非你以 root 或者通过`sudo`运行`top`，否则你只能让进程变得更好。你不能提高他们的优先级，只能降低优先级。

完成后，按 q 退出`top`。

Note

您还可以使用`renice`实用程序来更改 niceness 和 priority，而无需使用 top。例如，要改变进程 8612 的精确性，您可以运行`renice +5 8612`。

### 交换空间使用

如果您看到大量交换空间正在使用，这可能表明系统内存不足。交换空间和 RAM 构成了系统可用的总可分配内存。当一个特定的进程需要内存并且没有立即可用的内存时，内核会将较少使用的内存页换出到交换空间中。这不一定是一件坏事，但是如果系统“大量交换”(也就是说，频繁地将内存页面移入和移出交换空间，那么因为交换比 RAM 慢得多，所以会导致性能很差)。

您可以通过`vmstat`实用程序检查是否是这种情况。您通常希望让这个实用程序每隔几秒钟打印一次信息，这样您就可以发现任何趋势。传递`-n`选项，防止标题被重新打印，并告诉它每 5 秒重新显示一次统计，如图 [17-3](#Fig3) 所示。按 Ctrl+C 退出`vmstat`。

![A185439_2_En_17_Fig3_HTML.jpg](A185439_2_En_17_Fig3_HTML.jpg)

图 17-3。

vmstat output on heavily swapping host

这个令人印象深刻的混乱数字向我们表明了有多少数据在系统中流动。每一行由六组数字组成，这些数字提供了关于进程、内存、交换、输入/输出、系统和 CPU 的信息。

由于过多的交换空间使用而导致的性能下降将出现在其中的两个组中:`swap`和`cpu`。

`swap`组中的`si`和`so`列显示从(`si`—换入)和写入(`so`—换出)交换空间的交换内存量。`cpu`组中的`wa`和`sy`列告诉您 CPU 等待数据处理系统(或内核)请求的时间百分比——因此不处理系统指令。

如果主机将大部分 CPU 周期用于将应用程序移入和移出交换空间，则`si`和`so`列的值将会很高。实际值将取决于发生的交换数量和交换设备的速度。`wa`列通常也会显示 90 多的值，表明 CPU 正在等待从交换空间中检索应用程序或数据。

您可以通过使用`top`找出哪个应用程序使用了过多的 RAM，并可能更改其配置以使用较少的 RAM 来解决这个问题。大多数情况下，你会发现你的主应用程序使用了最多的内存。在这种情况下，请为您的系统分配或安装更多内存。

Note

`top`本身是相当资源饥渴的，所以如果一个系统没有响应并且负载非常重，重启它可能比等待`top`启动更容易更快。

```
procs - ---------memory------------- ---swap-- ---io--- --system-- ------cpu-----
 r  b   swpd   free     buff  cache   si   so    bi    bo    in    cs     us sy id wa st
 0  0   422336 750352   8252 130736    0    0     0     0     27   56     0  0 100  0  0
 0  0   422332 750352   8252 130736    1    0     1     0     27   55     0  0 100  0  0

```

在前面的示例中，这是一个主机处于轻负载下的示例。该主机交换空间低，CPU 大部分时间处于空闲状态。

### 磁盘存取

`vmstat`实用程序还将告诉我们有多少数据正在从磁盘读取和写入磁盘。在图 [17-4](#Fig4) 中，我们突出显示了`io`组中的`bi`(闭塞)和`bo`(闭塞)列。通过传递第二个数字作为参数，我们告诉`vmstat`在五次间隔后退出。

![A185439_2_En_17_Fig4_HTML.jpg](A185439_2_En_17_Fig4_HTML.jpg)

图 17-4。

vmstat with low disk I/O

这两个数字告诉您在每个时间间隔内，从(`bi`)磁盘读取和写入(`bo`)磁盘的确切数据块数量。在我们的例子中，系统从磁盘读取的数据比写回的数据多，但是两个数字都很低。因为我们磁盘上的块大小是 4KB，这意味着它们负载不是很重。

Tip

如果您忘记了您的磁盘或分区的块大小，您可以发出以下命令:`blockdev –getbsz <partition>`。

构成重负载的因素取决于数据块大小和磁盘速度。如果正在写入一个大文件，该数字将在写入操作期间上升，但稍后会再次下降。

当在一个空闲的系统上创建一个大文件时，通过检查得到的数字，可以了解主机的能力。运行`dd`命令在后台创建一个 1Gb 的只包含零的文件，同时运行`vmstat`，如图 [17-5](#Fig5) 所示。

![A185439_2_En_17_Fig5_HTML.jpg](A185439_2_En_17_Fig5_HTML.jpg)

图 17-5。

vmstat with high disk I/O

在同一台主机上，我们将运行以下命令:

```
$ dd if=/dev/zero of=./largefile bs=1M count=1024

```

然后当我们同时运行`vmstat`命令时，你会看到类似于图 [17-5](#Fig5) 的东西。

在两次运行中,`bo`列都很低，因为文件数据仍然在内核缓冲区中。但是，在下一个时间间隔，您可以看到它增加到超过 222，000 个数据块。请记住，这超过了 5 秒，因此我们可以计算出该特定主机上的峰值写入速率大约为每秒 45，000 个数据块。

如果您注意到性能下降，并且`vmstat`显示的`bo`值接近长时间测试时系统可以管理的最大速率，则您的应用程序或服务正在非常努力地写入大量数据。这通常表明存在问题，因此您应该找出哪个应用程序是罪魁祸首并纠正问题。

### dstat 更深入

您如何发现哪个应用程序可能有问题？`vmstat`命令对于发现问题很有用，但是它不允许您更深入地调查。另一方面，`dstat`命令是一个很好的挖掘工具。

您可以使用软件包管理器 YUM 或 Apt 通过 Ubuntu 和 CentOS 上的`dstat`软件包安装`dstat`。一旦安装了一个，您就可以发出如图 [17-6](#Fig6) 所示的输出。

![A185439_2_En_17_Fig6_HTML.jpg](A185439_2_En_17_Fig6_HTML.jpg)

图 17-6。

dstat output

到目前为止，它与`vmstat`没有太大的不同，除了我们有为我们计算的磁盘读写，我们还有网络发送和接收信息。CPU、分页、系统与`vmstat`相同。

让我们假设我们已经注意到我们的应用程序性能很差，我们认为这是由于磁盘性能。当我们查看`vmstat`时，我们看到了图 [17-7](#Fig7) 中的结果。

![A185439_2_En_17_Fig7_HTML.jpg](A185439_2_En_17_Fig7_HTML.jpg)

图 17-7。

Checking I/O with vmstat

我们可以看到有相当多的数据正在写入(`bo`)，但我们不知道是哪个磁盘。对于我们的虚拟应用程序，我们有三个分区，分别安装到`/app/log`、`/app/sys`和`/app/data`。分区分别是`sdc1`、`sdb1`和`sdb2`。我们将利用这些信息来看看`dstat`说了什么。

在图 [17-8](#Fig8) 中，我们可以看到我们已经使用了`–D`切换到`dstat`来传递我们想要监控的分区。我们有大量的数据被写入`sdc1`，这是我们的应用程序日志。在我们假想的世界中，我怀疑我们的应用程序已经用调试日志记录启动了。

![A185439_2_En_17_Fig8_HTML.jpg](A185439_2_En_17_Fig8_HTML.jpg)

图 17-8。

dstat disk access

同样，您可以使用`–N`开关向`dstat` ( `-N em1,em2`)提供网络接口，以报告每个接口的网络流量。`–C`将为 CPU 做类似的工作。你应该查看`help`或`man`页面了解更多信息。

当我们在第 [18](18.html) 章讨论 Nagios 时，我们将回到如何在系统性能下降时获得通知。

## 持续性能监控

现在您已经有了诊断性能瓶颈的基本工具，我们将向您展示如何自动化持续的监控。这将使您能够访问更长期的性能和资源使用数据，进而使您能够更好地确定是否以及何时升级硬件或将服务迁移到其他主机。我们将向您介绍以下工具:

*   Collectd:系统统计信息收集守护程序
*   Graphite:收集和绘制度量数据的商店
*   Grafana:一个很好的前端界面，用于显示度量图

### 已收集

Collectd 是一个强大的系统指标收集守护程序，可以收集关于您的系统和各种应用程序和服务的信息。它是高度可配置的，开箱即可为您收集指标。

我们将使用 Collectd 从我们的主机收集指标，并将它们发送到 Graphite，一个指标收集存储。但是，您可以使用 Write HTTP 或 Network 插件将指标写入许多其他后端。

你可以通过你的软件包管理器在 Ubuntu 和 CentOS 上安装 Collectd。对于 CentOS，您需要安装`epel-release`包，因为标准存储库中没有 Collectd 包。

可从标准 Ubuntu 库获得的 Ubuntu 版本稍微落后于当前版本，但是 CentOS 版本是相当新的；根据您需要的功能，这可能会影响您的安装决策。

安装很简单。在 CentOS 上，您可以发出以下命令来安装 Collectd 和`mysql`插件:

```
$ sudo yum install collectd collectd-mysql

```

根据您的需求，您可以用相同的方式安装几个插件包(使用`yum search collectd`获取列表)。在 Ubuntu 上简单如下:

```
$ sudo aptitude install collectd

```

#### 集合配置

Collectd 服务是从主`collectd.conf`文件配置的。当然，这些安装在哪里略有不同。在 Ubuntu 上，它被安装到`/etc/collectd`目录中，在 CentOS 上，它被安装到`/etc/`目录中。

您也可以将配置文件放入`collectd.d`目录。这在 Ubuntu ( `/etc/collectd/collectd.conf.d/`)和 CentOS ( `/etc/collectd.d/`)上当然是不同的。

Collectd 使用的配置文件有一个必需的格式。内容如下:

```
global options

# plugin without options
LoadPlugin plugin_name
# loading a plugin and overriding options
<LoadPlugin plugin_name>
    ...plugin options...
</LoadPlugin>
# provide an option block to plugins without a LoadPlugin stanza (requires AutoLoadPlugin true)
<Plugin plugin_name>
    ... plugin options...
</Plugin>

```

插件有两种:读插件和写插件(有些可以是读写插件)。读插件会收集数据，写插件会把收集到的数据放到某个地方。每个插件都可以放在自己的配置文件中；但是，如果 LoadPlugin 调用了多个副本，那么将执行读入的第一个副本，该插件的任何其他配置都将被忽略。该配置类似于 Apache web 服务器配置文件。配置块包含在`<>...</>`中。

在这个例子中，我们将收集基本的系统指标，比如 CPU、内存和磁盘空间，并且我们将使用`mysql`插件测量一些数据库统计数据。我们的数据库服务器恰好是 CentOS，安装`mysql collectd`插件已经在`/etc/collectd.d`目录下放置了一个`mysql.conf`文件。无论您使用哪种发行版，Collectd 配置都是相同的。

我们将首先看一下`collectd.conf`文件(清单 [17-3](#Par110) )。

```
#Hostname "localhost"
FQDNLookup true
#BaseDir "/var/lib/collectd"
#PluginDir "/usr/lib/collectd"
#TypesDB "/usr/share/collectd/types.db" "/etc/collectd/my_types.db"
#AutoLoadPlugin false
#CollectInternalStats false
#Interval 10
#MaxReadInterval 86400
#Timeout         2
#ReadThreads     5
#WriteThreads    5
#WriteQueueLimitHigh 1000000
#WriteQueueLimitLow   800000
Listing 17-3.collectd.conf Configuration Global Options

```

Collectd 的全局选项适用于 Collectd 服务本身，并定义了基本目录、插件目录、间隔和读/写线程以及队列限制等内容。这些可以大部分保留为默认值。`FQDNLookup`行意味着它将查找运行该程序的计算机的主机名，或者您可以通过`Hostname`设置强制这样做。

```
LoadPlugin syslog
<Plugin syslog>
    LogLevel info
</Plugin>

```

我们加载我们的第一个插件，它用于将我们的日志定向到带有`info`的`LogLevel`的`syslog`服务。`debug`值只有在 Collectd 已经编译了调试支持时才可用，notice、warning 和 err 也是可接受的。

```
LoadPlugin cpu
LoadPlugin df
LoadPlugin disk
LoadPlugin interface
LoadPlugin load
LoadPlugin memory
LoadPlugin mysql
LoadPlugin swap
LoadPlugin rrdtool

```

在本节中，我们将加载我们的插件，我们将使用这些插件来收集指标。我们涵盖了`cpu`、`df`、`disk`、`interface`、`load`、`memory`和`swap`的基础知识。到目前为止，这些对您来说应该是不言自明的了。`mysql`插件将用于从我们的 MariaDB 数据库中收集一些 InnoDB 统计数据。最后，我们有了`rrdtool`插件，它将用于将指标输出为 RRD 文件。

RRD 代表“循环数据库”文件，通常用于保存时序数据。时序数据库保存`db`记录类型，如计数、仪表和直方图。他们可以以不同的粒度保存这些记录。您可能拥有每秒收集一次的记录，它们可以以这种粒度存储在 RRD 文件中。或者，我们可以为这些指标选择 5 分钟的粒度，1 秒钟的指标累计为 5 分钟的平均值。

还有其他存储指标的选项，我们将在下一节向您展示如何配置它们。

```
<Plugin cpu>
    ReportByCpu true
    ReportByState true
    ValuesPercentage false
</Plugin>

```

当我们为我们的 CPU 声明配置选项时，我们给出了按 CPU 报告和按状态报告的选项，并且我们没有以百分比显示值。这将为我们提供 CPU 工作负载的准确情况。

```
<Plugin df>
    FSType rootfs
    FSType sysfs
    FSType proc
    FSType devtmpfs
    FSType devpts
    FSType tmpfs
    FSType fusectl
    FSType cgroup
    IgnoreSelected true
</Plugin>

```

`df`插件展示了另一个如何细化我们想要选择的指标的例子。在这个例子中，我们列出了我们不想在指标中收集的值，然后我们使用`IgnoreSelected true`将它们从我们的收集中排除。列出的文件类型是伪文件系统，只会增加噪音。

```
<Plugin disk>
    Disk "/^(xv)?[hs]?d[a-z]\d?$/"
    IgnoreSelected false
    UseBSDName false
    UdevNameAttr "DEVNAME"
</Plugin>

```

使用`disk`插件，我们正在做与使用`df`插件相反的事情。在这里，我们选择我们想要监控的设备，并通过正则表达式给它们命名。我们可能有以下列方式命名的磁盘:

```
/dev/sda2
/dev/hdb4
/dev/xvda3

```

我们需要能够匹配这些磁盘命名约定中的任何一个。首先，我们一起寻找`x`和`v``(^(xv)?)`，并在字符串的开始(`^`)匹配这个模式零次或多次。接下来，我们可能有一个`h`或者一个`s`零次或者更多次(`[hs]?`)。然后我们锚定在`d`周围，接着是任何`a`到`z`的磁盘`([a-z]`。然后，我们期望零个或多个分区号(`\d?`)。最后还匹配了行尾(`$`)。

当我们与`IgnoreSelected false`匹配时，我们应该能够匹配我们的磁盘名称。`UseBSDName false`只在 MAC 上使用，`UdevNameAttr "DEVNAME"`表示我们尝试对磁盘设备使用 Udev 名称。

```
<Plugin interface>
    Interface "localhost"
    IgnoreSelected true
</Plugin>

```

同样，对于接口配置，我们使用了`IgnoreSelected`选项。我们希望收集除本地主机或环回接口之外的每个网络接口的指标。

```
<Plugin load>
    ReportRelative true
</Plugin>

<Plugin memory>
    ValuesAbsolute true
    ValuesPercentage false
</Plugin>

```

前面是内存和负载的默认值，类似于我们正在收集的其他系统指标。

```
<Plugin mysql>
    <Database no_db>
        Host "localhost"
        Port "3306"
        User “monitor"
        Password “monitorpasswd"
        ConnectTimeout 10
        InnodbStats true
    </Database>
</Plugin>

```

这个插件将和我们的 MariaDB 服务器一起工作。它只需要拥有`USAGE`权限的用户，并将收集内部指标，相当于`mysql SHOW STATUS;`命令。如果您需要查询指标，您可以查看`dbi`插件，您可以使用它对您的数据库运行指标。

在`mysql`插件中，您可以在`<Database> </Database>`块中指定一个或多个数据库。

```
<Plugin rrdtool>
    DataDir "/var/lib/collectd/rrd"
    CacheTimeout 120
    CacheFlush 900
    WritesPerSecond 30
    CreateFilesAsync false
    RandomTimeout 0
</Plugin>

```

`rrdtool`插件是一个写插件，用于将`rrd`文件写入本地磁盘。一旦你启动 Collectd 服务，你会看到许多文件在`/var/lib/collectd/rrd`中被创建。虽然这对于小型系统来说很好，但是它不能很好地扩展，并且在系统使用量很大的情况下，会影响磁盘性能。这就是为什么许多人已经从这个系统转移到其他公制存储和收集系统，如石墨，它将很快取代它。

```
<Include "/etc/collectd/collectd.conf.d">
    Filter "*.conf"
</Include>

```

最后，我们有一个 include 语句，它表示将所有以`.conf`后缀结尾的文件包含在`/etc/collectd/collectd.conf.d`目录中。

#### 开始和停止收集 d

启动和停止 Collectd 也非常简单。在 Ubuntu 和 CentOS 上，您可以发出以下命令:

```
$ sudo systemctl start collectd
$ sudo systemctl status collectd
$ sudo systemctl enable collectd

```

在前面几行中，我们已经启动了 Collectd，检查了状态，并在启动时启用了它。成功的状态输出如下所示:

```
-- Unit collectd.service has begun starting up.
Nov 15 21:55:26 backup collectd[8000]: plugin_load: plugin "syslog" successfully loaded.
Nov 15 21:55:26 backup collectd[8000]: plugin_load: plugin "cpu" successfully loaded.
Nov 15 21:55:26 backup collectd[8000]: plugin_load: plugin "interface" successfully loaded.
Nov 15 21:55:26 backup collectd[8000]: plugin_load: plugin "load" successfully loaded.
Nov 15 21:55:26 backup collectd[8000]: plugin_load: plugin "memory" successfully loaded.
Nov 15 21:55:26 backup collectd[8000]: plugin_load: plugin "mysql" successfully loaded.
Nov 15 21:55:26 backup collectd[8000]: plugin_load: plugin "rrdtool" successfully loaded.
Nov 15 21:55:26 backup collectd[8000]: Systemd detected, trying to signal readyness.
Nov 15 21:55:26 backup collectd[8000]: Initialization complete, entering read-loop.
Nov 15 21:55:26 backup systemd[1]: Started Collectd statistics daemon.
-- Subject: Unit collectd.service has finished start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit collectd.service has finished starting up.
--
-- The start-up result is done.
Nov 15 21:55:26 backup collectd[8000]: mysql plugin: Successfully connected to database <none> at server Localhost via UNIX socket with cipher <none> (server version: 5.5.50-MariaDB, protocol version: 10)

```

您可以看到我们已经成功地连接到我们的数据库。如果有任何问题，您应该检查`systemctl`状态或`syslog`。

现在我们已经成功地设置好了，我们将看看如何设置 Graphite，这样我们就可以收集指标并集中存储它们。

### 石墨

根据网站上的说法，Graphite 只做三件事:踢屁股，嚼泡泡糖，让存储和绘制度量变得容易。我们没有资格验证前两种说法，但第三种说法是正确的。

石墨有四种成分。

*   Carbon:接收时序数据的高性能监听器
*   Whisper:度量数据的时间序列数据库
*   Graphite-web:一个呈现图形和仪表板的 web UI
*   Graphite-API:从时序 Whisper 数据库获取 JSON 数据的 API

在本练习中，我们将安装 Carbon、时序 Whisper 数据库和 Graphite-API。我们将使用 Grafana 来显示我们的指标(在下一节中),因此不需要安装 Graphite-web。

碳组件由碳继电器、碳聚合器和碳缓存组成。我们有兴趣安装碳缓存和碳继电器。所有这三个组件都有助于扩展碳服务，以支持每秒收集数千个指标。

carbon-cache 是一个必需的组件，它构成了基本的集合模型、carbon-cache、Whisper 和 Graphite-API。它能够监听 UDP 或 TCP 端口(2003、2004、2007)，并支持 Python pickle 和换行符分隔的格式。carbon-cache 还配置数据在 Whisper 数据库中的存储方式。您可以基于某些度量模式存储不同的保留期。这些被称为存储模式。

carbon-relay 用于根据指标模式向某些后端服务器发送指标。有两种方式可以使用 carbon-relay，一种是将请求分片(使用一致散列)到多个后端，另一种是复制，将指标发送到任意数量的不同 carbon-cache 服务器或聚合器。

carbon-aggregator 用于缓冲以 carbon-cache 为目的地的指标，以帮助减少 I/O。可以对指标进行平均或求和，并作为单个指标推送到 Whisper，从而减少 carbon-cache 和 Whisper 数据库上的 I/O。

Whisper 是一个时间序列数据库，用于长期存储您的指标数据。它是用 Python 编写的，允许高精度数据分辨率随着时间的推移而降低。当数据降级时，数据点被“汇总”或聚合。您可以选择使用以下函数进行聚合:

*   平均(默认)
*   总额
*   最大
*   福建话
*   最后的

您可以在这里找到有关 Whisper 的更多信息:

*   [T2`http://graphite.readthedocs.io/en/latest/whisper.html`](http://graphite.readthedocs.io/en/latest/whisper.html)

Note

有许多后端时间序列数据库可以用来代替 Whisper。这里列举了一些: [`https://graphite.readthedocs.io/en/latest/tools.html#storage-backend-alternates`](https://graphite.readthedocs.io/en/latest/tools.html#storage-backend-alternates) 。

Graphite-web 是查看数据的一种方式。它是一个 Python 应用程序，需要数据库的支持，可以是 SQLite(用于非常小的部署)、MariaDB 或 PostgreSQL。它还支持 LDAP 认证。

如果您想通过不同的图形表示服务来表示您的指标，您只需安装 Graphite-API，它将返回对指标查询的 JSON 响应。这为来自任意数量的第三方图形 web UIs 的度量提供了一个更轻量级的无状态界面。

#### 石墨装置

使用公共打包工具 YUM 和 Apt，或者通过 Pip(Python 打包工具)，可以很容易地安装 Graphite 组件。

在 CentOS 上，您可以安装 Graphite 和以下组件:

```
$ sudo yum install -y python-carbon

```

这将安装 carbon-cache 和 Whisper 数据库(python-whisper)。Graphite-API 是通过`graphite-api`包安装的。

```
$ sudo yum install –y graphite-api

```

在 Ubuntu 上，你需要安装以下软件来安装 carbon-cache 和 Whisper:

```
$ sudo aptitude install -y graphite-carbon

```

同样，要安装 Graphite-API 组件，您需要发出以下命令:

```
$ sudo aptitude install –y graphite-api

```

另一种方法是安装和试验石墨。Graphite 的开发者提供了一种快速安装和配置它的方法。

*   [T2`https://graphite.readthedocs.io/en/latest/install-synthesize.html`](https://graphite.readthedocs.io/en/latest/install-synthesize.html)

在撰写本文时，这将启动一个浮动的 Ubuntu 14.04，并安装 Graphite 软件的 0.9.5 版本。您将拥有一个快速启动并运行的环境，并开始对其进行测试。

#### 配置碳缓存

石墨的大部分配置是在我们如何配置碳缓存。我们使用相同的文件来配置 carbon 缓存、聚合器和中继。为了实现这一点，可以将文件分成几个部分:`[cache]`、`[aggregator]`和`[relay]`。这个配置文件经过了很好的注释，是您可以使用的选项的真实来源。

Carbon-cache 和 carbon-relay 可以在同一个实例上运行；聚合器应该是一个独立的主机。在本练习中，我们将配置碳缓存和碳中继。

首先，我们将配置碳缓存。我们可以在`[cache]`部分配置通用或全局选项。

```
[cache]
STORAGE_DIR    = /var/lib/graphite/
LOCAL_DATA_DIR = /var/lib/graphite/whisper/
CONF_DIR       = /etc/carbon/
LOG_DIR        = /var/log/carbon/
PID_DIR        = /var/run/
ENABLE_LOGROTATION = False
USER = _graphite

```

在这里，我们将描述存储或检索数据和服务内务的一般配置。这里需要注意的是`USER`在 CentOS 上将是 carbon，`_graphite`在 Ubuntu 上将是 carbon。这些也必须为`[relay]`和`[aggregator]`部分设置。下一节将进一步描述该服务。在清单[中，17-4](#Par183) 是随软件包一起安装的默认设置；这两个发行版是相同的。

```
ENABLE_UDP_LISTENER = False
UDP_RECEIVER_INTERFACE = 0.0.0.0
MAX_CACHE_SIZE = inf
MAX_UPDATES_PER_SECOND = 500
MAX_CREATES_PER_MINUTE = 50
CACHE_WRITE_STRATEGY = sorted
WHISPER_AUTOFLUSH = False
WHISPER_FALLOCATE_CREATE = True
USE_FLOW_CONTROL = True
LOG_LISTENER_CONNECTIONS = True
LOG_UPDATES = False
LOG_CACHE_HITS = False
LOG_CACHE_QUEUE_SORTS = True
USE_INSECURE_UNPICKLER = False
Listing 17-4.Default Carbon-Cache Settings

```

首先，缺省情况下禁用 UDP 监听器，将 TCP 监听器保留为缺省状态。然后我们有一些缓存写的设置。`MAX_CACHE_SIZE`设置为`inf`，或者无穷大。如果您看到大量交换或 CPU 受限的进程，您应该限制这种情况。随着缓存大小的增长，缓存的排序和查询变得越来越昂贵。`MAX_UPDATES_PER_SECOND`和`MAX_CREATES_PER_MINUTE`被设置为限制高磁盘 I/O 争用。

`CACHE_WRITE_STRATEGY`可以有三种可能的设置。

*   `sorted`(默认):数据点作为有序列表刷新到磁盘。
*   `max`:频繁更新的数据点被刷新到磁盘，不频繁的数据点将在关机或磁盘 I/O 低的时候被刷新(如果有的话)。
*   `naive`:数据点在无序列表中刷新。

在`carbon.conf`文件的注释中有关于这些设置的更多细节。`WHISPER_AUTOFLUSH`和`WHISPER_FALLOCATE_CREATE`与内核选项有关。`WHISPER_AUTOFLUSH`设置为`True`将导致 Whisper 同步写入，由 carbon-cache 处理，`WHISPER_FALLOCATE_CREATE`(仅限 Linux)可以加速文件创建(因此允许您增加`MAX_CREATES_PER_MINUTE`)。

将`USE_FLOW_CONTROL`设置为`True`(默认)意味着如果达到`MAX_CACHE_SIZE`，carbon-cache 将停止接受连接，直到缓存低于 95%。

接下来，我们有一组日志选项。将这些设置为`True`会产生高 I/O，如果您需要进一步调查问题，应该将其打开和关闭；我们保留了默认设置。

最后，在清单 [17-4](#Par183) 中，有一个选项允许旧的和不太安全的版本 unpickler，`USE_INSECURE_UNPICKLER = False`。除非你有非常强烈的需求，否则就让它保持原样。

在下一节中，我们将定义碳缓存服务的接口和端口:

```
LINE_RECEIVER_INTERFACE = 0.0.0.0
PICKLE_RECEIVER_INTERFACE = 0.0.0.0
CACHE_QUERY_INTERFACE = 0.0.0.0
LINE_RECEIVER_PORT = 2003
PICKLE_RECEIVER_PORT = 2004
CACHE_QUERY_PORT = 7002

```

在这里，您可以让您的监听器监听某些 IP 地址(IP v4)；您应该将端口保留为这里的默认值。行接收器支持换行符分隔的格式(这意味着换行符表示度量的结束)。pickle 接收器支持 Python pickle 对象序列化( [`https://docs.python.org/3/library/pickle.html`](https://docs.python.org/3/library/pickle.html) )。

您可以通过多个缓存声明来提高碳缓存的性能。类似于`[cache:1]`的声明指定了不同的接收端口，如下所示:

```
[cache:1]
LINE_RECEIVER_PORT = 2103
PICKLE_RECEIVER_PORT = 2104

```

如果您在一个有几个 CPU 的主机上运行，那么每个 CPU 可以有一个碳缓存。

碳缓存的最后一部分是我们在 Whisper 数据库中存储指标数据的方式。我们通过 file / `etc/carbon/storage-schemas.conf`做到这一点。该文件可能如下所示:

```
[carbon]
pattern = ^carbon\.
retentions = 60s:90d

[default_1min_for_1day]
pattern = .*
retentions = 60s:1d

```

不同的指标可以有不同的保留期。你在给它们一个`[name]`之后定义它们。您可以看到，我们可以匹配与模式`^carbon\.`相匹配的指标(即以单词 carbon 开头的指标)。碳本身产生的指标可能是这样的:

```
carbon.agents.host1.cache.queries

```

对于此模式，我们可以看到它们具有 60 秒的分辨率，并以此分辨率存储 90 天(`frequency:retention`)。默认情况下，我们将在 1 天内以一分钟的分辨率记录所有指标，作为一个总括收集器。

假设我们想从数据库中收集指标。从数据库之类的地方收集指标会产生大量数据，因此我们可以相应地更改频率和保留时间。例如，您可以选择如下内容:

```
[database_metrics]
pattern = ^collectd_(db|backup)_*
retentions = 15s:7d,1m:90d,15m:180d

```

在这里，我们基于模式`collectd_`选择指标，后跟`db_`或`backup_`，我们将在 7 天内保持 15 秒的频率，90 天内保持 1 分钟，180 天内保持 15 分钟。这意味着，默认情况下，我们的 15 秒指标将在 7 天后的一分钟内取平均值，失去了精确的分辨率。这将持续到第 90 天，届时它们将在 15 分钟内再次被平均化。

您可能需要更新防火墙，以允许访问端口 2003 和 2004。这就是配置一个基本碳缓存所需的全部内容。

#### 配置碳继电器

在本节中，我们将配置碳继电器。在小型网络中，您不需要这样做，因为单个 Graphite carbon-cache 可以管理每台主机的大量指标。在这个场景中，我们的主机将在端口 2013 上向我们的`relay.example.com`主机发送它们的指标(这是一个行分隔的接收器)。从那里，我们将把指标发送到我们的`monitor.example.com`主机，它有一个 carbon-cache 守护进程监听端口 2004。

配置碳继电器需要一个`carbon.conf`文件和一个名为`relay-rules.conf`的文件。看一看`carbon.conf`，你会看到我们有一个`[cache]`部分，类似于我们之前看到的碳缓存配置。

```
[cache]
STORAGE_DIR    = /var/lib/graphite/
LOCAL_DATA_DIR = /var/lib/graphite/whisper/
CONF_DIR       = /etc/carbon/
LOG_DIR        = /var/log/carbon/
PID_DIR        = /var/run/
ENABLE_LOGROTATION = False
USER = carbon
LOG_LISTENER_CONNECTIONS = True
USE_INSECURE_UNPICKLER = False
USE_FLOW_CONTROL = True
CACHE_WRITE_STRATEGY = sorted

```

接下来，我们将创建一个`[relay]`部分。

```
[relay]
LINE_RECEIVER_INTERFACE = 0.0.0.0
PICKLE_RECEIVER_INTERFACE = 0.0.0.0
LINE_RECEIVER_PORT = 2013
PICKLE_RECEIVER_PORT = 2014
DESTINATIONS = monitor.example.com:2004
LOG_LISTENER_CONNECTIONS = True
RELAY_METHOD = rules
MAX_DATAPOINTS_PER_MESSAGE = 500
MAX_QUEUE_SIZE = 10000
QUEUE_LOW_WATERMARK_PCT = 0.8
USE_FLOW_CONTROL = True

```

它的设置类似于碳缓存。我们将监听端口 2013(行分隔指标)和 2014 (pickle 格式)。对于碳接力，我们需要为我们的指标提供一个(或多个)目的地。如果像我们一样使用`RELAY_METHOD`规则，那么您需要指定您在`relay-rules.conf`文件中列出的每个碳缓存。`relay-rules.conf`文件是基于特定匹配模式的中继目的地的有序列表。我们将很快讨论这一点，但现在我们将包括`monitor.example.com`目的地，因为我们正在讨论碳中继到碳缓存，我们将使用 pickle 端口。

`MAX_DATAPOINTS_PER_MESSAGE`、`MAX_QUEUE_SIZE`、`QUEUE_LOW_WATERMARK_PCT`和`USE_FLOW_CONTROL`是流量控制的选项。`MAX_QUEUE`和`MAX_DATAPOINTS`应谨慎调整。`LOW_WATERMARK`意味着如果队列超过 80 %,我们将停止接受指标。

`relay-rules.conf`文件使我们能够将某些指标指向特定的碳缓存目的地。每个规则都需要一个唯一的名称、一个模式、一个目的地，以及我们是否在这个规则之后继续处理。在我们的示例中，我们使用了一个简单的`relay-rules.conf`文件，如下所示:

```
[default]
default = true
destinations = monitor.example.com:2004

```

带`default = true`的规则只能有一个。默认情况下，我们将所有指标发送到端口 2004 上的`monitor.example.com`。假设我们想将指标从`backup.example.com`发送到不同的碳缓存，我们可以这样做:

```
[backup_example]
pattern = ^collectd_backup_example_com\.*
destination = 192.168.0.250:2004
continue = true

```

我们需要将 192.168.0.250 添加到`carbon.conf`文件中的`DESTINATIONS`字段。

你可以像这样在 CentOS 上启动和停止你的碳接力服务:

```
$ sudo systemctl start carbon-relay

```

像 Ubuntu 这样，我们将实例名传递给`systemd`服务:

```
$ sudo systemctl start carbon-relay@default

```

#### 正在更新 Collectd 配置

现在，我们需要对 Collectd 配置进行更改，以便将指标发送到我们的碳继电器。有一个名为`write_graphite`的插件，它会将收集到的指标发送到石墨碳缓存或中继。

配置很简单，如下所示:

```
LoadPlugin write_graphite

<Plugin write_graphite>
  <Node "monitor">
    Host "relay.example.com"
    Port "2013"
    Protocol "tcp"
    ReconnectInterval 0
    LogSendErrors true
    Prefix "collectd_"
    StoreRates true
    AlwaysAppendDS false
    EscapeCharacter "_"
  </Node>
</Plugin>

```

这与我们之前看到的插件格式相同。在节点块中，我们正在设置中继主机和端口。我们还可以在度量标准和后缀中添加前缀。这里我们添加了`collectd_`作为每个指标的前缀，以便更容易地跟踪指标的来源。

我们现在可以重新启动 Collectd，服务和指标应该开始通过中继发送到监控服务器。但是，如果运行 CentOS，如果不修改 SELinux，将无法向端口 2013 发送指标。

您可以发出以下命令，允许 Collectd 使用`tcp`连接到网络:

```
$ sudo getsebool collectd_tcp_network_connect
collectd_tcp_network_connect --> off
$ sudo setsebool collectd_tcp_network_connect on

```

您还应该检查`/var/log/audit/audit.log`是否有任何被拒绝的消息。

#### 检查日志

一旦我们重新启动了 carbon-cache、carbon-relay 和 collectd 服务，您应该会在日志中看到它们与服务的连接。

Collectd 将记录到我们配置中的 syslog，Graphite 将记录到`/var/log/carbon`目录。看看 Collectd，我们希望在日志中看到以下内容:

```
Nov 22 23:19:06 backup collectd[5999]: plugin_load: plugin "write_graphite" successfully loaded.

```

在我们的中继主机上，我们希望看到我们的主机在`/var/log/carbon/listener.log`中连接到我们。

```
22/11/2016 12:29:56 :: MetricLineReceiver connection with 192.168.0.30:38309 established

```

然后在我们的监控主机上，我们希望在`/var/log/carbon/listener.log`中看到这个。

```
20/11/2016 10:19:03 :: MetricPickleReceiver connection with 192.168.0.251:52146 established

```

因此，我们可以从日志中看到，我们正在备份主机上运行的 Collectd 服务与我们的中继和监视器之间建立连接。现在，我们将快速检查是否正在为我们的备份主机创建指标。监控主机上的`/var/log/carbon/creates.log`文件将显示我们是否正在从备份主机获取指标。

```
21/11/2016 11:35:48 :: new metric collectd_backup_example_com.cpu-0.cpu-user matched schema default_1min_for_1day

```

在这里，您可以看到我们为 CPU 创建了一个指标。好了，现在我们在备份主机上生成指标，并通过中继发送到我们的监视器。现在让我们设置我们的 Graphite-API 服务，这样我们就可以使用 Grafana 来查看它们。

#### 配置 Graphite-API

正如我们已经说过的，Graphite-API 是 Graphite 的轻量级前端。它允许应用程序从我们的碳缓存中查询指标。要运行它，我们需要其他组件，Gunicorn 和 Nginx。

Gunicorn 是 unicorn 项目的 Python 分支，unicorn 是一个 web 服务器网关接口，支持许多 Ruby on Rails 应用程序。我们将用它将 Nginx web 服务器请求粘合到 Graphite-API 应用程序。

Nginx 我们已经简单谈过了。它是一个非常快速、低资源的 web 服务器，将位于 Gunicorn 的前面，并将 web 请求传递给它。我们将使用 Nginx 作为应用程序的代理服务。

##### 设置 Gunicorn

我们将建立 Gunicorn 来为我们的 Graphite-API 应用程序服务。为此，我们将让它启动我们的应用程序，在一个环回接口上监听，并在一个特定的端口上监听。这将允许 Nginx 将请求代理到这个端口并提供响应。

我们可以通过`pip`命令安装 Gunicorn，这是 Python 包管理器。在 Ubuntu 上，我们需要使用`pip3`或 pip 的第 3 版来安装 Gunicorn，因为 Graphite-API 是 Python 3 安装的。在 CentOS 上，标准的`pip`命令就足够了，因为它是 Python 2.7 版本。

```
$ sudo pip3 install gunicorn

```

同样，特别是对于 Ubuntu，我们将为`/usr/local/bin/gunicorn`创建一个符号链接作为`/usr/bin/gunicorn`。这将使我们能够为 Ubuntu 和 CentOS 编写一个`systemd`服务文件。

```
$ ln –s /usr/local/bin/gunicorn /usr/bin/gunicorn

```

现在我们将创建`systemd`文件来启动 Gunicorn 服务。我们将创建一个服务文件和套接字文件，因为我们希望运行一个套接字来连接 Nginx。您可能还记得，本地的`systemd`文件位于`/etc/systemd/system`。我们将创建文件`/etc/systemd/system/graphite-api.socket`。

```
[Unit]
Description=graphite-api socket

[Socket]
ListenStream=/run/graphite-api.sock
ListenStream=127.0.0.1:8881

[Install]
WantedBy=sockets.target

```

这里我们对`systemd`说，创建一个套接字`/run/graphite-api.sock`来监听端口 8881 上的环回地址。`WantedBy`将意味着当`socket.target`被激活时这将被启动。

现在查看服务文件`/etc/systemd/system/graphite-api.service`，我们可以看到以下详细信息:

```
[Unit]
Description=Graphite-API service
Requires=graphite-api.socket

[Service]
ExecStart=/usr/bin/gunicorn -b 127.0.0.1:8881 -w2 graphite_api.app:app
Restart=on-failure
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s TERM $MAINPID
PrivateTmp=true

[Install]
WantedBy=multi-user.target

```

这里可以看到我们调用了`gunicorn`命令来启动`graphite_api.app`。我们要求它连接到端口 8881 上的 127.0.0.1。我们还要求`graphite-api.socket`。`–w2`表示启动两个工作进程来处理请求。

我们现在可以使用`systemctl`命令来启动和停止服务和套接字。

```
$ sudo systemctl start graphite-api.service

```

你可以在这里阅读更多关于 Gunicorn 的内容:

*   [T2`http://gunicorn.org/`](http://gunicorn.org/)

##### 设置 Nginx

虽然 Gunicorn 是一个 web 服务器，但建议部署在代理服务器之后。代理服务器可以处理成千上万个连接，并充当客户端和 Gunicorn 进程之间的缓冲。

我们需要做的就是将下面的`graphite.conf`文件放在 Nginx 服务器可以找到的地方:

```
upstream graphite {
    server 127.0.0.1:8881 fail_timeout=0;
}

server {
    server_name monitor;
    listen 80;
    root /var/www;

    location / {
        try_files $uri @graphite;
    }

    location @graphite {
        proxy_pass http://graphite;
    }
}

```

使用 Nginx，代理服务器被声明为上游服务器。这是在上游`<name> { .. }`部分声明的。在本节中，我们告诉 Nginx 将对 Graphite 上游服务器的任何请求发送到服务器 127.0.0.1:8881，我们的 Gunicorn 服务器将在那里监听。如果您列出了不止一个后端服务器，Nginx 将在两者之间进行循环调度。

`server { ... }`部分是前端服务器声明。我们提供一个服务器名、我们监听的端口和根路径。根不需要存在，因为所有请求都将传递到后端服务器。我们用`location / { ... }`指令来做这件事。当我们向任何 URI 发出请求时，我们首先尝试返回 URI，然后，如果找不到，我们将请求发送到`@graphite`位置。位置`@graphite { ... }`然后将请求发送到位于`http://graphite`的上游服务器(这是我们在文件顶部声明的上游服务器)。

根据您的发行版，您将执行以下任一操作。在 Ubuntu 上，你将`graphite.conf`放在`/etc/nginx/sites-available/`目录中。然后我们需要创建到`sites-enabled`的符号链接，并像这样启动 Nginx:

```
$ sudo ln –s /etc/nginx/sites-available/graphite.conf /etc/nginx/sites-enabled/graphite.conf
$ sudo systemctl start nginx

```

在 CentOS 上，我们需要将`graphite.conf`放在下面的目录中，`/etc/nginx/conf.d/`。然后我们可以像平常一样启动 Nginx。

```
$ sudo systemctl start nginx

```

默认情况下，这两个发行版都将记录到`/var/log/nginx`。我们可以通过以下方式测试我们的 API 是否正常工作:

```
$ curl -H 'Host: monitor' http://127.0.0.1:80/metrics/find?query=*
[{"text": "carbon", "expandable": 1, "allowChildren": 1, "id": "carbon", "leaf": 0}, {"text": "relay", "expandable": 1, "allowChildren": 1, "id": "relay", "leaf": 0}]

```

这表明我们可以联系 Nginx web 服务器，这将向后端 Gunicorn 服务发出请求，后者将返回我们对指标的查询请求。

### 格拉凡娜

Grafana 是一个可视化 web 应用程序，用于绘制时间序列数据。它可以与各种数据源对话，包括 Graphite-API。使用新创建的指标，您现在可以创建仪表板并显示这些指标。

Grafana 支持 LDAP 认证，并可以使用数据库来存储用户的仪表板。它有一个独立的 web 服务，您可以与之交互。您可以将它安装在本地主机或中央服务器上；它不在本地存储指标数据，而是向后端存储服务发出请求，在我们的例子中是 Graphite。

#### 安装 Grafana

我们将在我们的 Ubuntu 服务器上安装 Grafana。我们从这里开始要按照指示: [`http://docs.grafana.org/installation/debian`](http://docs.grafana.org/installation/debian) 。可以按照这里的说明进行 CentOS: [`http://docs.grafana.org/installation/rpm/`](http://docs.grafana.org/installation/rpm/) 。也可以在 macOS 或 Windows 上安装 Grafana。

首先，我们将添加 Grafana 存储库。

```
$ sudo bash -c 'echo "deb https://packagecloud.io/grafana/stable/debian/ jessie main" > /etc/apt/sources.list.d/grafana.list'
$ curl https://packagecloud.io/gpg.key | sudo apt-key add -
$ sudo aptitude update
$ sudo aptitude install –y grafana

```

一旦安装完毕，我们就可以启动 Grafana 服务了。这对于 Ubuntu 和 CentOS 都是一样的:

```
$ sudo systemctl start grafana-server

```

现在我们可以通过以下网址访问 Grafana:`http://monitor:3000`。默认情况下，用户名和密码是 admin(图 [17-9](#Fig9) )。

![A185439_2_En_17_Fig9_HTML.jpg](A185439_2_En_17_Fig9_HTML.jpg)

图 17-9。

Logging into Grafana

#### 添加存储后端

在我们可以绘制任何新收集的指标之前，我们需要添加我们的石墨后端。我们需要将其添加为数据源(图 [17-10](#Fig10) )。

![A185439_2_En_17_Fig10_HTML.jpg](A185439_2_En_17_Fig10_HTML.jpg)

图 17-10。

Selecting data sources

从数据源屏幕，我们点击绿色的“添加数据源”按钮，并填写详细信息(图 [17-11](#Fig11) )。

![A185439_2_En_17_Fig11_HTML.jpg](A185439_2_En_17_Fig11_HTML.jpg)

图 17-11。

Adding Graphite as our data source

点击 Save & Test 将尝试向我们的 Graphite 主机发出一个请求，并测试它是否可以获得适当的数据。如果我们单击 Dashboards 选项卡，我们将导入 Graphite metrics 仪表板(图 [17-12](#Fig12) )。

![A185439_2_En_17_Fig12_HTML.jpg](A185439_2_En_17_Fig12_HTML.jpg)

图 17-12。

Clicking Import

导入仪表板后，您可以点击石墨碳指标，您将看到图 [17-13](#Fig13) 。

![A185439_2_En_17_Fig13_HTML.jpg](A185439_2_En_17_Fig13_HTML.jpg)

图 17-13。

Carbon Metrics graph

让我们通过选择新建来创建一个新的仪表板，如图 [17-14](#Fig14) 所示。

![A185439_2_En_17_Fig14_HTML.jpg](A185439_2_En_17_Fig14_HTML.jpg)

图 17-14。

Creating a new graph

创建仪表板时，左侧会出现一个绿色栏。然后选择添加面板和图形，如图 [17-15](#Fig15) 所示。

![A185439_2_En_17_Fig15_HTML.jpg](A185439_2_En_17_Fig15_HTML.jpg)

图 17-15。

From the left drop-down, select Graph

当您添加一个面板时，您会得到一个基于假数据的测试度量图(图 [17-6](#Fig6) )。

![A185439_2_En_17_Fig16_HTML.jpg](A185439_2_En_17_Fig16_HTML.jpg)

图 17-16。

Test metric

要创建我们自己的图表，我们必须首先选择数据源。就这么办吧，如图 [17-17](#Fig17) 所示。

![A185439_2_En_17_Fig17_HTML.jpg](A185439_2_En_17_Fig17_HTML.jpg)

图 17-17。

Selecting the Panel data source

一旦我们选择了数据源，测试数据就会消失。您可以单击“选择指标”并选择您想要绘制的指标的来源。我们已经选择了“collectd_backup_example_com”，然后我们可以选择我们感兴趣的指标。我们将从列表中选择“加载”。然后，我们选择所有可用的指标(`*`)，然后再次选择(`*`)。在图 [17-18](#Fig18) 中，您可以看到我们在 15 分钟内跟踪了主机的负载。你可以在 Grafana 的这个 YouTube 教程中看到更多关于 Grafana 的内容: [`https://youtu.be/1kJyQKgk_oY`](https://youtu.be/1kJyQKgk_oY) 。

![A185439_2_En_17_Fig18_HTML.jpg](A185439_2_En_17_Fig18_HTML.jpg)

图 17-18。

Seeing load metrics on backup host

既然您已经收集并发现了您的度量标准，那么您就可以进行性能调整，并能够测量它们的效果。

## 性能优化

安装您的主机时，它的默认设置可为大多数配置提供合理的性能。但是，由于每个主机都不同，您通常可以调整设置，使配置对于特定的工作负载来说更加优化。

在本节中，我们将向您展示一些提示和技巧，它们应该有助于加快您的主机执行大多数与服务器相关的任务的速度。

### 资源限制

Linux 允许您通过`ulimit`命令对用户实施资源限制。这实际上是 Bash shell 的一个内置函数。通过该命令设置的任何限制仅适用于当前 shell 及其启动的进程。

要报告当前限值，运行带有`-a`选项的`ulimit`，如图 [17-19](#Fig19) 所示。

![A185439_2_En_17_Fig19_HTML.jpg](A185439_2_En_17_Fig19_HTML.jpg)

图 17-19。

ulimit -a

为了防止这个 shell 用户运行 fork bomb，您可以使用`-u`选项更改正在运行的进程的最大数量，例如从 3909 更改为 1。如果您试图运行一个新的进程，系统会阻止您这样做。

```
$ ulimit -u 1
$ ls
bash: fork: Resource temporarily unavailable

```

您会收到一个错误，指出 shell 无法派生您尝试运行的命令。我们并不建议您以这种方式管理用户，而是演示该命令的效果。

Caution

如果您通过 SSH 或 X 登录，您将已经有几个正在运行的进程。

其他有用的限制是最大内存大小，可以通过`-m`选项设置，以及打开文件的数量，可以通过`-n`设置。针对资源限制进行调优时，最常见的更改是用户可以打开的文件数量。

您可以在`man bash`页面的`ulimit`部分获得选项及其功能的完整列表。

#### 为所有用户设置限制

`ulimit`命令为当前 shell 设置限制，因此您可以通过`/etc/profile`或`/etc/bashrc`为登录的用户添加限制。然而，大多数守护进程不使用 shell，因此向 shell 配置文件添加限制不会有任何效果。

您可以使用 PAM 的`limits`模块。当用户创建一个新流程时，这个模块被调用，它设置您可以在`/etc/security/limits.conf`中定义的限制。该文件为用户和组定义了软限制和硬限制。我们在图 [17-20](#Fig20) 中包含了 CentOS 的样本`limits.conf`。

![A185439_2_En_17_Fig20_HTML.jpg](A185439_2_En_17_Fig20_HTML.jpg)

图 17-20。

Setting limits for all users

每一行指定该限制适用的域。该域可以是通配符、用户名或组名。接下来是限制类型，可以是软的，也可以是硬的。硬限制只能由 root 用户设置，当用户或进程试图突破此限制时，系统会阻止。用户可以使用`ulimit`命令调整软限值，但只能增加到硬限值。

接下来是资源是有限的。可用资源的完整列表包含在示例文件中，也可以在`man limits.conf`页面上找到。每行的最后一个是限值应该设置的值。以`#`开头的行是注释或例子。

在示例文件中，`@faculty`组被允许根据它们的软限制运行 20 个并发进程(`nproc`)。但是，该组中的任何成员都可以将该限制更改为不超过 50 的任何值，但不能高于该值。

### sysctl 和 proc 文件系统

我们在第 9 章中简单提到了 proc 文件系统，作为一种直接从内核获取系统信息的方式。它还提供了一种调整正在运行的内核以提高系统性能的方法。为此，您可以在`/proc/sys`目录下的虚拟文件中更改值。

虚拟文件根据它们影响的系统部分分组在子目录中，如表 [17-2](#Tab2) 所列。

表 17-2。

/proc/sys Subdirectories

<colgroup><col> <col></colgroup> 
| 目录 | 使用人 |
| --- | --- |
| 踝肱指数 | 系统仿真(例如，在 64 位主机上运行 32 位应用程序)。 |
| 秘密党员 | 与加密相关的信息，如密码、模块等。 |
| 调试 | 这是一个空目录；没用过。 |
| 偏差 | 设备特定的信息。 |
| 满量程 | 文件系统设置和调整。 |
| 核心 | 内核设置和调优。 |
| 网 | 网络设置和调谐。 |
| sun RPC(sun RPC) | Sun 远程过程调用(NFS)设置。 |
| 伏特计 | 内存、缓冲区和缓存设置和调整。 |

我们不会详细讨论每个文件，但是我们会给你一个可以做的调整的概念。

每个虚拟文件包含一个或多个可以通过`cat`或`sysctl`实用程序读取的值。要列出所有当前设置，我们可以使用以下内容:

```
$ sysctl –a
abi.vsyscall32 = 1
crypto.fips_enabled = 0
debug.exception-trace = 1
debug.kprobes-optimization = 1
dev.hpet.max-user-freq = 64
dev.mac_hid.mouse_button2_keycode = 97
...
vm.percpu_pagelist_fraction = 0
vm.stat_interval = 1
vm.swappiness = 30
vm.user_reserve_kbytes = 29608
vm.vfs_cache_pressure = 100
vm.zone_reclaim_mode = 0

```

要读取特定的值，将其键作为参数传递给`sysctl`。

```
$ sudo sysctl vm.swappiness
vm.swappiness = 30

```

关键是文件的完整路径，去掉了`/proc/sys/`，斜杠也可以替换为句号。例如，为了检查您的主机使用交换内存的可能性，您可以检查`/proc/sys/vm/swappiness`的内容。

```
$ cat /proc/sys/vm/swappiness
30

```

这个特定的值表明，在一段时间没有使用信息之后，内核将信息从 RAM 转移到交换空间的可能性有多大。数字越高，这种可能性越大。在这种情况下，该值的范围为 0 到 100，默认值为 60。如果您想确保您的主机不太可能使用交换内存，您可以通过`sysctl`实用程序和`-w`选项将该值设置为 20。然后，您需要传递想要更改其值的键和新值。

```
$ sudo sysctl -w vm.swappiness=20

```

另一个例子是系统中任何时刻可以打开的文件和目录的数量。这在`/proc/sys/fs/file-max`中定义，您可以通过命令`sysctl fs.file-max`读取该值。要将打开文件的最大数量增加到 50 万，运行`sudo sysctl -w fs.file-max=500000`。

Caution

更改 proc 文件系统中的内核变量不仅会对系统性能产生积极影响，还会产生巨大的负面影响。除非有充分的理由，否则我们建议您不要更改任何内容。一个好的调谐方法是测量、改变、测量。如果你不能测量，就要非常小心。

当系统重新启动时，这些变量被重置为默认值。为了使它们持久化，您可以在`/etc/sysctl.conf`文件中添加一个适当的条目。当系统启动时，该文件中的所有设置都通过`sysctl -p`命令应用于系统。

在 Ubuntu 上，不用直接编辑`/etc/sysctl.conf`，可以在`/etc/sysctl.d/<number>-<option-name>.conf`中创建一个文件，它们会在开机时被读入。

在 CentOS 上，您可以在`/usr/lib/sysctl.d`中找到默认的系统设置。你可以在`/etc/systctl.conf`中覆盖这些，或者在`/etc/sysctl.d/`中放置一个类似 Ubuntu 的文件。

关于`sysctl`设置的更多信息可通过`man sysctl.d`找到。在 [`https://www.kernel.org/doc/Documentation/sysctl/`](https://www.kernel.org/doc/Documentation/sysctl/) 可获得可用变量的完整列表和文档。

### 存储设备

在第 [9](09.html) 章中，您看到了在磁盘故障的情况下，一旦添加了替换磁盘，内核就需要重建 RAID 阵列。此任务会生成大量 I/O，并会降低机器可能提供的其他服务的性能。或者，您可能希望以牺牲服务为代价，优先考虑重建过程。

当重建发生时，内核将重建速度保持在设定的最小值和最大值之间。我们可以通过`/proc/sys/dev/raid`目录中的`speed_min_limit`和`speed_max_limit`条目来改变这些数字。

更可接受的最低速度是每个磁盘每秒 20，000K，您可以使用`sysctl`来设置它。

```
$ sudo sysctl -w dev.raid.speed_limit_min=20000

```

将最小值设置得太高会对系统性能产生负面影响，因此请确保将该值设置得低于系统可以处理的最大吞吐量除以 RAID 阵列中的磁盘数。

通过设置`dev.raid.speed_limit_max`变量可以改变的最大值已经相当高了。如果您希望 RAID 重建对性能的影响更小，以更长的等待时间为代价，您可以降低该数值。

为了使这些更改永久化，将这些键值对添加到`/etc/sysctl.conf`。

### 文件系统调整

每次访问文件或目录时，即使只是为了读取，也需要更新其最后访问的时间戳(或`atime`)并将其写入磁盘。除非您需要这个时间戳，否则您可以通过告诉您的主机不要更新它们来加速磁盘访问。

默认情况下，您的系统应该使用`relatime`选项挂载您的磁盘。此选项意味着每次文件访问不会启动对文件元数据的更新，这通过不发出不必要的操作来提高性能。它是`noatime`的同义词。

如果没有设置，您只需将`noatime`选项添加到您想要启用该选项的每个文件系统的`/etc/fstab`文件的`options`字段中。

```
UUID=f87a71b8-a323-4e8e-acc9-efb0758a0642 / ext4 defaults,
   errors=remount-ro,relatime 0 1

```

这将在下次挂载文件系统时启用该选项。要立即激活它，您可以使用`mount`命令重新挂载文件系统。

```
$ sudo mount -o remount,relatime /

```

除了挂载选项之外，文件系统本身也提供了一些可以提高性能的特性；这取决于特定文件系统的用途。其中最主要的是`dir_index`，它适用于 ext2、ext3 和 ext4 文件系统。启用此功能会导致文件系统创建内部索引，从而加快对包含大量文件或子目录的目录的访问。您可以使用`tune2fs`实用程序来检查它是否已启用。

```
$sudo tune2fs -l /dev/md0 | grep features
Filesystem features: has_journal ext_attr resize_inode dir_index filetype needs_recovery extent 64bit flex_bg
    sparse_super large_file huge_file uninit_bg dir_nlink extra_isize

```

如果你需要改变特性，而你很少这样做，你可以使用`tune2fs`来启用一个特定的特性。

```
sudo tune2fs -O dir_index /dev/md0

```

或者，可以通过在名称前加一个脱字符号来关闭特性。

```
sudo tune2fs -O ^dir_index /dev/md0

```

您可以通过更改`/etc/mke2fs.conf`文件中的默认值来设置应该在各种 ext 文件系统上启用哪些选项。

### 输入输出调度程序

I/O 调度程序，也称为 I/O 电梯，是内核用来对磁盘子系统的 I/O 进行排序的算法。可以更改调度程序来提高该过程的效率。内核有三个调度程序可用。

*   Cfq:这是 SATA 设备的默认调度程序，并试图为处理 I/O 实现完全公平的队列。
*   截止时间:这是块设备的默认调度程序。它优先选择读取请求，并试图通过对开始时间设置一个截止日期来为请求提供确定性。
*   Noop:这是一个先进先出队列，其中 I/O 留给下级子系统排序；它适用于虚拟机。

您可以通过执行类似下面的命令在您的设备上找到调度程序:

```
$ cat /sys/block/sda/queue/scheduler
noop deadline [cfq]

```

`[]`中的调度程序是当前设置。您可以使用以下命令更改它:

```
$ sudo bash -c  'echo deadline > /sys/block/sda/queue/scheduler'
$ cat /sys/block/sda/queue/scheduler
noop [deadline] cfq

```

您可以通过编辑 GRUB 在引导时设置调度程序。您需要通过添加以下内容来编辑以下文件:

```
$ vi /etc/default/grub
GRUB_CMDLINE_LINUX="console=tty0 ... rhgb quiet elevator=deadline"

```

这会将`deadline`设置为整个服务器的默认调度程序。然后，您需要使用以下内容重新制作 GRUB:

```
$ sudo grub2-mkconfig -o /boot/grub2//grub.cfg

```

现在，当您重新启动主机时，默认的调度程序是`deadline`。

```
$ cat /sys/block/sda/queue/scheduler
noop [deadline] cfq

```

记住在 Ubuntu 上`grub2-mkconfig`需要这样:

```
$ sudo grub2-mkconfig -o /boot/grub/grub2.cfg

```

现在，您的更改将在重新启动后保持不变。

## 摘要

在本章中，我们向您展示了简单的工具，这些工具使您能够轻松地确定正在运行的主机的基本健康状况。您学习了如何执行以下操作:

*   检查 CPU 使用率
*   检查内存和交换空间使用情况

我们还引入了更高级的系统指标收集工具，如 Collectd 和 Graphite，它们将帮助您持续监控资源使用和性能。您学习了如何执行以下操作:

*   安装和配置 Collectd
*   安装和配置石墨
*   使用 Grafana 监控和可视化主机的运行状况

我们还提供了一些关于一些常见的性能调优以及如何使用`sysctl`改变内核设置的信息。

在下一章中，您将看到如何配置对您的主机和服务的一些监控。我们还将向您展示如何配置日志记录，以及如何监控异常或可疑活动的日志。