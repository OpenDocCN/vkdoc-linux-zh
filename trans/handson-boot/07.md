# 7.系统(第一部分)

以下是我们目前所知的引导顺序:

1.  引导加载程序在内存中加载内核和 initramfs。

2.  内核将被加载到特定的位置(特定于架构的位置)，而 initramfs 将被加载到任何可用的位置。

3.  内核在`vmlinuz`文件头的帮助下提取自己。

4.  内核在主内存(`init/initramfs.c`)中提取 initramfs，并将其作为临时根文件系统(`/`)安装在主内存中。

5.  内核从临时根文件系统启动(`init/main.c`)systemd 作为第一个进程，使用 PID-1。

6.  systemd 将找到用户的根文件系统并将`chroot`放入其中。

本章将介绍从 initramfs 派生的 systemd 如何挂载用户的根文件系统，我们还将看到 initramfs 中 systemd 的详细引导顺序。但在此之前，我们需要将 systemd 理解为一个过程。

我将让 systemd 的手册页在这里进行讨论:

*   *“找到并挂载根文件系统后，* `initrd` *将控制权移交给存储在根文件系统中的主机的系统管理器(如 systemd(1))，该系统管理器随后负责探测所有剩余的硬件，挂载所有必需的文件系统并生成所有配置的服务。”*

## 结构

systemd 最初是在 Fedora 15 中引入的。我们都知道 systemd 是对`init`脚本的替代(`/sbin/init`现在是`/usr/lib/systemd/systemd`的符号链接),它惊人地减少了引导时间。然而，在现实中，systemd 远不止是`init`的替代品。这就是 systemd 所做的:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

单位

 | 

目的

 |
| --- | --- |
| `systemd.service` | 来管理服务 |
| `systemd.socket` | 创建和管理套接字 |
| `systemd.device` | 根据`udev`的输入创建和使用设备 |
| `systemd.mount` | 要挂载文件系统 |
| `systemd.automount` | 要自动挂载文件系统 |
| `systemd.swap` | 制造和管理交换设备 |
| `systemd.target` | 服务组而不是运行级别 |
| `systemd.path` | 关于由 systemd 监控的路径的信息，用于基于路径的激活 |
| `systemd.timer` | 对于基于时间的激活 |
| `systemd.slice` | 服务单元的资源管理，如 CPU、内存、I/O |

1.  它用`journalctl`维护日志。

2.  它广泛使用 cgroups 版本 1 和 2。

3.  它减少了启动时间。

4.  它管理单元。是 systemd 处理的一种类型的单元。以下是 systemd 提供和管理的单元:

单元文件将从以下三个位置存储和加载:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

小路

 | 

描述

 |
| --- | --- |
| `/etc/systemd/system` | 本地配置 |
| `/run/systemd/system` | 运行时间单位 |
| `/usr/lib/systemd/system` | 已安装软件包的单位 |

`/etc/systemd/system`是一个管理位置，而`/usr/lib/systemd/system`是一个应用程序供应商位置。这意味着如果相同的单元文件出现在两个位置，管理员的位置将优先于应用程序供应商的位置。请注意，在本章中，所有的命令都是从 initramfs 被解压缩的目录中执行的。

```
#  tree etc/systemd/
       etc/systemd/
       ├── journald.conf
       └── system.conf
0 directories, 2 files

#ls usr/lib/systemd/system | column

basic.target                       plymouth-switch-root.service
cryptsetup.target                  poweroff.target
ctrl-alt-del.target                poweroff.target.wants
default.target                     reboot.target
dracut-cmdline-ask.service         reboot.target.wants
dracut-cmdline.service             remote-fs-pre.target
dracut-emergency.service           remote-fs.target
dracut-initqueue.service           rescue.service
dracut-mount.service               rescue.target
dracut-pre-mount.service           rescue.target.wants
dracut-pre-pivot.service           rpcbind.target
dracut-pre-trigger.service         shutdown.target
dracut-pre-udev.service            sigpwr.target
emergency.service                  slices.target
emergency.target                   sockets.target
emergency.target.wants             sockets.target.wants
final.target                       swap.target
halt.target                        sysinit.target
halt.target.wants                  sysinit.target.wants
initrd-cleanup.service             sys-kernel-config.mount
initrd-fs.target                   syslog.socket
initrd-parse-etc.service           systemd-ask-password-console.path
initrd-root-device.target          systemd-ask-password-console.service
initrd-root-fs.target              systemd-ask-password-console.service.wants
initrd-switch-root.service         systemd-ask-password-plymouth.path
initrd-switch-root.target          systemd-ask-password-plymouth.service
initrd-switch-root.target.wants    systemd-ask-password-plymouth.service.wants
initrd.target                      systemd-fsck@.service
initrd.target.wants                systemd-halt.service
initrd-udevadm-cleanup-db.service  systemd-journald-audit.socket
kexec.target                       systemd-journald-dev-log.socket
kexec.target.wants                 systemd-journald.service
kmod-static-nodes.service          systemd-journald.socket
local-fs-pre.target                systemd-kexec.service
local-fs.target                    systemd-modules-load.service
multi-user.target                  systemd-poweroff.service
multi-user.target.wants            systemd-random-seed.service
network-online.target              systemd-reboot.service
network-pre.target                 systemd-sysctl.service
network.target                     systemd-tmpfiles-setup-dev.service
nss-lookup.target                  systemd-tmpfiles-setup.service
nss-user-lookup.target             systemd-udevd-control.socket
paths.target                       systemd-udevd-kernel.socket
plymouth-halt.service              systemd-udevd.service
plymouth-kexec.service             systemd-udev-settle.service
plymouth-poweroff.service          systemd-udev-trigger.service
plymouth-quit.service              systemd-vconsole-setup.service
plymouth-quit-wait.service         timers.target
plymouth-reboot.service            umount.target
plymouth-start.service

```

第三个位置`/run/systemd/system`是一个临时位置，将由 systemd 在内部用来管理单元。例如，它将在创建套接字时被广泛使用。事实上，`/run`是 systemd 引入的一个单独的文件系统，用于存储运行时数据。到目前为止，initramfs 的`/run`目录是空的，这很明显，因为 initramfs 没有被使用。

```
#ls run/
    <no_output>

```

此外，预计 initramfs 中的单元文件比用户根文件系统中的单元文件要少。dracut 将只收集那些挂载用户根文件系统所必需的 systemd 单元文件。例如，在 initramfs 中添加与 systemd 单元文件相关的`httpd`或`mysql`是没有意义的。我们来试着了解一下 systemd 的`service`单元文件之一，如下图:

```
# cat /usr/lib/systemd/system/sshd.service
[Unit]
Description=OpenSSH server daemon
Documentation=man:sshd(8) man:sshd_config(5)
After=network.target sshd-keygen.target
Wants=sshd-keygen.target

[Service]
Type=notify
EnvironmentFile=-/etc/crypto-policies/back-ends/opensshserver.config
EnvironmentFile=-/etc/sysconfig/sshd-permitrootlogin
EnvironmentFile=-/etc/sysconfig/sshd
ExecStart=/usr/sbin/sshd -D $OPTIONS $CRYPTO_POLICY $PERMITROOTLOGIN
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=on-failure
RestartSec=42s

[Install]
WantedBy=multi-user.target

```

这个`sshd`服务单元文件将不是 initramfs 的一部分，因为您不需要一个`ssh`服务来挂载用户的根文件系统。`service`单元文件分为三部分:`[unit]`、`[service]`、`[install]`。

*   `[unit]`:

```
After=network.target sshd-keygen.target

```

只有在`network.target`(列出的单位)和`sshd-keygen`(列出的单位)成功启动后，`sshd`服务才会启动。如果其中任何一个失败，那么`sshd`服务也会失败。

```
Wants=sshd-keygen.target

```

这是`Requires.`的一个不太严重的版本，如果`wants`中提到的任何单元出现故障，那么`sshd`服务(或该特定服务)也将启动，而在`Requires`中，只有在`Requires`中提到的单元已经成功启动时，`sshd`服务才会启动。`Before`与`After`相反`Wants`、`After`、`Before`和`Requires`都是相互独立工作的。通常将`Wants`和`After`一起使用。

```
Conflicts=

```

这可用于列出与当前单位冲突的单位。启动此设备可能会停止列出的冲突设备。

```
OnFailure=

```

当任何给定单元达到故障状态时，单元将启动。

*   **【服务】:**

```
ExecStart=/usr/sbin/sshd

```

启动一个`sshd`服务单元只是启动在`ExecStart.`之后提到的二进制

*   **【安装】:**

systemd 不使用单元文件的`Install`部分。而是由`systemctl` `enable`或`disable`命令使用。它将被`systemctl`用来创建或破坏符号链接。

## systemd 如何减少启动时间？

systemd 的创造者 Lennart Poettering 在他的博客 [`http://0pointer.de/blog/projects/systemd.html`](http://0pointer.de/blog/projects/systemd.html) 中给出了 systemd 如何减少启动时间的经典例子。如果你真的想深入 systemd 世界，这个博客是最好的资源之一。

有四个守护进程:`syslog`、`dbus`、`avahi`和`bluetooth`。

每个守护进程都需要记录消息。因此，`syslog`是其他所有守护进程的要求。`avahi`需要`syslog`和`dbus`来运行。`bluetooth`需要`dbus`和`syslog`但不需要`avahi`运行。使用`Sysv/init`脚本模型，会发生这样的情况:

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig1_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig1_HTML.jpg)

图 7-1

初始模型

1.  `syslog`会先开始。

2.  当它完全准备好时，`dbus`服务将被启动。

3.  在`dbus`之后，`avahi`将被启动。

4.  最后会启动`bluetooth`服务。见图 [7-1](#Fig1) 。

`bluetooth`和`avahi`互不依赖，但是`bluetooth`要等到`avahi`启动。类似 Ubuntu 的发行版使用`upstart`而不是`init`，这在一定程度上改善了引导时间。在`upstart`中，互不依赖的服务将并行启动，意味着`avahi`和`bluetooth`将一起启动。请参考图 [7-2](#Fig2) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig2_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig2_HTML.jpg)

图 7-2

暴发户模式

在`systemd,`中，所有的服务都是借助`sockets` `.`同时启动的下面是一个例子:

1.  systemd 将为`syslog`(已经被替换为`journald`)创建一个套接字。

2.  套接字`/dev/log`是到`/run/systemd/journal/dev-log`的符号链接。

    ```
    # file /dev/log
          /dev/log: symbolic link to /run/systemd/journal/dev-log

    # file /run/systemd/journal/dev-log
          /run/systemd/journal/dev-log: socket

    ```

如前所述，`run`文件系统将被 systemd 用来创建套接字文件。

1.  对于`dbus`，套接字是在`/run/dbus/system_bus_socket.`创建运行的，`dbus`需要`journald`才能运行，但由于系统仍在引导，`journald` / `syslog`尚未完全启动，`dbus`会将其消息记录到`journald`的套接字`/dev/log`中，每当`journald`服务完全就绪时，它就会从套接字中获取消息。

2.  It’s the same for the `bluetooth` service ; it needs the `dbus` service to be running to start. So, systemd will create a `/run/dbus/system_bus_socket` socket before the `dbus` service starts. The `bluetooth` service will not wait for `dbus` to start. You can refer to Figure [7-3](#Fig3) for a better understanding.

    ![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig3_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig3_HTML.jpg)

    图 7-3

    系统模型

3.  如果`systemd`创建的套接字用完了缓冲区，那么`bluetooth`服务将被阻塞，直到套接字可用。这种套接字方法将大大减少启动时间。

这种基于套接字的方法最初是在 macOS 中尝试的。当时叫`launchd`。Lennart Poettering 从中获得了灵感。

### 系统 d-分析

systemd 提供了`systemd-analyze`工具来检查系统启动所需的时间。

```
# systemd-analyze
Startup finished in 1.576s (kernel) + 1.653s (initrd) + 11.574s (userspace) = 14.805s
graphical.target reached after 11.561s in userspace

```

你可以看到，我的 Fedora 系统初始化内核用了 1.5 秒；然后，它在 initramfs 中花了 1.6 秒，花了将近 11 秒来启动服务或初始化用户空间。总时间几乎是 15 秒。总时间是从引导装载程序到图形目标计算出来的。

以下是一些重要的注意事项:

*   总时间不包括 GNOME、KDE、Cinnamon 等桌面环境所花费的时间。这也是有意义的，因为桌面环境不是由 systemd 处理的，所以 systemd 工具不能计算桌面环境所花费的时间。

*   此外，由于 systemd 的套接字方法，服务可能在总时间(14.805 秒)后仍在启动。

因此，为了提供更多的洞察力和干净的数据，`systemd-analyse`提供了一个`blame`工具。

```
# systemd-analyze blame
          31.202s dnf-makecache.service
          10.517s pmlogger.service
          9.264s NetworkManager-wait-online.service
          4.977s plymouth-switch-root.service
          2.994s plymouth-quit-wait.service
          1.674s systemd-udev-settle.service
          1.606s lightdm.service
          1.297s pmlogger_check.service
           938ms docker.service
           894ms dracut-initqueue.service
           599ms pmcd.service
           590ms lvm2-monitor.service
           568ms abrtd.service
           482ms firewalld.service
           461ms systemd-logind.service
           430ms lvm2-pvscan@259:3.service
           352ms initrd-switch-root.service
           307ms bolt.service
           290ms systemd-machined.service
           288ms registries.service
           282ms udisks2.service
           269ms libvirtd.service
           255ms sssd.service
           209ms systemd-udevd.service
           183ms systemd-journal-flush.service
           180ms docker-storage-setup.service
           169ms systemd-journald.service
           156ms polkit.service
           .
           .
           </snip>

```

`blame`输出很容易被误解；即，两个服务可能同时初始化，因此初始化两个服务所花费的时间比两个单独时间的总和少得多。为了获得更精确的数据，您可以使用`systemd-analyse`的`plot`工具，它将生成图表并提供更多关于启动时间的细节。生成的绘图图像如图 [7-4](#Fig4) 所示。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig4_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig4_HTML.jpg)

图 7-4

生成的绘图图像

```
# systemd-analyze plot > plot.svg

# eog plot.svg

```

以下是`systemd-analyse`提供的一些其他工具，可以用来识别引导时间。

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

系统分析

 | 

描述

 |
| --- | --- |
| `time` | 打印在内核中花费的时间 |
| `blame` | 打印按时间排序的运行单元列表至`init` |
| `critical-chain [UNIT...]` | 打印时间关键型单位链的树 |
| `plot` | 输出显示服务初始化的 SVG 图形 |
| `dot [UNIT...]` | 以`dot(1)`格式输出依赖图 |
| `log-level [LEVEL]` | 获取/设置管理器的日志记录阈值 |
| `log-target [TARGET]` | 获取/设置管理器的日志记录目标 |
| `dump` | 服务管理器的输出状态序列化 |
| `cat-config` | 显示配置文件和插件 |
| `unit-files` | 列出设备的文件和符号链接 |
| `units-paths` | 列出设备的装载目录 |
| `exit-status [STATUS...]` | 列出退出状态定义 |
| `syscall-filter [NAME...]` | 打印 seccomp 过滤器中的系统调用列表 |
| `condition...` | 评估条件和资产 |
| `verify FILE...` | 检查单元文件的正确性 |
| `service-watchdogs [BOOL]` | 获取/设置服务监视器状态 |
| `calendar SPEC...` | 验证重复的日历时间事件 |
| `timestamp...` | 验证时间戳 |
| `timespan SPAN...` | 验证时间跨度 |
| `security [UNIT...]` | 分析单元的安全性 |

### “无法启动”问题 6 (systemd)

**问题:**系统成功启动，但启动时`nagios`服务无法启动。

以下是解决此问题的步骤:

1.  我们需要首先隔离问题。当 GRUB 出现在屏幕上时，删除`rhgb quiet`内核命令行参数。

2.  详细日志显示系统能够启动，但是`nagios`服务在启动时无法启动。可以看到，负责网络的 systemd 的`NetworkManager`服务已经成功启动。这意味着这不是网络通信问题。

    ```
    13:23:52   systemd: Starting Network Manager...
    13:23:52   systemd: Started Kernel Samepage Merging (KSM) Tuning Daemon.
    13:23:52   systemd: Started Install ABRT coredump hook.
    13:23:52   abrtd: Init complete, entering main loop
    13:23:52   systemd: Started Load CPU microcode update.
    13:23:52   systemd: Started Authorization Manager.
    13:23:53   NetworkManager[1356]: <info>  [1534389833.1078] NetworkManager is starting... (for the first time)
    13:23:53   NetworkManager[1356]: <info>  [1534389833.1079] Read config: /etc/NetworkManager/NetworkManager.conf (lib: 00-server.conf, 10-slaves-order.conf)
    13:23:53   NetworkManager[1356]: <info>  [1534389833.1924] manager[0x558b0496a0c0]: monitoring kernel firmware directory '/lib/firmware'.
    13:23:53   NetworkManager[1356]: <info>  [1534389833.2051] dns-mgr[0x558b04971150]: init: dns=default, rc-manager=file
    13:23:53   systemd: Started Network Manager.

    ```

3.  `nagios`服务试图在`NetworkManager`服务之后立即执行。这意味着`nagios`在其服役单位档案中一定提到过`after=Network.target`。但是`nagios`服务无法启动。

    ```
    13:24:03   nagios: Nagios 4.2.4 starting... (PID=5006)
    13:24:03   nagios: Local time is Thu  13:24:03 AEST 2018
    13:24:03   nagios: LOG VERSION: 2.0
    13:24:03   nagios: qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
    13:24:03   nagios: qh: core query handler registered
    13:24:03   nagios: nerd: Channel hostchecks registered successfully
    13:24:03   nagios: nerd: Channel servicechecks registered successfully
    13:24:03   nagios: nerd: Channel opathchecks registered successfully
    13:24:03   nagios: nerd: Fully initialized and ready to rock!  Nagios Can't ping devices (not 100% packet loss at the end of each line)
    13:24:04   nagios: HOST ALERT:  X ;DOWN;SOFT;1;CRITICAL -  X: Host unreachable @  X. rta nan, lost 100%

    ```

**解决:**奇怪的是`nagios`错误信息说启动失败是因为无法连接网络，但是根据`NetworkManager`显示已经成功启动，系统已经放入网络。

这个问题显然是由 systemd 的“加速启动过程”方法造成的。要将系统放入网络，systemd 必须做大量的工作:初始化网卡、激活链接、将 IP 放在网卡上、检查是否有任何重复的 IP 可用、开始在网络上通信等。显然，要完成这一切，systemd 需要一些时间。在我的测试系统上，完全填充网络花了将近 20 秒。当然，systemd 不能在这段时间内暂停引导序列。如果 systemd 等待网络完全填充，那么 systemd 加快引导过程的创新的一个主要方面将被破坏。

在`NetworkManager`的帮助下，systemd 将尽最大努力确保我们在网络上，但它不会等待用户指定的网络生成，也不会等到拓扑的每个规则都实现。

在某些情况下，像这种“无法启动”的问题，有可能是`NetworkManager`已经告诉 systemd 初始化`nagios`，这是依赖于`network.target`，但网络尚未完全启动，所以`nagios`可能无法联系其服务器。

1.  为了解决这样的问题，systemd 建议启用`NetworkManager-wait-online.service.`这项服务会让`NetworkManager`一直等到网络完全恢复。一旦网络被完全填充，`NetworkManager`将向 systemd 发送信号，启动依赖于`network.target`的服务。

```
# cat /usr/lib/systemd/system/NetworkManager-wait-online.service
[Unit]
Description=Network Manager Wait Online
Documentation=man:nm-online(1)
Requires=NetworkManager.service
After=NetworkManager.service
Before=network-online.target

[Service]
Type=oneshot
ExecStart=/usr/bin/nm-online -s -q --timeout=30
RemainAfterExit=yes

[Install]
WantedBy=network-online.target

```

这只是调用`nm-online`二进制文件，并将`-s`开关传递给它。这项服务将保持`NetworkManager`最多 30 秒。

这是手册页对 nm-online 的描述:

> *“等待 NetworkManager 启动完成，而不是专门等待网络连接。一旦 NetworkManager 激活(或试图激活)了当前网络状态下可用的每个自动激活连接，启动即被视为完成。(这通常只在启动时有用；启动完成后，不管当前网络状态如何，nm-online -s 都会立即返回。)”*

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig5_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig5_HTML.jpg)

图 7-5

启用网络管理器-等待-在线-服务后的图

1.  启用`NetworkManager-wait-online-service`后，问题已解决，但开机时间略有减少。如图 [7-5](#Fig5) 所示，大部分开机时间已经被`NetworkManager-wait-online-service`吃光了，这是意料之中的。

systemd 提供了另一个工具`bootchart`，它基本上是一个守护进程，通过它可以对 Linux 引导过程进行性能分析。它将在启动时收集数据并制作图表。你可以认为`bootchart`是`systemd-analyze`剧情的高级版本。要使用这个工具，如图 [7-6](#Fig6) 所示，您需要将`systemd-bootchart`二进制文件的完整路径传递给`init`内核命令行参数。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig6_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig6_HTML.jpg)

图 7-6

内核命令行参数

在成功的引导过程后，如图 [7-7](#Fig7) 所示，工具将在`/run/log/bootchart*.`创建一个详细的图形图像。一旦图像生成，`systemd-bootchart`将控制权移交给 systemd，systemd 将继续引导过程。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig7_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig7_HTML.jpg)

图 7-7

引导图表

既然我们现在了解了 systemd 的基础知识，我们可以继续我们暂停的引导序列。到目前为止，我们已经到了内核已经提取 RAM 中的 initramfs 并从中启动 systemd 二进制文件的阶段。一旦 systemd 进程启动，它将遵循常规的引导顺序。

## initramfs 中的系统流

systemd 将从 initramfs 启动，并遵循图 [7-8](#Fig8) 所示的引导顺序。Harald Hoyer(他创建了 dracut initramfs，并且是 systemd 的主要开发人员)创建了这个流程图，它也可以在 systemd 手册页中找到。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig8a_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig8a_HTML.jpg)

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig8b_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig8b_HTML.jpg)

图 7-8

引导流程图

此流程图来自 dracut 的手册页。systemd 在引导过程中的最终目的是在 initramfs ( `sysroot`)中挂载用户的根文件系统，然后切换到其中。一旦 systemd 将`switch_rooted`放入新的(用户的)根文件系统，它将离开 initramfs 环境，并通过启动`httpd`、`mysql`等用户空间服务继续引导过程。如果用户以图形模式启动系统，它还会绘制一个桌面/GUI。本书的范围包括引导序列，直到 systemd 挂载用户的根文件系统，然后切换到它。没有介绍`switch_root`之后的引导序列有几个原因。我将在此提及原因，这些原因非常重要:

*   引导的最终目标是挂载用户的根文件系统并呈现给用户，这一点在本书中有详细介绍。

*   initramfs 之后 systemd 执行的活动很容易理解，因为 systemd 执行类似的活动，但是是在新的根文件系统环境下。

*   生产系统通常不在图形模式下运行。

*   Linux 有几个桌面，如 GNOME、KDE、Cinnamon、Unity 等。每个用户都有自己喜欢的桌面，几乎不可能在启动时记录每个桌面的每一步。

因此，在这种理解下，本章我们将讨论到`basic.target.`的启动序列，请参考图 [7-9](#Fig9) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig9_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig9_HTML.jpg)

图 7-9

直到 basic.target 的引导序列

### 系统日志。socket

每个进程都必须记录它的消息。事实上，只有当进程、服务或守护进程能够在操作系统日志记录机制中记录其消息时，它才会启动。现在的 OS 日志机制是`journald`。因此，显然必须首先启动`journald`服务，但是我们知道，systemd 不会等到服务完全启动。为了加速这个过程，它使用了套接字方法。因此，systemd 必须首先启动`journald`套接字。`journald`服务创建以下四个套接字并监听消息:

*   `systemd-journald.socket`

*   `systemd-journald-dev-log.socket`

*   `systemd-journald-audit.socket`

*   `syslog.socket`

守护程序、应用程序和每个进程都将使用这些套接字来记录它们的消息。

```
# # vim usr/lib/systemd/system/systemd-journald.socket

#  SPDX-License-Identifier: LGPL-2.1+
#
#  This file is part of systemd.
#
#  systemd is free software; you can redistribute it and/or modify it
#  under the terms of the GNU Lesser General Public License as published by
#  the Free Software Foundation; either version 2.1 of the License, or
#  (at your option) any later version.

[Unit]
Description=Journal Socket
Documentation=man:systemd-journald.service(8) man:journald.conf(5)
DefaultDependencies=no
Before=sockets.target

# Mount and swap units need this. If this socket unit is removed by an
# isolate request the mount and swap units would be removed too,
# hence let's exclude this from isolate requests.
IgnoreOnIsolate=yes

[Socket]
ListenStream=/run/systemd/journal/stdout
ListenDatagram=/run/systemd/journal/socket
SocketMode=0666
PassCredentials=yes
PassSecurity=yes
ReceiveBuffer=8M
Service=systemd-journald.service

# cat usr/lib/systemd/system/systemd-journald-dev-log.socket | grep -v '#'
[Unit]
Description=Journal Socket (/dev/log)
Documentation=man:systemd-journald.service(8) man:journald.conf(5)
DefaultDependencies=no
Before=sockets.target

IgnoreOnIsolate=yes

[Socket]
Service=systemd-journald.service
ListenDatagram=/run/systemd/journal/dev-log
Symlinks=/dev/log
SocketMode=0666
PassCredentials=yes
PassSecurity=yes

ReceiveBuffer=8M
SendBuffer=8M

```

我们已经讨论了套接字的工作方式，尤其是`/dev/log`套接字。引导序列的下一步是`dracut-cmdline.service` `.`

### dracut-cmdline.service

初始化`journald`套接字后，systemd 通过`usr/lib/systemd/system/dracut-cmdline.service`收集内核命令行参数，如`root`、`rflags`和`fstype`变量。这也被称为 initramfs 的一个 *cmdline 钩子*，我们在第 [6](06.html) 章的最后提到过。可以通过将`cmdline`值传递给`rd.break`(一个 dracut 命令行参数)来调用钩子。我们将通过使用`cmdline`钩子来探索引导过程的这个阶段。我们需要在启动时将`rd.break=cmdline` dracut 命令行参数传递给内核。

在 initramfs 内部，systemd 从`usr/lib/systemd/system/dracut-cmdline.service`调用这个钩子。

```
# cat usr/lib/systemd/system/dracut-cmdline.service

#  This file is part of dracut.
#
# See dracut.bootup(7) for details

[Unit]
Description=dracut cmdline hook
Documentation=man:dracut-cmdline.service(8)
DefaultDependencies=no
Before=dracut-pre-udev.service
After=systemd-journald.socket
Wants=systemd-journald.socket
ConditionPathExists=/usr/lib/initrd-release
ConditionPathExistsGlob=|/etc/cmdline.d/*.conf
ConditionDirectoryNotEmpty=|/lib/dracut/hooks/cmdline
ConditionKernelCommandLine=|rd.break=cmdline
ConditionKernelCommandLine=|resume
ConditionKernelCommandLine=|noresume
Conflicts=shutdown.target emergency.target
[Service]
Environment=DRACUT_SYSTEMD=1
Environment=NEWROOT=/sysroot
Type=oneshot
ExecStart=-/bin/dracut-cmdline
StandardInput=null
StandardOutput=syslog
StandardError=syslog+console
KillMode=process
RemainAfterExit=yes

# Bash ignores SIGTERM, so we send SIGHUP instead, to ensure that bash
# terminates cleanly.
KillSignal=SIGHUP

```

如您所见，systemd 调用了一个`dracut-cmdline`脚本。该脚本在 initramfs 本身中可用，它将收集内核命令行参数。

```
# vim bin/dracut-cmdline
 24 # Get the "root=" parameter from the kernel command line, but differentiate
 25 # between the case where it was set to the empty string and the case where it
 26 # wasn't specified at all.
 27 if ! root="$(getarg root=)"; then
 28     root_unset='UNSET'
 29 fi
 30
 31 rflags="$(getarg rootflags=)"
 32 getargbool 0 ro && rflags="${rflags},ro"
 33 getargbool 0 rw && rflags="${rflags},rw"
 34 rflags="${rflags#,}"
 35
 36 fstype="$(getarg rootfstype=)"
 37 if [ -z "$fstype" ]; then
 38     fstype="auto"
 39 fi
 40
 41 export root
 42 export rflags
 43 export fstype
 44
 45 make_trace_mem "hook cmdline" '1+:mem' '1+:iomem' '3+:slab' '4+:komem'
 46 # run scriptlets to parse the command line
 47 getarg 'rd.break=cmdline' -d 'rdbreak=cmdline' && emergency_shell -n cmdline "Break before cmdline"
 48 source_hook cmdline
 49
 50 [ -f /lib/dracut/parse-resume.sh ] && . /lib/dracut/parse-resume.sh
 51
 52 case "${root}${root_unset}" in
 53     block:LABEL=*|LABEL=*)

 54         root="${root#block:}"
 55         root="$(echo $root | sed 's,/,\\x2f,g')"
 56         root="block:/dev/disk/by-label/${root#LABEL=}"
 57         rootok=1 ;;
 58     block:UUID=*|UUID=*)
 59         root="${root#block:}"
 60         root="block:/dev/disk/by-uuid/${root#UUID=}"
 61         rootok=1 ;;
 62     block:PARTUUID=*|PARTUUID=*)
 63         root="${root#block:}"
 64         root="block:/dev/disk/by-partuuid/${root#PARTUUID=}"
 65         rootok=1 ;;
 66     block:PARTLABEL=*|PARTLABEL=*)
 67         root="${root#block:}"
 68         root="block:/dev/disk/by-partlabel/${root#PARTLABEL=}"
 69         rootok=1 ;;
 70     /dev/*)
 71         root="block:${root}"
 72         rootok=1 ;;
 73     UNSET|gpt-auto)
 74         # systemd's gpt-auto-generator handles this case.
 75         rootok=1 ;;
 76 esac
 77
 78 [ -z "${root}${root_unset}" ] && die "Empty root= argument"
 79 [ -z "$rootok" ] && die "Don't know how to handle 'root=$root'"
 80
 81 export root rflags fstype netroot NEWROOT
 82
 83 export -p > /dracut-state.sh
 84
 85 exit 0

```

基本上，有三个参数(内核命令行参数)将在这个钩子中导出:

*   **root** =用户的根文件系统名称

*   **rflags** =用户的根文件系统标志(`ro`或`rw`)

*   **fstype** =自动(是否自动安装)

让我们看看这些参数是如何被 initramfs 发现的(或者在 initramfs 的 cmdline 钩子中)。`getarg`命名函数将用于获取这三个内核命令行参数。

```
root="$(getarg root=)
rflags="$(getarg rootflags=)
fstype="$(getarg rootfstype=)"
.
.
export root
export rflags
export fstype

```

在 initramfs 的`usr/lib/dracut-lib.sh`文件中定义了`getarg`函数。

```
#vim usr/lib/dracut-lib.sh
 201 getarg() {
 202     debug_off
 203     local _deprecated _newoption
 204     while [ $# -gt 0 ]; do
 205         case $1 in
 206             -d) _deprecated=1; shift;;
 207             -y) if _dogetarg $2 >/dev/null; then
 208                     if [ "$_deprecated" = "1" ]; then
 209                         [ -n "$_newoption" ] && warn "Kernel command line option '$2' is deprecated, use '$_newoption' instead." || warn "Option '$2' is deprecated."
 210                     fi
 211                     echo 1
 212                     debug_on
 213                     return 0
 214                 fi
 215                 _deprecated=0
 216                 shift 2;;
 217             -n) if _dogetarg $2 >/dev/null; then

 218                     echo 0;
 219                     if [ "$_deprecated" = "1" ]; then
 220                         [ -n "$_newoption" ] && warn "Kernel command line option '$2' is deprecated, use '$_newoption=0' instead." || warn "Option '$2' is deprecated."
 221                     fi
 222                     debug_on
 223                     return 1

 224                 fi
 225                 _deprecated=0
 226                 shift 2;;
 227             *)  if [ -z "$_newoption" ]; then
 228                     _newoption="$1"
 229                 fi
 230                 if _dogetarg $1; then
 231                     if [ "$_deprecated" = "1" ]; then
 232                         [ -n "$_newoption" ] && warn "Kernel command line option '$1' is deprecated, use '$_newoption' instead." || warn "Option '$1' is deprecated."
 233                     fi
 234                     debug_on
 235                     return 0;
 236                 fi
 237                 _deprecated=0
 238                 shift;;
 239         esac
 240     done
 241     debug_on
 242     return 1
 243 }

```

`getarg`函数正在从同一个文件中调用`_dogetarg`函数。

```
 165 _dogetarg() {
 166     local _o _val _doecho
 167     unset _val
 168     unset _o
 169     unset _doecho
 170     CMDLINE=$(getcmdline)
 171
 172     for _o in $CMDLINE; do
 173         if [ "${_o%%=*}" = "${1%%=*}" ]; then
 174             if [ -n "${1#*=}" -a "${1#*=*}" != "${1}" ]; then
 175                 # if $1 has a "=<value>", we want the exact match
 176                 if [ "$_o" = "$1" ]; then
 177                     _val="1";
 178                     unset _doecho
 179                 fi
 180                 continue
 181             fi
 182
 183             if [ "${_o#*=}" = "$_o" ]; then
 184                 # if cmdline argument has no "=<value>", we assume "=1"
 185                 _val="1";
 186                 unset _doecho
 187                 continue
 188             fi
 189
 190             _val="${_o#*=}"
 191             _doecho=1
 192         fi
 193     done
 194     if [ -n "$_val" ]; then
 195         [ "x$_doecho" != "x" ] && echo "$_val";
 196         return 0;
 197     fi
 198     return 1;
 199 }

```

然后，`_dogetarg()`函数调用`getcmdline`命名函数，该函数从`/proc/cmdline`收集实际的内核命令行参数。

```
 137 getcmdline() {
 138     local _line
 139     local _i
 140     local CMDLINE_ETC_D
 141     local CMDLINE_ETC
 142     local CMDLINE_PROC
 143     unset _line
 144
 145     if [ -e /etc/cmdline ]; then
 146         while read -r _line || [ -n "$_line" ]; do
 147             CMDLINE_ETC="$CMDLINE_ETC $_line";
 148         done </etc/cmdline;
 149     fi
 150     for _i in /etc/cmdline.d/*.conf; do
 151         [ -e "$_i" ] || continue
 152         while read -r _line || [ -n "$_line" ]; do
 153             CMDLINE_ETC_D="$CMDLINE_ETC_D $_line";
 154         done <"$_i";
 155     done
 156     if [ -e /proc/cmdline ]; then
 157         while read -r _line || [ -n "$_line" ]; do
 158             CMDLINE_PROC="$CMDLINE_PROC $_line"
 159         done </proc/cmdline;
 160     fi
 161     CMDLINE="$CMDLINE_ETC_D $CMDLINE_ETC $CMDLINE_PROC"
 162     printf "%s" "$CMDLINE"
 163 }

```

以下是到目前为止的引导顺序:

1.  引导装载程序从用户那里收集内核命令行参数，并将它们存储在自己的配置文件中(`grub.cfg`)。

2.  它通过填充内核头将这些命令行参数传递给内核。

3.  内核提取自身并复制内核头中的内核命令行参数。

4.  内核提取内存中的 initramfs，并将其用作临时根文件系统。

5.  在相同的过程中，内核准备虚拟文件系统，如`proc`、`sys`、`dev`、`devpts`、`shm`等。

6.  内核将命令行参数存储在`/proc/cmdline`文件中。

7.  systemd 通过读取`/proc/cmdline`文件收集内核命令行参数，并将它们存储在`root`、`rootfs`和`fstype`变量中。

我们可以通过使用`cmdline`钩子来验证这个程序。

回到`/bin/dracut-cmdline`脚本，让我们来看看:

```
 41 export root
 42 export rflags
 43 export fstype
 44
 45 make_trace_mem "hook cmdline" '1+:mem' '1+:iomem' '3+:slab' '4+:komem'
 46 # run scriptlets to parse the command line
 47 getarg 'rd.break=cmdline' -d 'rdbreak=cmdline' && emergency_shell -n cmdline "Break before cmdline"
 48 source_hook cmdline
 49
 50 [ -f /lib/dracut/parse-resume.sh ] && . /lib/dracut/parse-resume.sh

```

条件是如果用户已经在 GRUB 的内核部分传递了`rd.break=cmdline`参数，那么就执行`emergency_shell`函数。图 [7-10](#Fig10) 显示了该情况。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig10_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig10_HTML.jpg)

图 7-10

条件

如果用户已经通过了`rd.break=cmdline`，那么脚本调用名为`emergency_shell.`的函数顾名思义，它会提供调试 shell，如果调试 shell 已经成功启动，那么它调用另一个名为`source_hook`的函数，并向其传递`cmdline`参数。谁写这个代码给用户提供调试外壳，谁就是天才程序员！

我们在这个阶段不会讨论紧急 shell 函数，因为我们需要先了解 systemd。因此，我们将在第 8 章中更详细地讨论它。

图 [7-11](#Fig11) 显示了`dracut-cmdline.service`单元工作的流程图。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig11_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig11_HTML.jpg)

图 7-11

dracut-cmdline.service 流程图

更进一步，用户的根文件系统名称可能只是`/dev/sda5`，但是同一个 sda5 设备可能通过`uuid`、`partuuid`或`label`被引用。最后，sda5 的每隔一个引用都要到达`/dev/sda5`；因此，内核在`/dev/disk/`下为所有这些不同的设备名准备了符号链接文件。请参见图 [7-12](#Fig12) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig12_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig12_HTML.jpg)

图 7-12

/dev/disk 目录内容

同一个`/bin/dracut-cmdline`脚本将 mear sda5 根文件系统名称转换为`/dev/disk/by-uuid/6588b8f1-7f37-4162-968c-8f99eacdf32e`。

```
 52 case "${root}${root_unset}" in
 53     block:LABEL=*|LABEL=*)
 54         root="${root#block:}"
 55         root="$(echo $root | sed 's,/,\\x2f,g')"
 56         root="block:/dev/disk/by-label/${root#LABEL=}"
 57         rootok=1 ;;
 58     block:UUID=*|UUID=*)
 59         root="${root#block:}"
 60         root="block:/dev/disk/by-uuid/${root#UUID=}"
 61         rootok=1 ;;
 62     block:PARTUUID=*|PARTUUID=*)
 63         root="${root#block:}"
 64         root="block:/dev/disk/by-partuuid/${root#PARTUUID=}"
 65         rootok=1 ;;
 66     block:PARTLABEL=*|PARTLABEL=*)
 67         root="${root#block:}"
 68         root="block:/dev/disk/by-partlabel/${root#PARTLABEL=}"
 69         rootok=1 ;;
 70     /dev/*)
 71         root="block:${root}"
 72         rootok=1 ;;
 73     UNSET|gpt-auto)
 74         # systemd's gpt-auto-generator handles this case.
 75         rootok=1 ;;
 76 esac
 77
 78 [ -z "${root}${root_unset}" ] && die "Empty root= argument"
 79 [ -z "$rootok" ] && die "Don't know how to handle 'root=$root'"
 80
 81 export root rflags fstype netroot NEWROOT
 82
 83 export -p > /dracut-state.sh
 84
 85 exit 0

```

让我们看看`cmdline`钩子的作用。如图 [7-13](#Fig13) 所示，在 GRUB 的内核节上传递`rd.break=cmdline`。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig13_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig13_HTML.jpg)

图 7-13

内核命令行参数

内核将提取 initramfs，systemd 进程将启动，systemd 将初始化`journald`套接字，正如你在图 [7-14](#Fig14) 中看到的，systemd 将把我们放到一个命令行 shell 中，因为我们告诉 systemd 在执行`dracut-cmdline`钩子之前中断(钩子)引导序列。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig14_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig14_HTML.jpg)

图 7-14

命令行挂钩

目前，我们在 initramfs 内部，由于`dracut-cmdline.service`还没有启动，systemd 还没有从`/proc/cmdline`收集到内核命令行参数，如`root`、`rsflags`和`fstype`，我们已经在`systemd-journal.socket.`之后暂停(dracut hooked)了 systemd 的引导序列。请参见图 [7-15](#Fig15) 以便更好地理解。另外，`/dev/disk`下的符号链接还没有被 dracut 创建。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig15_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig15_HTML.jpg)

图 7-15

命令行挂钩

因为 systemd 还没有收集用户根文件系统的名称，所以毫无疑问，您不会发现用户的根文件系统挂载在 initramfs 中。`sysroot`是 initramfs 中的一个目录，systemd 在这里挂载用户的根文件系统。参见图 [7-16](#Fig16) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig16_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig16_HTML.jpg)

图 7-16

sysroot 目录

但是如果我们不向`rd.break`传递任何参数或者简单地退出当前的 cmdline shell，我们将被丢弃到`switch_root` shell。`switch_root` shell 是 initramfs 中 systemd 引导序列的最后阶段。在图 [7-17](#Fig17) 中，你可以看到我们正在没有任何争论的情况下通过`rd.break`。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig17_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig17_HTML.jpg)

图 7-17

rd.break 内核命令行参数

如图 [7-18](#Fig18) 所示，在`switch_root` shell 中，由于`dracut-cmdline.service`已经执行，你会发现内核命令行参数已经被 systemd 收集。此外，用户的根文件系统已经挂载在`sysroot`下的 initramfs 中。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig18_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig18_HTML.jpg)

图 7-18

开关根挂钩

如果我们从这个阶段退出，`switch_root` ( `pivot_root`)将由 systemd 执行，它将离开 initramfs 环境。稍后 systemd 将执行剩余的引导程序，如图 [7-19](#Fig19) 所示，最终我们将得到桌面。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig19_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig19_HTML.jpg)

图 7-19

Fedora 的登录屏幕

回到我们到目前为止的引导顺序，我们已经到达了预`udev`阶段。对此可参考图 [7-20](#Fig20) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig20_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig20_HTML.jpg)

图 7-20

到目前为止介绍的引导顺序

### dracut-预 udev.service

下一个 systemd 将处理连接的设备。为此，systemd 必须启动`udev`守护进程，但是在启动`udev`服务之前，它会检查用户是否希望在`udev`开始之前停止引导过程。如果用户已经传递了`rd.break=pre-udev dracut`命令行参数，systemd 将在执行`udev`守护进程之前停止引导序列。

```
# cat usr/lib/systemd/system/dracut-pre-udev.service | grep -v '#'

[Unit]
Description=dracut pre-udev hook
Documentation=man:dracut-pre-udev.service(8)
DefaultDependencies=no
Before=systemd-udevd.service dracut-pre-trigger.service
After=dracut-cmdline.service
Wants=dracut-cmdline.service
ConditionPathExists=/usr/lib/initrd-release
ConditionDirectoryNotEmpty=|/lib/dracut/hooks/pre-udev
ConditionKernelCommandLine=|rd.break=pre-udev
ConditionKernelCommandLine=|rd.driver.blacklist
ConditionKernelCommandLine=|rd.driver.pre
ConditionKernelCommandLine=|rd.driver.post
ConditionPathExistsGlob=|/etc/cmdline.d/*.conf
Conflicts=shutdown.target emergency.target

[Service]
Environment=DRACUT_SYSTEMD=1
Environment=NEWROOT=/sysroot
Type=oneshot
ExecStart=-/bin/dracut-pre-udev
StandardInput=null
StandardOutput=syslog
StandardError=syslog+console
KillMode=process
RemainAfterExit=yes

KillSignal=SIGHUP

```

它会把我们扔在一个前贝壳上。注意`after`、`before`和`wants`变量。执行`dracut-pre-udev.service`只是从 initramfs 中启动一个`/bin/dracut-pre-udev`二进制文件。在图 [7-21](#Fig21) 中，我们已经将`rd.break=pre-udev`作为内核命令行参数进行了传递。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig21_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig21_HTML.jpg)

图 7-21

传递 udev 之前的内核命令行参数

为了理解`pre-udev`钩子，你可以简单地列出`/dev`的内容，在图 [7-22](#Fig22) 中你会注意到没有名为 sda 的设备文件。sda 是我们的硬盘，在那里我们有我们的根文件系统。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig22_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig22_HTML.jpg)

图 7-22

前 udev 挂钩

没有`sda`设备文件的原因是因为`udev`守护进程还没有启动。守护进程将由`/usr/lib/systemd/system/systemd-udevd.service`单元文件启动，该文件将在`pre-udev`钩子之后启动。

```
# cat usr/lib/systemd/system/systemd-udevd.service | grep -v '#'

[Unit]
Description=udev Kernel Device Manager
Documentation=man:systemd-udevd.service(8) man:udev(7)
DefaultDependencies=no
After=systemd-sysusers.service systemd-hwdb-update.service
Before=sysinit.target
ConditionPathIsReadWrite=/sys

[Service]
Type=notify
OOMScoreAdjust=-1000
Sockets=systemd-udevd-control.socket systemd-udevd-kernel.socket
Restart=always
RestartSec=0
ExecStart=/usr/lib/systemd/systemd-udevd
KillMode=mixed
WatchdogSec=3min
TasksMax=infinity
PrivateMounts=yes
ProtectHostname=yes
MemoryDenyWriteExecute=yes
RestrictAddressFamilies=AF_UNIX AF_NETLINK AF_INET AF_INET6
RestrictRealtime=yes
RestrictSUIDSGID=yes
SystemCallFilter=@system-service @module @raw-io
SystemCallErrorNumber=EPERM
SystemCallArchitectures=native
LockPersonality=yes
IPAddressDeny=any

```

让我们试着了解一下`udev`是如何工作的，它是如何在`/dev`下创建设备文件的。

是内核检测连接到系统的硬件；更准确地说，是内核内部编译的驱动程序或后来插入的模块将检测硬件，并用`sysfs` ( `/sys`挂载点)注册它们的对象。因为有了`/sys`挂载点，这些数据对用户空间和`udev.`这样的工具变得可用，所以是内核通过驱动程序检测硬件并在`/dev`中创建一个设备文件，这是一个`devfs`文件系统。此后，内核向`udevd`发送一个`uevent`，然后`udevd`改变设备文件的名称、所有者或组，或者根据这里定义的规则设置适当的权限:

```
     /etc/udev/rules.d,
     /lib/udev/rules.d, and
     /run/udev/rules.d

# ls etc/udev/rules.d/
     59-persistent-storage.rules  61-persistent-storage.rules

# ls lib/udev/rules.d/
     50-udev-default.rules        70-uaccess.rules    75-net-description.rules  85-nm-unmanaged.rules
     60-block.rules               71-seat.rules       80-drivers.rules          90-vconsole.rules
     60-persistent-storage.rules  73-seat-late.rules  80-net-setup-link.rules   99-systemd.rules

```

与用户根文件系统上的可用的`udev`规则相比，initramfs 的`udev`规则文件很少。基本上，它只有那些管理用户根文件系统设备所必需的规则。一旦`udevd`处于控制状态，它将基于`lib/udev/rules.d/99-systemd.rules`调用各自的 systemd 单元。这里有一个例子:

```
# cat lib/udev/rules.d/99-systemd.rules
SUBSYSTEM=="net", KERNEL!="lo", TAG+="systemd", ENV{SYSTEMD_ALIAS}+="/sys/subsystem/net/devices/$name"
SUBSYSTEM=="bluetooth", TAG+="systemd", ENV{SYSTEMD_ALIAS}+="/sys/subsystem/bluetooth/devices/%k"

SUBSYSTEM=="bluetooth", TAG+="systemd", ENV{SYSTEMD_WANTS}+="bluetooth.target", ENV{SYSTEMD_USER_WANTS}+="bluetooth.target"
ENV{ID_SMARTCARD_READER}=="?*", TAG+="systemd", ENV{SYSTEMD_WANTS}+="smartcard.target", ENV{SYSTEMD_USER_WANTS}+="smartcard.target"
SUBSYSTEM=="sound", KERNEL=="card*", TAG+="systemd", ENV{SYSTEMD_WANTS}+="sound.target", ENV{SYSTEMD_USER_WANTS}+="sound.target"

SUBSYSTEM=="printer", TAG+="systemd", ENV{SYSTEMD_WANTS}+="printer.target", ENV{SYSTEMD_USER_WANTS}+="printer.target"
SUBSYSTEM=="usb", KERNEL=="lp*", TAG+="systemd", ENV{SYSTEMD_WANTS}+="printer.target", ENV{SYSTEMD_USER_WANTS}+="printer.target"
SUBSYSTEM=="usb", ENV{DEVTYPE}=="usb_device", ENV{ID_USB_INTERFACES}=="*:0701??:*", TAG+="systemd", ENV{SYSTEMD_WANTS}+="printer.target", ENV{SYSTEMD_USER_WANTS}+="printer.target"

SUBSYSTEM=="udc", ACTION=="add", TAG+="systemd", ENV{SYSTEMD_WANTS}+="usb-gadget.target"

```

该规则被加上了`systemd`标签。这意味着无论何时检测到一个`bluetooth`设备，`udevd`将调用 systemd 的`bluetooth.target.`,`bluetooth.target`将执行`/usr/libexec/bluetooth/bluetoothd`二进制，这将负责剩下的`bluetooth`设备处理。因此，`udevd`操作`bluetooth`装置的完整顺序如下:

1.  如果用户在启动时将蓝牙设备连接到系统，则内核或内核中编译的驱动程序或稍后插入的模块将检测蓝牙设备并将其对象注册到`/sys`。

2.  稍后，内核将在`/dev`挂载点创建一个设备文件。设备文件创建完成后，内核会发送一个`uevent`给`udevd`。

3.  `udevd`将从 initramfs 引用`lib/udev/rules.d/99-systemd.rules`并将调用 systemd。根据标签，systemd 应该处理剩下的部分。

4.  systemd 将执行`bluetooth.target`，T0 将执行`bluetoothd`二进制，蓝牙硬件将准备好使用。

当然，蓝牙不是启动时必需的硬件。我举这个例子只是为了便于理解。

因此，我们已经到达`systemd-udev.service.` systemd 将继续其引导序列，并将执行`dracut-pre-trigger.service.`您可以在图 [7-23](#Fig23) 中看到引导序列。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig23_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig23_HTML.jpg)

图 7-23

到目前为止介绍的引导顺序

### dracut-预触发服务

如果用户传递了`rd.break=pre-trigger` dracut 命令行参数，systemd 的 initramfs 引导序列将被中断(挂钩)。你可以在图 [7-24](#Fig24) 中看到，我们已经将`pre-trigger`作为参数传递给了`rd.break`内核命令行参数。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig24_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig24_HTML.jpg)

图 7-24

rd.break =预触发内核命令行参数

它将把我们放在一个`pre-trigger` shell 上，这是在启动`udevd`服务之后。首先让我们看看它是如何落在一个`pre-trigger`壳上的。

```
# cat usr/lib/systemd/system/dracut-pre-trigger.service | grep -v '#'
[Unit]
Description=dracut pre-trigger hook
Documentation=man:dracut-pre-trigger.service(8)
DefaultDependencies=no
Before=systemd-udev-trigger.service dracut-initqueue.service
After=dracut-pre-udev.service systemd-udevd.service systemd-tmpfiles-setup-dev.service
Wants=dracut-pre-udev.service systemd-udevd.service
ConditionPathExists=/usr/lib/initrd-release
ConditionDirectoryNotEmpty=|/lib/dracut/hooks/pre-trigger
ConditionKernelCommandLine=|rd.break=pre-trigger
Conflicts=shutdown.target emergency.target

[Service]
Environment=DRACUT_SYSTEMD=1
Environment=NEWROOT=/sysroot
Type=oneshot
ExecStart=-/bin/dracut-pre-trigger
StandardInput=null
StandardOutput=syslog
StandardError=syslog+console
KillMode=process
RemainAfterExit=yes

KillSignal=SIGHUP

```

请注意服务单元文件的`After`、`Before`和`wants`部分。如果这个`ConditionDirectoryNotEmpty=|/lib/dracut/hooks/pre-trigger`目录存在，并且如果用户将`rd.break=pre-trigger`作为命令行参数传递，这个服务文件将从 initramfs 执行`/bin/dracut-pre-trigger`。

```
[root@fedorab boot]# cat bin/dracut-pre-trigger
#!/usr/bin/sh

export DRACUT_SYSTEMD=1
if [ -f /dracut-state.sh ]; then
    . /dracut-state.sh 2>/dev/null
fi
type getarg >/dev/null 2>&1 || . /lib/dracut-lib.sh
source_conf /etc/conf.d
make_trace_mem "hook pre-trigger" '1:shortmem' '2+:mem' '3+:slab' '4+:komem'
source_hook pre-trigger
getarg 'rd.break=pre-trigger' 'rdbreak=pre-trigger' && emergency_shell -n pre-trigger "Break pre-trigger"
udevadm control --reload >/dev/null 2>&1 || :
export -p > /dracut-state.sh
exit 0

```

如您所见，它正在通过`getarg`函数检查传递的 dracut 命令行参数(`rd.break=pre-trigger`)。我们在本章前面已经看到了`getarg`是如何工作的。如果用户已经通过了`rd.break=pre-trigger,`，那么它将调用`emergency_shell`函数，并将`pre-trigger`作为参数传递给它。`emergency_shell`函数写在`dracut-lib.sh`文件中。这个函数将为我们提供`pre-trigger`外壳。第 [8](08.html) 章介绍了提供应急外壳的程序。

顾名思义，正如你在图 [7-25](#Fig25) 中看到的，我们已经在`udev`触发之前停止了引导序列。因此，sda 磁盘在`dev`下还不可用。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig25_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig25_HTML.jpg)

图 7-25

预触发钩

这是因为`udevadm`触发器还没有被执行。服务`dracut-pre-trigger.service`只执行重新加载`udev`规则`.`的`udevadm control --reload,`，如图 [7-26](#Fig26) 所示，服务`systemd-udev.service`已经启动，但`systemd-udev-trigger`服务尚未启动。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig26_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig26_HTML.jpg)

图 7-26

预触发钩

### systemd-udev-trigger.service

图 [7-27](#Fig27) 显示了我们已经到达的引导阶段。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig27_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig27_HTML.jpg)

图 7-27

到目前为止的引导顺序

正如我们已经看到的，在 pre-T0 中，`/dev`没有被填充，因为`systemd-udevd.service`本身没有启动。与`pre-trigger`一样:`/dev`没有被填充，但是`udevd`服务已经开始。通过使用`udevd`守护进程提供的环境，`udevd`服务将创建一个环境来启动/运行各种`udev`工具，如`udevadm.`，如图 [7-28](#Fig28) 所示，在`pre-trigger`中，我们将能够执行`udevadm`，这是我们在`pre-udev` shell 中无法使用的。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig28_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig28_HTML.jpg)

图 7-28

预触发钩

正如您在`pre-trigger`开关内部看到的，sda 设备尚未创建。但是由于我们已经准备好了一个`udevadm`环境，我们可以通过它发现设备。如图 [7-29](#Fig29) 所示，我们将首先挂载内核配置文件系统。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig29_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig29_HTML.jpg)

图 7-29

预触发钩

```
pre-trigger:/ # udevadm trigger --type=subsystems --action=add

```

然后我们将触发`udevadm`来添加设备。

```
pre-trigger:/ # udevadm trigger --type=devices --action=add

```

如图 [7-29](#Fig29) 所示，sda 设备已经创建完毕。systemd 将通过`systemd-udev-trigger.service`发出相同的命令，这些命令将在`/dev`下发现并创建存储设备文件。

```
# cat usr/lib/systemd/system/systemd-udev-trigger.service  | grep -v ‘#’

[Unit]
Description=udev Coldplug all Devices
Documentation=man:udev(7) man:systemd-udevd.service(8)
DefaultDependencies=no
Wants=systemd-udevd.service
After=systemd-udevd-kernel.socket systemd-udevd-control.socket
Before=sysinit.target
ConditionPathIsReadWrite=/sys

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/bin/udevadm trigger –type=subsystems –action=add
ExecStart=/usr/bin/udevadm trigger –type=devices –action=add

```

但是在图 [7-30](#Fig30) 中可以看到，由于`udev`环境缺失，相同的`udevadm`命令在`pre-udev`钩子中不会成功。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig30_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig30_HTML.jpg)

图 7-30

前 udev hook 中的 udevadm

这就是`dracut-pre-trigger.service`或`pre-trigger`挂钩的重要性。

图 [7-31](#Fig31) 中给出的流程图将帮助您理解迄今为止 systemd 在 initramfs 中采取的步骤。读完第八章[后，流程图会更容易理解。我强烈推荐在看完第八章](08.html)[后重温这一章。](08.html)

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig31_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig31_HTML.jpg)

图 7-31

流程图

### 本地文件系统目标

如图 [7-32](#Fig32) 所示，我们已经到了启动的`local-fs-target`阶段。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig32_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig32_HTML.jpg)

图 7-32

到目前为止介绍的引导顺序

所以，systemd 到目前为止已经达到了`local-fs.target.`，systemd 一直在执行一个又一个的服务，只是因为存储设备没有准备好。由于`udevadm`触发成功，存储设备已被填充，现在是准备挂载点的时候了，这将由`local-fs.target`完成。在进入`local-fs.target`之前，它会确保运行`local-fs.pre.target`。

```
# cat usr/lib/systemd/system/local-fs-pre.target

[Unit]
Description=Local File Systems (Pre)
Documentation=man:systemd.special(7)
RefuseManualStart=yes

#cat usr/lib/systemd/system/local-fs.target

[Unit]
Description=Local File Systems
Documentation=man:systemd.special(7)
DefaultDependencies=no
Conflicts=shutdown.target
After=local-fs-pre.target
OnFailure=emergency.target
OnFailureJobMode=replace-irreversibly

```

`systemd-fstab-generator`将由`local-fs.target`导航。

```
man page - systemd.special

```

`systemd-fstab-generator(3)` *自动将类型* `Before=` *的依赖项添加到所有引用该目标单元的本地挂载点的挂载单元。此外，对于* `/etc/fstab` *中列出的那些设置了自动挂载选项的挂载，它会将* `Wants=` *类型的依赖项添加到该目标单元。*

将从 initramfs 中调用`systemd-fstab-generator`二进制文件。

```
# file usr/lib/systemd/system-generators/systemd-fstab-generator

usr/lib/systemd/system-generators/systemd-fstab-generator: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=e16e9d4188e2cab491f551b5f703a5caa645764b, for GNU/Linux 3.2.0, stripped

```

事实上，systemd 在引导序列的早期运行所有的生成器。

```
# ls -l usr/lib/systemd/system-generators
     total 92
     -rwxr-xr-x. 1 root root  3750 Dec 21 12:19 dracut-rootfs-generator
     -rwxr-xr-x. 1 root root 45640 Dec 21 12:19 systemd-fstab-generator
     -rwxr-xr-x. 1 root root 37032 Dec 21 12:19 systemd-gpt-auto-generator

```

`systemd-fstab-generator`就是其中之一。`systemd-fstab-generator`的主要任务是读取内核命令行，在`/tmp`目录下或者`/run/systemd/generator/`下创建 systemd 挂载单元文件(继续读，这个都有意义)。如你所见，它是一个二进制文件，这意味着我们需要检查 systemd 的 C 源代码，以了解它是做什么的。`systemd-fstab-generator`要么没有输入，要么有三个输入。

```
# usr/lib/systemd/system-generators/systemd-fstab-generator /dev/sda5
This program takes zero or three arguments.

```

当然，三个输入是根文件系统名称、文件系统类型和根文件系统标志。在写这本书的时候，systemd 的最新版本是版本 244，所以我们在这里用这个来解释。之前显示的错误信息来自`src/shared/generator.h`。

```
# vim systemd-244/src/shared/generator.h
 57 /* Similar to DEFINE_MAIN_FUNCTION, but initializes logging and assigns positional arguments. */
 58 #define DEFINE_MAIN_GENERATOR_FUNCTION(impl)                            \
 59         _DEFINE_MAIN_FUNCTION(                                          \
 60                 ({                                                      \
 61                         log_setup_generator();                          \
 62                         if (argc > 1 && argc != 4)                      \
 63                                 return log_error_errno(SYNTHETIC_ERRNO(EINVAL), \
 64                                                 "This program takes zero or three arguments."); \
 65                 }),                                                     \
 66                 impl(argc > 1 ? argv[1] : "/tmp",                       \
 67                      argc > 1 ? argv[2] : "/tmp",                       \

```

`systemd-fstab-generator`二进制由`src/fstab-generator/fstab-generator.c`构成。

```
# vim systemd-244/src/fstab-generator/fstab-generator.c

868 static int run(const char *dest, const char *dest_early, const char *dest_late) {
869         int r, r2 = 0, r3 = 0;
870
871         assert_se(arg_dest = dest);
872         assert_se(arg_dest_late = dest_late);
873
874         r = proc_cmdline_parse(parse_proc_cmdline_item, NULL, 0);
875         if (r < 0)
876                 log_warning_errno(r, "Failed to parse kernel command line, ignoring: %m");
877
878         (void) determine_root();
879
880         /* Always honour root= and usr= in the kernel command line if we are in an initrd */
881         if (in_initrd()) {
882                 r = add_sysroot_mount();
883
884                 r2 = add_sysroot_usr_mount();
885
886                 r3 = add_volatile_root();
887         } else
888                 r = add_volatile_var();
889
890         /* Honour /etc/fstab only when that's enabled */
891         if (arg_fstab_enabled) {
892                 /* Parse the local /etc/fstab, possibly from the initrd */
893                 r2 = parse_fstab(false);
894
895                 /* If running in the initrd also parse the /etc/fstab from the host */
896                 if (in_initrd())
897                       r3 = parse_fstab(true);
898                 else
899                       r3 = generator_enable_remount_fs_service(arg_dest);
900         }
901
902         return r < 0 ? r : r2 < 0 ? r2 : r3;
903 }
904
905 DEFINE_MAIN_GENERATOR_FUNCTION(run);

```

如您所见，首先它通过函数`proc_cmdline_parse`解析命令行参数。

```
root        = root filesystem name
rootfstype  = root filesystem type
rootflags   = ro, rw or auto etc.

```

`systemd-fstab-generator`运行两次:在 initramfs 内部和在 initramfs 外部。一旦 systemd 退出 initramfs(在`sysroot`中挂载用户的根文件系统之后)，`systemd-fstab-generator`将收集 usr 文件系统的命令行参数(如果它是一个单独的分区，并且它的条目在`etc/fstab`中可用)。

```
'usr' filesystem name
'usr' filesystem type
'usr' filesystem flags

```

为了便于理解，我们将考虑以下情况:

```
Inside of initramfs:   Before mounting the user's root filesystem in /sysroot
Outside of initramfs:   After mounting the user's root filesystem in /sysroot

```

因此，当 systemd 在 initramfs 内运行时，`systemd-fstab-generator`二进制文件将收集用户的根文件系统相关的命令行参数，当 systemd 在 initramfs 外运行时，它将收集 usr 文件系统相关的命令行参数。systemd 是在 initramfs 内部还是外部运行将通过`in_initrd`函数来检查。函数写在文件`src/basic/util.c` `.`中，检查它如何验证它是在 initramfs 环境内部还是外部很有趣。

```
# vim systemd-244/src/basic/util.c
 54 bool in_initrd(void) {
 55         struct statfs s;
 56         int r;
 57
 58         if (saved_in_initrd >= 0)
 59                 return saved_in_initrd;
 60
 61         /* We make two checks here:
 62          *
 63          * 1\. the flag file /etc/initrd-release must exist
 64          * 2\. the root file system must be a memory file system
 65          *
 66          * The second check is extra paranoia, since misdetecting an
 67          * initrd can have bad consequences due the initrd
 68          * emptying when transititioning to the main systemd.
 69          */
 70
 71         r = getenv_bool_secure("SYSTEMD_IN_INITRD");
 72         if (r < 0 && r != -ENXIO)
 73                 log_debug_errno(r, "Failed to parse $SYSTEMD_IN_INITRD, ignoring: %m");
 74
 75         if (r >= 0)
 76                 saved_in_initrd = r > 0;
 77         else
 78                 saved_in_initrd = access("/etc/initrd-release", F_OK) >= 0 &&
 79                                   statfs("/", &s) >= 0 &&
 80                                   is_temporary_fs(&s);
 81
 82         return saved_in_initrd;
 83 }

```

它检查`/etc/initrd-release`文件是否可用。如果这个文件不存在，这意味着我们在 initramfs 之外。这个函数然后调用`statfs`函数，它将提供文件系统的详细信息，如下所示:

```
struct statfs {
               __fsword_t f_type;    /* Type of filesystem (see below) */
               __fsword_t f_bsize;   /* Optimal transfer block size */
               fsblkcnt_t f_blocks;  /* Total data blocks in filesystem */
               fsblkcnt_t f_bfree;   /* Free blocks in filesystem */
               fsblkcnt_t f_bavail;  /* Free blocks available to
                                        unprivileged user */
               fsfilcnt_t f_files;   /* Total file nodes in filesystem */
               fsfilcnt_t f_ffree;   /* Free file nodes in filesystem */
               fsid_t     f_fsid;    /* Filesystem ID */
               __fsword_t f_namelen; /* Maximum length of filenames */
               __fsword_t f_frsize;  /* Fragment size (since Linux 2.6) */
               __fsword_t f_flags;   /* Mount flags of filesystem
                                        (since Linux 2.6.36) */
               __fsword_t f_spare[xxx];
                               /* Padding bytes reserved for future use */
           };

```

然后它调用`is_temporary_fs()`函数，这个函数写在`/src/basic/stat-util.c`里面。

```
190  bool is_temporary_fs(const struct statfs *s) {
191         return is_fs_type(s, TMPFS_MAGIC) ||
192                 is_fs_type(s, RAMFS_MAGIC);
193 }

```

如您所见，它检查根文件系统是否分配了 ramfs 幻数。如果是，那么我们在 initramfs 内部。在我们的例子中，我们在 initramfs 环境中，所以这个函数将返回`true`并从`src/fstab-generator/fstab-generator.c`继续前进，只创建根文件系统的`-.mount` ( `sysroot.mount`)单元文件`.`。如果我们在 initramfs 之外(在用用户的根文件系统挂载`sysroot`之后)，它将为 usr 文件系统创建一个`-.mount`单元文件。简而言之，首先它检查我们是否在 initramfs 中。如果我们是，那么它为根文件系统创建挂载单元文件，如果我们是外部的，那么它为 usr(如果它是一个单独的文件系统)文件系统创建挂载单元文件。为了看到这一点，我们将进入`switch_root`(钩子)阶段，以便能够手动运行`systemd-fstab-generator`二进制文件。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig34_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig34_HTML.jpg)

图 7-34

sysroot.mount 文件

1.  首先我已经删除了`/tmp`目录的内容。这是因为`fstab`生成器在`/tmp.`中生成挂载单元文件

2.  Run the `systemd-fstab-generator` binary, and as you can see in Figure [7-33](#Fig33), it has created a couple of files in `/tmp`.

    ![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig33_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig33_HTML.jpg)

    图 7-33

    系统 d-fstab-generato0072

3.  它创建了一个`sysroot.mount`单元文件。顾名思义，创建它是为了挂载用户的根文件系统。读取`/proc/cmdline.`已创建单元文件，参见图 [7-34](#Fig34) 查看`sysroot.mount`文件内容。

根文件系统将从 sda5(通过使用 UUID)挂载到`sysroot`目录。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig35_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig35_HTML.jpg)

图 7-35

systemd-fsck-root.service 文件内容

1.  检查`sysroot.mount`单元文件的`requires`部分。它说在挂载根文件系统之前，必须首先执行`systemd-fsck-root.service`。图 [7-35](#Fig35) 为`systemd-fsck-root.service`档。

因此在引导时，如果您在 initramfs 中，那么`systemd-fstab-generator`将为用户的根文件系统生成挂载单元文件，并且相应的`fsck`服务文件也将被生成。

在 initramfs 引导序列的最后，systemd 将从`/tmp`目录中引用这些文件，将首先在根设备上执行`fsck`，并将根文件系统挂载到 sysroot 上(在 initramfs 内部)；最终`switch_root`将会上演。

现在您必须明白，尽管二进制文件的名称是`systemd-fstab-generator`，但它并没有真正创建`/etc/fstab`文件。相反，它的工作是在`/tmp`或`run/systemd/generator/`目录下为`root`(在 initramfs 内)和`usr`(在 initramfs 外)创建 systemd 挂载单元。这个系统只有`root`挂载点，所以它只为根文件系统创建了 systemd 单元文件。在 initramfs 内部，它调用`add_sysroot_mount`来挂载用户的根文件系统。一旦它被挂载，根文件系统 systemd 就调用`add_sysroot_usr_mount`函数。这些函数调用`add_mount`命名的函数，这又使 systemd 挂载单元文件。下面是`src/fstab-generator/fstab-generator.c`中`add_mount`函数的一个片段:

```
# vim systemd-244/src/fstab-generator/fstab-generator.c
341      r = unit_name_from_path(where, ".mount", &name);
342         if (r < 0)
343                 return log_error_errno(r, "Failed to generate unit name: %m");
344
345         r = generator_open_unit_file(dest, fstab_path(), name, &f);
346         if (r < 0)
347                 return r;
348
349         fprintf(f,
350                 "[Unit]\n"
351                 "SourcePath=%s\n"
352                 "Documentation=man:fstab(5) man:systemd-fstab-generator(8)\n",
353                 source);
354
355         /* All mounts under /sysroot need to happen later, at initrd-fs.target time. IOW, it's not
356          * technically part of the basic initrd filesystem itself, and so shouldn't inherit the default
357          * Before=local-fs.target dependency. */
358         if (in_initrd() && path_startswith(where, "/sysroot"))
359                 fprintf(f, "DefaultDependencies=no\n");

```

当前系统只有一个根分区。为了帮助您更好地理解这一点，这里我准备了一个测试系统，它有`root`、`boot`、`usr`、`var`和`opt`作为独立的文件系统:

```
UUID = f7ed74b5-9085-4f42-a1c4-a569f790fdad    /       ext4   defaults   1  1
UUID = 06609f65-5818-4aee-a9c5-710b76b36c68    /boot   ext4   defaults   1  2
UUID = 68fa7990-edf9-4a03-9011-21903a676322    /opt    ext4   defaults   1  2
UUID = 6fa78ab3-6c05-4a2f-9907-31be6d2a1071    /usr    ext4   defaults   1  2
UUID = 9c721a59-b62d-4d60-9988-adc8ed9e8770    /var    ext4   defaults   1  2

```

我们将置身于 initramfs 的`pre-pivot`外壳中(我们还没有讨论过)。图 [7-36](#Fig36) 显示我们已经将`rd.break=pre-pivot`命令行参数传递给内核。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig36_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig36_HTML.jpg)

图 7-36

内核命令行参数

如图 [7-37](#Fig37) 所示，在`pre-pivot`钩子中，`root`文件系统将与`usr`文件系统一起被挂载，因为`pre-pivot`钩子在`sysroot`上挂载用户的根文件系统后停止了引导序列。但是`opt`、`var`和`boot`不会被安装。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig37_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig37_HTML.jpg)

图 7-37

预枢转钩

即使运行`systemd-fstab-generator`，你也会发现只创建了`usr`和`root`挂载单元文件。在图 [7-38](#Fig38) 中可以看到`systemd-fstab-generator`输出。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig38_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig38_HTML.jpg)

图 7-38

预旋转挂钩中的 systemd-fstab-generator

这证明了在 initramfs 环境中，只有`root`和`usr`会被挂载。其余的挂载点将在 initramfs 之后或者切换到 root 之后挂载。因为`var`文件系统还没有安装，所以`journalctl`日志将从`/run`文件系统中维护，正如我们所知，这是一个临时文件系统。这清楚地表明，在 initramfs 环境中，您不能访问 journald 的永久日志，它们位于`/var/log`。请参考图 [7-39](#Fig39) 、 [7-40](#Fig40) 和 [7-41](#Fig41) 更好地理解这一点。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig41_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig41_HTML.jpg)

图 7-41

预透视挂钩中的日志行为

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig40_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig40_HTML.jpg)

图 7-40

journalctl 提供的日志来自/run

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig39_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig39_HTML.jpg)

图 7-39

预透视挂钩中的 journalctl 命令

你注意到一件事了吗？`dracut-cmdline`服务正在读取内核命令行参数，`usr`相关的命令行参数在`/proc/cmdline`中不可用。那么，systemd 是如何挂载`usr`文件系统的呢？另外，在生成 initramfs 时，dracut 不会复制其中的`etc/fstab`文件。

```
# lsinitrd | grep -i fstab
-rw-r--r--  1 root root       0 Jul 25 03:54 etc/fstab.empty
-rwxr-xr-x  1 root root   45640 Jul 25 03:54 usr/lib/systemd/system-generators/systemd-fstab-generator

# lsinitrd -f etc/fstab.empty
     <no_output>

```

那么，当 systemd 没有条目时，它如何在 initramfs 中挂载`usr`文件系统呢？

当`systemd-fstab-generator`在`local-fs.target`期间运行时，它只为 root 创建挂载单元文件；然后它继续引导序列并在`sysroot`上挂载根文件系统。一旦挂载了根文件系统，它就从`/etc/sysroot/etc/fstab`中读取`usr`条目，并创建一个`usr.mount`单元文件，最后挂载它。让我们交叉验证这种理解:

1.  放下`pre-pivot`挂钩。

2.  从安装的`/sysroot.`中删除`/etc/fstab`

3.  运行`systemd-fstab-generator.`

4.  参见图 [7-42](#Fig42) 。

因为`root`文件系统名称将由`dracut-cmdline`从`proc/cmdline, systemd-fstab-generator`中取出，将成为`sysroot.mount`。但是由于`sysroot`中缺少`fstab`文件，它会将`usr`视为一个不可用的独立分区，并且它会跳过创建`usr.mount`单元文件，即使`usr`是一个独立的挂载点。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig42_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig42_HTML.jpg)

图 7-42

systemd-fstab-生成器行为

如果您希望在`/sysroot`中有类似于`opt`和`var`的独立挂载点，或者您希望它们在 initramfs 环境中，该怎么办？systemd 的手册页对此有一个答案，如下所示:

> *x-initrd . mount*

> *要在 initramfs 中挂载的附加文件系统。参见*`systemd.special(7).`

> *中的* `initrd-fs.target` *描述 initrd-fs . target*

> `systemd-fstab-generator(3)`*自动将* `Before=` *类型的依赖项添加到*`sysroot-usr.mount``sysroot-usr.mount`中，以及在 `/etc/fstab` *中找到的所有具有* `x-initrd.mount` *而没有* `noauto mount` *选项的挂载点*T45

所以，我们需要使用`/etc/fstab`中的`x-initrd.mount [systemd.mount]`选项。例如，这里我已经通过相同的`pre-pivot`环境启用了 initramfs 中的`var`挂载点:

```
pre-pivot:/# vi /sysroot/etc/fstab

UUID=f7ed74b5-9085-4f42-a1c4-a569f790fdad  /      ext4  defaults   1  1
UUID=06609f65-5818-4aee-a9c5-710b76b36c68  /boot  ext4  defaults   1  2
UUID=68fa7990-edf9-4a03-9011-21903a676322  /opt   ext4  defaults   1  2
UUID=6fa78ab3-6c05-4a2f-9907-31be6d2a1071  /usr   ext4  defaults   1  2
UUID=9c721a59-b62d-4d60-9988-adc8ed9e8770  /var   ext4  defaults,x-initrd.mount   1  2

```

如图 [7-43](#Fig43) 所示，`var`挂载单元文件已经创建，但是`fsck`只对`root`文件系统可用。请参考图 [7-44](#Fig44) 中的流程图，以帮助您更好地理解这一点。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig44_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig44_HTML.jpg)

图 7-44

流程图

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig43_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig43_HTML.jpg)

图 7-43

systemd-fstab-generator 的工作原理

### 交换目标

如图 [7-45](#Fig45) 所示，我们已经到了启动的`swap.target`阶段。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig45_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig45_HTML.jpg)

图 7-45

到目前为止的引导顺序

这将与`local-fs.target`并行执行。`local-fs-.target`为`root`和`usr`创建挂载点，而`swap.target`为交换设备创建挂载单元文件。一旦根文件系统挂载文件准备好了，就根据它挂载`sysroot`。`systemd-fstab-generator`将读取`fstab`，如果交换设备条目存在，它将生成`swap.mount`单元文件。这意味着只有在切换到用户的根文件系统(`switch_root`到`sysroot`)之后，才会创建`swap.mount`文件。在此阶段不会创建`swap.mount`。

### dracut-initqueue .服务

该服务创建实际的`root`、`swap`和`usr`设备。我们用一个例子来理解这个。

通过`pre-udev`钩子，我们看到了类似 sda 的设备是不可用的。因为`udevd`服务本身还没有启动，所以两个`udevadm`命令都不起作用。参见图 [7-46](#Fig46) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig46_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig46_HTML.jpg)

图 7-46

预 udev 挂钩的工作原理

使用`pre-trigger`钩子，sda 设备没有创建，但是`udevd`服务已经启动；因此，如图 [7-47](#Fig47) 和图 [7-48](#Fig48) 所示，您可以使用类似`udevadm`的工具在`/dev`下创建`sda`器件，但不会在其上创建类似`lvm`或`raid`的器件。这种设备也称为`dm`(设备映射器)设备。因此，如果根在`lvm`上，`pre-trigger`服务将不能为根创建设备文件，因此像`/dev/fedora_localhost-live/`这样的设备将不会被创建。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig48_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig48_HTML.jpg)

图 7-48

sda 装置已在预触发挂钩下创建

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig47_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig47_HTML.jpg)

图 7-47

预触发钩

服务`dracut-initqueue.service`尚未启动。我们先看看单位档案到底是怎么说的。

```
# cat usr/lib/systemd/system/dracut-initqueue.service | grep -v '#'

[Unit]
Description=dracut initqueue hook
Documentation=man:dracut-initqueue.service(8)
DefaultDependencies=no
Before=remote-fs-pre.target
Wants=remote-fs-pre.target
After=systemd-udev-trigger.service
Wants=systemd-udev-trigger.service
ConditionPathExists=/usr/lib/initrd-release
ConditionPathExists=|/lib/dracut/need-initqueue
ConditionKernelCommandLine=|rd.break=initqueue
Conflicts=shutdown.target emergency.target

[Service]
Environment=DRACUT_SYSTEMD=1
Environment=NEWROOT=/sysroot
Type=oneshot
ExecStart=-/bin/dracut-initqueue
StandardInput=null
StandardOutput=syslog
StandardError=syslog+console
KillMode=process
RemainAfterExit=yes
KillSignal=SIGHUP

```

正如你所看到的，这个服务只是启动了`/bin/dracut-initqueue`脚本，如果我们打开这个脚本，你会发现它实际上是在执行`udevadm settle`命令，其`timeout`值为 0。

```
 # vim bin/dracut-initqueue
 22 while :; do
 23
 24     check_finished && break
 25
 26     udevadm settle --exit-if-exists=$hookdir/initqueue/work
 27
 28     check_finished && break
 29
 30     if [ -f $hookdir/initqueue/work ]; then
 31         rm -f -- "$hookdir/initqueue/work"
 32     fi
 33
 34     for job in $hookdir/initqueue/*.sh; do
 35         [ -e "$job" ] || break
 36         job=$job . $job
 37         check_finished && break 2
 38     done
 39
 40     udevadm settle --timeout=0 >/dev/null 2>&1 || continue
 41
 42     for job in $hookdir/initqueue/settled/*.sh; do
 43         [ -e "$job" ] || break
 44         job=$job . $job
 45         check_finished && break 2
 46     done
 47
 48     udevadm settle --timeout=0 >/dev/null 2>&1 || continue
 49
 50     # no more udev jobs and queues empty.
 51     sleep 0.5

```

这将最终运行来自`lib/dracut/hooks/initqueue/timeout/.`的`lvm_scan`命令。注意图 [7-49](#Fig49) 中传递的`root`和`rd.break`内核命令行参数。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig49_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig49_HTML.jpg)

图 7-49

内核命令行参数

如图 [7-50](#Fig50) 所示，`lvm_scan`命令被写入其中一个文件。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig50_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig50_HTML.jpg)

图 7-50

initqueue 挂钩

因此，这里我们有两个选择:或者我们可以只执行`/bin/dracut-initqueue`或者如图 [7-51](#Fig51) 所示，我们可以从`pre-trigger`钩子或者从`initqueue`钩子执行`lvm_scan`命令。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig51_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig51_HTML.jpg)

图 7-51

initqueue 挂钩中的 lvm_scan 命令

既然我们已经讨论了 initramfs 的 LVM 部分，现在是时候来看看最常见和最关键的“无法启动”问题了。

#### “无法启动”问题 7 (systemd + Root LVM)

**问题:**我们将标准根设备名称从`/dev/mapper/fedora_localhost--live-root`更改为`/dev/mapper/root_vg-root`。我们在`/etc/fstab`中做了适当的输入，但是重启后，系统无法启动。图 [7-52](#Fig52) 显示了屏幕上可见的内容。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig52_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig52_HTML.jpg)

图 7-52

控制台消息

由于我们现在对`dracut-initqueue`有了更好的理解，我们可以看到错误消息清楚地表明 systemd 无法组装`root lvm`设备。

1.  让我们首先通过回忆执行的步骤来隔离问题。原`root lv`名如下:

1.  `root volume group`名称已被更改。

    ```
    # vgrename  fedora_localhost-live  root_vg

    The volume group Fedora_localhost-live was successfully renamed to root_vg.

    ```

2.  `root lvm`的`/etc/fstab`条目已被适当更改。

```
#cat /etc/fstab

/dev/mapper/fedora_localhost--live-root     /        ext4  defaults 1  1
UUID=eea3d947-0618-4d8c-b083-87daf15b2679  /boot  ext4  defaults 1  2
/dev/mapper/fedora_localhost--live-swap        none   ext4  defaults 0  0

```

```
/dev/mapper/root_vg-root /            ext4    defaults   1 1
UUID=eea3d947-0618-4d8c-b083-87daf15b2679 /boot ext4  defaults  1 2
/dev/mapper/root_vg-swap none         swap    defaults      0 0

```

但是重启后，systemd 开始抛出`dracut-initqueue timeout`错误信息。

这些步骤看起来都被正确遵循了，但是我们需要进一步调查以了解为什么`dracut-initqueue`不能组装 LVM。

如果我们在错误屏幕上等待一段时间，如图 [7-53](#Fig53) 所示，systemd 将自动让我们进入紧急外壳。我们将在第 8 章[中详细了解 systemd 是如何让我们进入紧急状态的。](08.html)

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig53_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig53_HTML.jpg)

图 7-53

应急外壳

如图 [7-54](#Fig54) 所示，我们将扫描当前可用的 LVs，并将挂载`root vg`以验证其内容。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig54_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig54_HTML.jpg)

图 7-54

激活 LVs

如您所见，`root_vg`(重命名为`vg`)可用，我们也可以激活它。这显然意味着 LVM 元数据没有损坏，LVM 设备没有任何完整性问题。如图 [7-55](#Fig55) 所示，我们将`root_vg`挂载到一个临时目录，并从应急 shell 本身交叉验证其`fstab`条目。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig55_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig55_HTML.jpg)

图 7-55

挂载根文件系统

`vg`是完整的，`fstab`条目是正确的，我们能够挂载根`vg`。那还缺什么？

缺少的部分是 GRUB 中没有调整内核命令行参数。见图 [7-56](#Fig56) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig56_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig56_HTML.jpg)

图 7-56

内核命令行参数

为了启动，我们需要中断 GRUB 闪屏，并需要更改图 [7-57](#Fig57) 中所示的内核命令行参数。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig57_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig57_HTML.jpg)

图 7-57

旧的内核命令行参数

新的见图 [7-58](#Fig58) 。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig58_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig58_HTML.jpg)

图 7-58

新的内核命令行参数

系统启动后，将`/etc/default/grub`更改为:

```
# cat /etc/default/grub
GRUB_TIMEOUT=10
GRUB_DISTRIBUTOR="$(sed 's, release .*$,,g' /etc/system-release)"
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT="console"
GRUB_CMDLINE_LINUX="resume=/dev/mapper/fedora_localhost--live-swap rd.lvm.lv=fedora_localhost-live/root rd.lvm.lv=fedora_localhost-live/swap console=ttyS0,115200 console=tty0"
GRUB_DISABLE_RECOVERY="true"
GRUB_ENABLE_BLSCFG=true

```

致以下内容:

```
# cat /etc/default/grub
GRUB_TIMEOUT=10
GRUB_DISTRIBUTOR="$(sed 's, release .*$,,g' /etc/system-release)"
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT="console"
GRUB_CMDLINE_LINUX="resume=/dev/mapper/root_vg-swap rd.lvm.lv=root_vg/root rd.lvm.lv=root_vg/swap console=ttyS0,115200 console=tty0"
GRUB_DISABLE_RECOVERY="true"
GRUB_ENABLE_BLSCFG=true

```

由于 Fedora 使用来自`/boot/loader/entries`的 BLS 条目，因此没有必要更改`/etc/default/grub`文件。

由此改变`/boot/grub2/grubenv`:

```
# cat /boot/grub2/grubenv
saved_entry=2058a9f13f9e489dba29c477a8ae2493-5.3.7-301.fc31.x86_64
menu_auto_hide=1
boot_success=0
kernelopts=root=/dev/mapper/fedora_localhost--live-root ro resume=/dev/mapper/fedora_localhost--live-swap rd.lvm.lv=fedora_localhost-live/root rd.lvm.lv=fedora_localhost-live/swap console=ttyS0,115200 console=tty0
boot_indeterminate=9

```

致以下内容:

```
# cat /boot/grub2/grubenv
saved_entry=2058a9f13f9e489dba29c477a8ae2493-5.3.7-301.fc31.x86_64
menu_auto_hide=1
boot_success=0
kernelopts=root=/dev/root_vg/root ro resume=/dev/mapper/root_vg-swap rd.lvm.lv=root_vg/root rd.lvm.lv=root_vg/swap console=ttyS0,115200 console=tty0
boot_indeterminate=9

```

这修复了“无法启动”的问题。

### 普利茅斯

现在是时候谈谈一个叫做`plymouth`的有趣服务了。早期的 Linux 会直接在控制台上显示引导信息，这对于桌面用户来说有点无聊。于是，`plymouth`被引入，如下图所示:

```
# cat usr/lib/systemd/system/plymouth-start.service
[Unit]
Description=Show Plymouth Boot Screen
DefaultDependencies=no
Wants=systemd-ask-password-plymouth.path systemd-vconsole-setup.service
After=systemd-vconsole-setup.service systemd-udev-trigger.service systemd-udevd.service
Before=systemd-ask-password-plymouth.service
ConditionKernelCommandLine=!plymouth.enable=0
ConditionVirtualization=!container

[Service]
ExecStart=/usr/sbin/plymouthd --mode=boot --pid-file=/var/run/plymouth/pid --attach-to-session
ExecStartPost=-/usr/bin/plymouth show-splash
Type=forking
KillMode=none
SendSIGKILL=no

```

可以看到，从`/usr/lib/systemd/system/plymouth-start.service`单元文件中，`plymouth`紧接在`systemd-udev-trigger.service`之后，`dracut-initqueue.service`之前开始，如图 [7-59](#Fig59) 所示。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig59_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig59_HTML.jpg)

图 7-59

引导序列

如图 [7-60](#Fig60) 所示，`plymouth`将在整个启动过程中处于活动状态。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig60_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig60_HTML.jpg)

图 7-60

普利茅斯

`plymouth`是一个在启动时显示动画的工具。例如，在 Fedora 中，它不显示如图 [7-61](#Fig61) 所示的控制台消息。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig61_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig61_HTML.jpg)

图 7-61

当普利茅斯不可用时

`plymouth`向您展示如图 [7-62](#Fig62) 所示的动画。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig62_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig62_HTML.jpg)

图 7-62

普利茅斯银幕

#### 安装普利茅斯

如果你想安装不同主题的`plymouth`，那么你可以这样做:

1.  从 [`gnome-look.org`](http://gnome-look.org) 下载`plymouth-theme`，也可以使用以下:

1.  将下载的主题解压到以下位置:`/usr/share/plymouth/themes/`

```
# dnf install plymouth-theme*

```

1.  当`plymouth`从 initramfs 环境中运行时，您需要重新构建 initramfs。例如，必须为新的`plymouth`主题更新它的配置文件。

```
# ls -l /usr/share/plymouth/themes/
total 52
drwxr-xr-x. 2 root root 4096 Apr 26  2019 bgrt
drwxr-xr-x  3 root root 4096 Mar 30 09:15 breeze
drwxr-xr-x  2 root root 4096 Mar 30 09:15 breeze-text
drwxr-xr-x. 2 root root 4096 Mar 30 09:15 charge
drwxr-xr-x. 2 root root 4096 Apr 26  2019 details
drwxr-xr-x  2 root root 4096 Mar 30 09:15 fade-in
drwxr-xr-x  2 root root 4096 Mar 30 09:15 hot-dog
drwxr-xr-x  2 root root 4096 Mar 30 09:15 script
drwxr-xr-x  2 root root 4096 Mar 30 09:15 solar
drwxr-xr-x  2 root root 4096 Mar 30 09:15 spinfinity
drwxr-xr-x. 2 root root 4096 Apr 26  2019 spinner
drwxr-xr-x. 2 root root 4096 Apr 26  2019 text
drwxr-xr-x. 2 root root 4096 Apr 26  2019 tribar

```

```
# cat /etc/plymouth/plymouthd.conf
# Administrator customizations go in this file
#[Daemon]
#Theme=fade-in
[Daemon]
Theme=hot-dog

```

重启后，如图 [7-63](#Fig63) 所示，你会看到一个新的`plymouth`主题，名为`hot-dog`。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig63_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig63_HTML.jpg)

图 7-63

热狗普利茅斯主题

#### 管理普利茅斯

由于`plymouth`在早期启动，dracut 确实提供了一些命令行选项来管理`plymouth`的行为。

```
      plymouth.enable=0
           disable the plymouth bootsplash completely.

     rd.plymouth=0
           disable the plymouth bootsplash only for the initramfs.

```

之前显示的热狗图像被称为*启动画面* `.`要查看安装/选择的启动画面，您可以使用以下内容:

```
#plymouth --show-splash

```

`plymouth`的另一个主要动机是在一个简单的文本文件中维护所有的引导时消息，用户可以在引导后检查。日志将被存储在`/var/log/boot.log`，但是记住这个文件是由`plymouth`维护的。这意味着只有在启动`plymouth`后，您才能找到启动信息。但同时，我们需要记住，`plymouth`确实在 initramfs 的早期阶段就开始了(就在`udevd`开始之后)。

```
# less /varlog/boot.log
<snip>
------------ Sat Jul 06 01:43:12 IST 2019 ------------
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mShow Plymouth Boot ScreenESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mPathsESC[0m.
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mForward Password R...s to Plymouth Directory WatchESC[0m.
[ESC[0;32m  OK  ESC[0m] Found device ESC[0;1;39m/dev/mapper/fedora_localhost--live-rootESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mInitrd Root DeviceESC[0m.
[ESC[0;32m  OK  ESC[0m] Found device ESC[0;1;39m/dev/mapper/fedora_localhost--live-swapESC[0m.
         Starting ESC[0;1;39mResume from hiber...fedora_localhost--live-swapESC[0m...
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mResume from hibern...r/fedora_localhost--live-swapESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mLocal File Systems (Pre)ESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mLocal File SystemsESC[0m.
         Starting ESC[0;1;39mCreate Volatile Files and DirectoriesESC[0m...
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mCreate Volatile Files and DirectoriesESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mSystem InitializationESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mBasic SystemESC[0m.
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mdracut initqueue hookESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mRemote File Systems (Pre)ESC[0m.

[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mRemote File SystemsESC[0m.
         Starting ESC[0;1;39mFile System Check...fedora_localhost--live-rootESC[0m...
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mFile System Check ...r/fedora_localhost--live-rootESC[0m.
         Mounting ESC[0;1;39m/sysrootESC[0m...
[ESC[0;32m  OK  ESC[0m] Mounted ESC[0;1;39m/sysrootESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mInitrd Root File SystemESC[0m.
         Starting ESC[0;1;39mReload Configuration from the Real RootESC[0m...
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mReload Configuration from the Real RootESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mInitrd File SystemsESC[0m.
[ESC[0;32m  OK  ESC[0m] Reached target ESC[0;1;39mInitrd Default TargetESC[0m.
         Starting ESC[0;1;39mdracut pre-pivot and cleanup hookESC[0m...
[ESC[0;32m  OK  ESC[0m] Started ESC[0;1;39mdracut pre-pivot and cleanup hookESC[0m.
         Starting ESC[0;1;39mCleaning Up and Shutting Down DaemonsESC[0m...
[ESC[0;32m  OK  ESC[0m] Stopped target ESC[0;1;39mTimersESC[0m.
[ESC[0;32m  OK  ESC[0m] Stopped ESC[0;1;39mdracut pre-pivot and cleanup hookESC[0m.
[ESC[0;32m  OK  ESC[0m] Stopped target ESC[0;1;39mInitrd Default TargetESC[0m.
[ESC[0;32m  OK  ESC[0m] Stopped target ESC[0;1;39mRemote File SystemsESC[0m.
[ESC[0;32m  OK  ESC[0m] Stopped target ESC[0;1;39mRemote File Systems (Pre)ESC[0m.
[ESC[0;32m  OK  ESC[0m] Stopped ESC[0;1;39mdracut initqueue hookESC[0m.
         Starting ESC[0;1;39mPlymouth switch root serviceESC[0m...
[ESC[0;32m  OK  ESC[0m] Stopped target ESC[0;1;39mInitrd Root DeviceESC[0m.
[ESC[0;32m  OK  ESC[0m] Stopped target ESC[0;1;39mBasic SystemESC[0m.
[ESC[0;32m  OK  ESC[0m] Stopped target ESC[0;1;39mSystem InitializationESC[0m.
.
.
</snip>

```

#### 结构

`plymouth`从 initramfs/systemd 获取输入，以了解引导程序的哪个阶段已经完成(占引导程序的百分比),并相应地在屏幕上显示动画或进度条。有两个二进制文件负责`plymouth`的工作。

```
      /bin/plymouth            (Interface to plymouthd)
   /usr/sbin/plymouthd  (main binary which shows splash and logs boot messages in boot.log file)

```

systemd 所依赖的 initramfs 中提供了各种 plymouth 服务。

```
# ls -l usr/lib/systemd/system/ -l | grep -i plymouth

-rw-r--r--. 1 root root  384 Dec 21 12:19 plymouth-halt.service
-rw-r--r--. 1 root root  398 Dec 21 12:19 plymouth-kexec.service
-rw-r--r--. 1 root root  393 Dec 21 12:19 plymouth-poweroff.service
-rw-r--r--. 1 root root  198 Dec 21 12:19 plymouth-quit.service
-rw-r--r--. 1 root root  204 Dec 21 12:19 plymouth-quit-wait.service
-rw-r--r--. 1 root root  386 Dec 21 12:19 plymouth-reboot.service
-rw-r--r--. 1 root root  547 Dec 21 12:19 plymouth-start.service
-rw-r--r--. 1 root root  295 Dec 21 12:19 plymouth-switch-root.service
-rw-r--r--. 1 root root  454 Dec 21 12:19 systemd-ask-password-plymouth.path
-rw-r--r--. 1 root root  435 Dec 21 12:19 systemd-ask-password-plymouth.service
drwxr-xr-x. 2 root root 4096 Dec 21 12:19 systemd-ask-password-plymouth.service.wants

```

systemd 在 initramfs 中运行时，会在引导阶段不时调用这些服务。如您所见，每个服务都在调用`plymouthd`二进制文件，并根据当前的引导阶段传递开关。例如，`plymouth-start.service`简单的用模式`boot.`启动`plymouthd`二进制只有两种模式；一个是`boot`，另一个是`shutdown.`

```
# cat usr/lib/systemd/system/plymouth*  | grep -i execstart

ExecStart=/usr/sbin/plymouthd --mode=shutdown --attach-to-session
ExecStartPost=-/usr/bin/plymouth show-splash
ExecStart=/usr/sbin/plymouthd --mode=shutdown --attach-to-session
ExecStartPost=-/usr/bin/plymouth show-splash
ExecStart=/usr/sbin/plymouthd --mode=shutdown --attach-to-session
ExecStartPost=-/usr/bin/plymouth show-splash
ExecStart=-/usr/bin/plymouth quit                                    <<---
ExecStart=-/usr/bin/plymouth --wait
ExecStart=/usr/sbin/plymouthd --mode=reboot --attach-to-session
ExecStartPost=-/usr/bin/plymouth show-splash
ExecStart=/usr/sbin/plymouthd --mode=boot --pid-file=/var/run/plymouth/pid --attach-to-session
ExecStartPost=-/usr/bin/plymouth show-splash
ExecStart=-/usr/bin/plymouth update-root-fs --new-root-dir=/sysroot   <<---

```

我们可以考虑的另一个例子是，在`switch_root`时，systemd 简单地调用`plymouth-switch-root.service`，后者又运行带有更新的`root`文件系统的`plymouthd`二进制文件作为`sysroot.`，换句话说`,`你可以和`switch_root`一起说`plymouth`将其根目录从 initramfs 更改为实际的根文件系统。更进一步，您可以看到 systemd 启动`plymouth`服务的方式与 systemd 在引导序列结束时向`plymouthd`发送`quit`消息的方式相同。同时，您可能注意到 systemd 在重启或关机时也会调用`plymouth`。这其实没什么大不了的，因为它只是用适当的模式调用同一个`plymouthd`。

### Sysinit.target

所以，我们已经到了`sysinit.target`阶段。图 [7-64](#Fig64) 显示了到目前为止我们已经介绍过的引导顺序。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig64_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig64_HTML.jpg)

图 7-64

到目前为止介绍的引导顺序

因为这是一个`target`单元，它的工作是持有或启动一堆其他单元(服务、套接字等)。).单位列表将在其`wants`目录中提供。正如您所看到的，可用的单元文件只是到原始服务单元文件的符号链接。

```
#ls -l usr/lib/systemd/system/sysinit.target.wants/

total 0
kmod-static-nodes.service -> ../kmod-static-nodes.service
plymouth-start.service -> ../plymouth-start.service
systemd-ask-password-console.path -> ../systemd-ask-password-console.path
systemd-journald.service -> ../systemd-journald.service
systemd-modules-load.service -> ../systemd-modules-load.service
systemd-sysctl.service -> ../systemd-sysctl.service
systemd-tmpfiles-setup-dev.service -> ../systemd-tmpfiles-setup-dev.service
systemd-tmpfiles-setup.service -> ../systemd-tmpfiles-setup.service
systemd-udevd.service -> ../systemd-udevd.service
systemd-udev-trigger.service -> ../systemd-udev-trigger.service

```

大多数服务在我们到达`sysinit.target.`之前就已经启动了，例如`systemd-udevd.service`和`systemd-udev-trigger.service`(在`pre-trigger`服务之后)已经启动了，我们已经看到`systemd -udevd.service`将执行`/usr/lib/systemd/systemd-udevd`二进制，而`systemd-udev-trigger`服务将执行`udevadm`二进制。那我们为什么要用`sysinit.target`重新启动这些服务呢？我们没有。`sysinit.target`将仅启动尚未启动的服务，并且将忽略对已经启动的服务采取的任何操作。让我们看看这些服务单元文件的用途。

`kmod-static-nodes` systemd 单元文件用`static-nodes`开关执行`kmod`二进制。我们已经在第 [5](05.html) 章看到了`lsmod`、`insmod`、`modinfo`、`modprobe`、`depmod`等。，是指向`kmod`二进制文件的符号链接。

```
#lsinitrd | grep -i kmod

lrwxrwxrwx   1 root  root  11 Jul 25 03:54 usr/sbin/depmod -> ../bin/kmod
lrwxrwxrwx   1 root  root  11 Jul 25 03:54 usr/sbin/insmod -> ../bin/kmod
lrwxrwxrwx   1 root  root  11 Jul 25 03:54 usr/sbin/lsmod -> ../bin/kmod
lrwxrwxrwx   1 root  root  11 Jul 25 03:54 usr/sbin/modinfo -> ../bin/kmod
lrwxrwxrwx   1 root  root  11 Jul 25 03:54 usr/sbin/modprobe -> ../bin/kmod
lrwxrwxrwx   1 root  root  11 Jul 25 03:54 usr/sbin/rmmod -> ../bin/kmod

# cat usr/lib/systemd/system/kmod-static-nodes.service | grep -v '#'
[Unit]
Description=Create list of static device nodes for the current kernel
DefaultDependencies=no
Before=sysinit.target systemd-tmpfiles-setup-dev.service
ConditionCapability=CAP_SYS_MODULE
ConditionFileNotEmpty=/lib/modules/%v/modules.devname

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/bin/kmod static-nodes --format=tmpfiles --output=/run/tmpfiles.d/static-nodes.conf

```

使用`static-nodes`开关，systemd 只是收集系统中存在的所有静态节点(设备)。为什么在动态节点处理(`udev`)的时代我们还需要静态节点？有一些像`fuse`或`ALSA`这样的模块需要一些存在于`/dev`中的设备文件，或者他们可以创建它们。但是这可能是危险的，因为设备文件是由`kernel`或`udev`生成的。因此，为了避免模块创建设备文件，systemd 将通过`kmod-static-nodes.service.`创建类似`/dev/fuse`或`/dev/snd/seq`的静态节点。以下是由`kmod-static-nodes.service`在 Fedora 系统上创建的静态节点:

```
# kmod static-nodes
Module: fuse
      Device node: /dev/fuse
            Type: character device
            Major: 10
            Minor: 229
Module: btrfs
      Device node: /dev/btrfs-control
            Type: character device
            Major: 10
            Minor: 234
Module: loop
      Device node: /dev/loop-control
            Type: character device
            Major: 10
            Minor: 237
Module: tun
      Device node: /dev/net/tun
            Type: character device
            Major: 10
            Minor: 200
Module: ppp_generic
      Device node: /dev/ppp
            Type: character device
            Major: 108
            Minor: 0
Module: uinput
      Device node: /dev/uinput

            Type: character device
            Major: 10
            Minor: 223
Module: uhid
      Device node: /dev/uhid
            Type: character device
            Major: 10
            Minor: 239
Module: vfio
      Device node: /dev/vfio/vfio
            Type: character device
            Major: 10
            Minor: 196
Module: hci_vhci
      Device node: /dev/vhci
            Type: character device
            Major: 10
            Minor: 137
Module: vhost_net
      Device node: /dev/vhost-net
            Type: character device
            Major: 10
            Minor: 238
Module: vhost_vsock
      Device node: /dev/vhost-vsock
            Type: character device
            Major: 10
            Minor: 241
Module: snd_timer
      Device node: /dev/snd/timer
            Type: character device
            Major: 116
            Minor: 33
Module: snd_seq
      Device node: /dev/snd/seq
            Type: character device
            Major: 116
            Minor: 1
Module: cuse
      Device node: /dev/cuse
            Type: character device
            Major: 10
            Minor: 203

```

接下来我们有`plymouth`服务，已经开始了；然后我们有`systemd-ask-password-console.path`，这是一个`.path`的单位档案。

```
# cat usr/lib/systemd/system/systemd-ask-password-console.path | grep -v '#'

[Unit]
Description=Dispatch Password Requests to Console Directory Watch
Documentation=man:systemd-ask-password-console.service(8)
DefaultDependencies=no
Conflicts=shutdown.target emergency.service
After=plymouth-start.service
Before=paths.target shutdown.target cryptsetup.target
ConditionPathExists=!/run/plymouth/pid

[Path]
DirectoryNotEmpty=/run/systemd/ask-password
MakeDirectory=yes

```

`.path`单元文件用于基于路径的激活，但是因为我们没有用 LUKS 加密我们的根磁盘，所以我们没有接受用户密码的实际服务文件。如果我们配置了 LUKS，我们就会有`/usr/lib/systemd/system/systemd-ask-password-plymouth.service`服务单元文件，如下所示:

```
# cat usr/lib/systemd/system/systemd-ask-password-plymouth.service
[Unit]
Description=Forward Password Requests to Plymouth
Documentation=http://www.freedesktop.org/wiki/Software/systemd/PasswordAgents
DefaultDependencies=no
Conflicts=shutdown.target
After=plymouth-start.service
Before=shutdown.target
ConditionKernelCommandLine=!plymouth.enable=0
ConditionVirtualization=!container
ConditionPathExists=/run/plymouth/pid

[Service]
ExecStart=/usr/bin/systemd-tty-ask-password-agent --watch --plymouth

```

如您所见，这是在执行`systemd-tty-ask-password-agent`二进制文件，它将要求输入带有`plymouth`而不是 TTY 的密码。接下来，服务单元文件是`systemd-journald.service`，它将为我们启动`journald`守护进程。在此之前，所有的消息都是用`journald`套接字记录的，systemd 将这个套接字作为引导序列的第一个服务启动。`journald`插座大小为 8 MB。如果套接字用完了缓冲区，那么服务将被阻塞，直到套接字变得可用。8 MB 的缓冲空间对于生产系统来说绰绰有余。

```
#vim usr/lib/systemd/system/sysinit.target.wants/systemd-journald.service
[Unit]
Description=Journal Service
Documentation=man:systemd-journald.service(8) man:journald.conf(5)
DefaultDependencies=no
Requires=systemd-journald.socket
After=systemd-journald.socket systemd-journald-dev-log.socket systemd-journald-audit.socket syslog.socket
Before=sysinit.target

[Service]
OOMScoreAdjust=-250
CapabilityBoundingSet=CAP_SYS_ADMIN CAP_DAC_OVERRIDE CAP_SYS_PTRACE CAP_SYSLOG CAP_AUDIT_CONTROL CAP_AUDIT_READ CAP_CHOWN CAP_DAC_READ_SEARCH CAP_FOWNER CAP_SETUID CAP_SETGID CAP_MAC_OVERRIDE
DeviceAllow=char-* rw
ExecStart=/usr/lib/systemd/systemd-journald
FileDescriptorStoreMax=4224
IPAddressDeny=any
LockPersonality=yes
MemoryDenyWriteExecute=yes
Restart=always
RestartSec=0
RestrictAddressFamilies=AF_UNIX AF_NETLINK

RestrictNamespaces=yes
RestrictRealtime=yes
RestrictSUIDSGID=yes
Sockets=systemd-journald.socket systemd-journald-dev-log.socket systemd-journald-audit.socket
StandardOutput=null
SystemCallArchitectures=native
SystemCallErrorNumber=EPERM
SystemCallFilter=@system-service
Type=notify
WatchdogSec=3min

LimitNOFILE=524288

```

接下来，如果你想让 systemd 静态加载某个特定的模块，那么你可以从我们的下一个服务得到一些帮助，这个服务就是`systemd-modules-load.service`。

```
# cat usr/lib/systemd/system/systemd-modules-load.service | grep -v '#'

[Unit]
Description=Load Kernel Modules
Documentation=man:systemd-modules-load.service(8) man:modules-load.d(5)
DefaultDependencies=no
Conflicts=shutdown.target
Before=sysinit.target shutdown.target
ConditionCapability=CAP_SYS_MODULE
ConditionDirectoryNotEmpty=|/lib/modules-load.d
ConditionDirectoryNotEmpty=|/usr/lib/modules-load.d
ConditionDirectoryNotEmpty=|/usr/local/lib/modules-load.d
ConditionDirectoryNotEmpty=|/etc/modules-load.d
ConditionDirectoryNotEmpty=|/run/modules-load.d
ConditionKernelCommandLine=|modules-load
ConditionKernelCommandLine=|rd.modules-load

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/lib/systemd/systemd-modules-load
TimeoutSec=90s

```

服务执行`/usr/lib/systemd/systemd-modules-load` `.`二进制理解两个命令行参数。

*   `module_load`:这是一个内核命令行参数。

*   `rd.module_load`:这是一个 dracut 命令行参数。

如果您传递一个 dracut 命令行参数，那么`systemd-modules-load`将统计地将模块加载到内存中，但是为此，模块必须存在于 initramfs 中。如果它不在 initramfs 中，那么首先必须将其拉入 initramfs。在生成 initramfs 时，dracut 从这里读取`<module-name>.conf`文件:

```
/etc/modules-load.d/*.conf
/run/modules-load.d/*.conf
/usr/lib/modules-load.d/*.conf

```

您需要创建`*.conf`文件，并且需要在其中提到模块名，这是您想要添加到 initramfs 中的。

例如，这里我们创建了一个新的 initramfs 映像，其中没有`vfio`模块:

```
# dracut new.img
# lsinitrd | grep -i vfio
  <no_output>

```

为了在 initramfs 中以统计方式提取模块，我们在这里创建了`vfio.conf`文件:

```
# cat /usr/lib/modules-load.d/vfio.conf
  vfio

```

在这里，我们重建了 initramfs:

```
# dracut new.img -f
# lsinitrd new.img | grep -i vfio

Jul 25 03:54 usr/lib/modules/5.3.16-300.fc31.x86_64/kernel/drivers/vfio
Jul 25 03:54 usr/lib/modules/5.3.16-300.fc31.x86_64/kernel/drivers/vfio/vfio.ko.xz
Jul 25 03:54 usr/lib/modules-load.d/vfio.conf

```

如您所见，该模块已经被拉入 initramfs 中，一旦服务`systemd-modules-load.service`启动，它就会被加载到内存中。

以统计方式加载模块并不是一个好主意。如今，模块在必要或要求时被动态加载到内存中，而静态模块总是被加载到内存中，而不管需要或要求如何。

不要和`/etc/modprobe.d`目录混淆。它的用途是将选项传递给模块。这里有一个例子:

```
#cat /etc/modprobe.d/lockd.conf
     options lockd nlm_timeout=10

```

`nlm_timeour=10`是传递给`lockd`模块的选项。记住，`/etc/modprobe.d`中的`.conf`文件必须是一个模块名。通过同一个 conf 文件，您可以为模块名设置一个别名。这里有一个例子:

```
"alias my-mod really_long_modulename"

```

接下来，systemd 会在`systemd-sysctl.service`的帮助下设置`sysctl`内核参数。

```
# cat usr/lib/systemd/system/systemd-sysctl.service | grep -v '#'

[Unit]
Description=Apply Kernel Variables
Documentation=man:systemd-sysctl.service(8) man:sysctl.d(5)
DefaultDependencies=no
Conflicts=shutdown.target
After=systemd-modules-load.service
Before=sysinit.target shutdown.target
ConditionPathIsReadWrite=/proc/sys/net/

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/lib/systemd/systemd-sysctl
TimeoutSec=90s

```

`systemd-sysctl.service`将启动`/usr/lib/systemd/systemd-sysctl`二进制文件，它将通过从三个不同的位置读取`*.conf`文件来设置内核调优参数。

```
/etc/sysctl.d/*.conf
     /run/sysctl.d/*.conf
     /usr/lib/sysctl.d/*.conf

```

这里有一个例子:

```
# sysctl -a | grep -i swappiness
      vm.swappiness = 60

```

默认的`swappiness`内核参数值设置为 60。如果您想将其更改为 10，并且它必须在重启后保持不变，那么在`/etc/sysctl.d/99-sysctl.conf`中添加它。

```
#cat /etc/sysctl.d/99-sysctl.conf

     vm.swappiness = 10

```

您可以使用以下命令重新加载和设置`sysctl`参数:

```
# sysctl -p
vm.swappiness = 10

```

要在 initramfs 中进行这些更改，您需要重新生成 initramfs。在引导时，`systemd-sysctl.service`将从`99-sysctl.conf`文件中读取`swappiness`值，并将它设置在 initramfs 环境中。

systemd 为其顺利执行创建了许多临时文件。设置好`sysctl`参数后，它执行下一个服务`systemd-tmpfiles-setup-dev.service`，这个服务将执行`/usr/bin/systemd-tmpfiles --prefix=/dev --create --boot`二进制文件。这将根据以下规则创建`dev`与文件系统相关的临时文件:

```
/etc/tmpfiles.d/*.conf
/run/tmpfiles.d/*.conf
/usr/lib/tmpfiles.d/*.conf

```

在`sysinit.target`之后，systemd 将通过`sockets.target`验证是否创建了所需的套接字。

```
# ls usr/lib/systemd/system/sockets.target.wants/ -l
total 0
32 Jan  3 18:05 systemd-journald-audit.socket -> ../systemd-journald-audit.socket
34 Jan  3 18:05 systemd-journald-dev-log.socket -> ../systemd-journald-dev-log.socket
26 Jan  3 18:05 systemd-journald.socket -> ../systemd-journald.socket
31 Jan  3 18:05 systemd-udevd-control.socket -> ../systemd-udevd-control.socket
30 Jan  3 18:05 systemd-udevd-kernel.socket -> ../systemd-udevd-kernel.socket

```

因此，我们的引导过程已经完成了到`sysinit.target.`的序列，参见图 [7-65](#Fig65) 所示的流程图。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig65_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig65_HTML.jpg)

图 7-65

到目前为止介绍的引导顺序

#### “无法启动”问题 8 (sysctl.conf)

**问题:**重启后，内核死机，系统无法启动。控制台上显示的内容如下:

```
[    4.596220] Mem-Info:
[    4.597455] active_anon:566 inactive_anon:1 isolated_anon:0
[    4.597455]  active_file:0 inactive_file:0 isolated_file:0
[    4.597455]  unevictable:19700 dirty:0 writeback:0 unstable:0
[    4.597455]  slab_reclaimable:2978 slab_unreclaimable:3180
[    4.597455]  mapped:2270 shmem:22 pagetables:42 bounce:0
[    4.597455]  free:23562 free_pcp:1982 free_cma:0
[    4.611930] Node 0 active_anon:2264kB inactive_anon:4kB active_file:0kB inactive_file:0kB unevictable:78800kB isolated(anon):0kB isolated(file):0kB mapped:9080kB dirty:0kB writeback:0kB shmem:88kB shmem_thp: 0kB shmem_pmdmapped: 0kB anon_thp: 0kB writeback_tmp:0kB unstable:0kB all_unreclaimable? yes
[    4.621748] Node 0 DMA free:15900kB min:216kB low:268kB high:320kB active_anon:0kB inactive_anon:0kB active_file:0kB inactive_file:0kB unevictable:0kB writepending:0kB present:15992kB managed:15908kB mlocked:0kB kernel_stack:0kB pagetables:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB
[    4.632561] lowmem_reserve[]: 0 1938 4764 4764 4764
[    4.634609] Node 0 DMA32 free:38516kB min:27404kB low:34252kB high:41100kB active_anon:0kB inactive_anon:0kB active_file:0kB inactive_file:0kB unevictable:0kB writepending:0kB present:2080628kB managed:2015092kB mlocked:0kB kernel_stack:0kB pagetables:0kB bounce:0kB free_pcp:2304kB local_pcp:0kB free_cma:0kB
[    4.645636] lowmem_reserve[]: 0 0 2826 2826 2826
[    4.647886] Node 0 Normal free:39832kB min:39956kB low:49944kB high:59932kB active_anon:2264kB inactive_anon:4kB active_file:0kB inactive_file:0kB unevictable:78800kB writepending:0kB present:3022848kB managed:2901924kB mlocked:0kB kernel_stack:1776kB pagetables:168kB bounce:0kB free_pcp:5624kB local_pcp:1444kB free_cma:0kB
[    4.659458] lowmem_reserve[]: 0 0 0 0 0
[    4.661319] Node 0 DMA: 1*4kB (U) 1*8kB (U) 1*16kB (U) 0*32kB 2*64kB (U) 1*128kB (U) 1*256kB (U) 0*512kB 1*1024kB (U) 1*2048kB (M) 3*4096kB (M) = 15900kB
[    4.666730] Node 0 DMA32: 1*4kB (M) 0*8kB 1*16kB (M) 1*32kB (M) 1*64kB (M) 0*128kB 0*256kB 1*512kB (M) 3*1024kB (M) 1*2048kB (M) 8*4096kB (M) = 38516kB
[    4.673247] Node 0 Normal: 69*4kB (UME) 16*8kB (M) 10*16kB (UME) 7*32kB (ME) 5*64kB (E) 1*128kB (E) 1*256kB (U) 9*512kB (ME) 9*1024kB (UME) 2*2048kB (ME) 5*4096kB (M) = 39892kB
[    4.680399] Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=1048576kB
[    4.683930] Node 0 hugepages_total=2303 hugepages_free=2303 hugepages_surp=0 hugepages_size=2048kB
[    4.687749] 19722 total pagecache pages
[    4.689841] 0 pages in swap cache
[    4.691580] Swap cache stats: add 0, delete 0, find 0/0
[    4.694275] Free swap  = 0kB
[    4.696039] Total swap = 0kB
[    4.697617] 1279867 pages RAM
[    4.699229] 0 pages HighMem/MovableOnly
[    4.700862] 46636 pages reserved
[    4.703868] 0 pages cma reserved
[    4.705589] 0 pages hwpoisoned
[    4.707435] Tasks state (memory values in pages):
[    4.709532] [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
[    4.713849] [    341]     0   341     5118     1178    77824        0         -1000 (md-udevd)
[    4.717805] Out of memory and no killable processes...
[    4.719861] Kernel panic - not syncing: System is deadlocked on memory
[    4.721926] CPU: 3 PID: 1 Comm: systemd Not tainted 5.3.7-301.fc31.x86_64 #1
[    4.724343] Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 1.12.0-2.fc30 04/01/2014
[    4.727959] Call Trace:
[    4.729204]  dump_stack+0x5c/0x80
[    4.730707]  panic+0x101/0x2d7
[    4.747357]  out_of_memory.cold+0x2f/0x88
[    4.749172]  __alloc_pages_slowpath+0xb09/0xe00
[    4.750890]  __alloc_pages_nodemask+0x2ee/0x340
[    4.752452]  alloc_slab_page+0x19f/0x320
[    4.753982]  new_slab+0x44f/0x4d0
[    4.755317]  ? alloc_slab_page+0x194/0x320
[    4.757016]  ___slab_alloc+0x507/0x6a0
[    4.758768]  ? copy_verifier_state+0x1f7/0x270
[    4.760591]  ? ___slab_alloc+0x507/0x6a0
[    4.763266]  __slab_alloc+0x1c/0x30
[    4.764846]  kmem_cache_alloc_trace+0x1ee/0x220
[    4.766418]  ? copy_verifier_state+0x1f7/0x270
[    4.768120]  copy_verifier_state+0x1f7/0x270
[    4.769604]  ? kmem_cache_alloc_trace+0x162/0x220
[    4.771098]  ? push_stack+0x35/0xe0
[    4.772367]  push_stack+0x66/0xe0
[    4.774010]  check_cond_jmp_op+0x1fe/0xe60
[    4.775644]  ? _cond_resched+0x15/0x30
[    4.777524]  ? _cond_resched+0x15/0x30
[    4.779315]  ? kmem_cache_alloc_trace+0x162/0x220
[    4.780916]  ? copy_verifier_state+0x1f7/0x270
[    4.782357]  ? copy_verifier_state+0x16f/0x270
[    4.783785]  do_check+0x1c06/0x24e0
[    4.785218]  bpf_check+0x1aec/0x24d4
[    4.786613]  ? _cond_resched+0x15/0x30
[    4.788073]  ? kmem_cache_alloc_trace+0x162/0x220
[    4.789672]  ? selinux_bpf_prog_alloc+0x1f/0x60
[    4.791564]  bpf_prog_load+0x3a3/0x670
[    4.794915]  ? seq_vprintf+0x30/0x50
[    4.797085]  ? seq_printf+0x53/0x70
[    4.799013]  __do_sys_bpf+0x7e5/0x17d0
[    4.800909]  ? __fput+0x168/0x250
[    4.802352]  do_syscall_64+0x5f/0x1a0
[    4.803826]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
[    4.805587] RIP: 0033:0x7f471557915d
[    4.807638] Code: 00 c3 66 2e 0f 1f 84 00 00 00 00 00 90 f3 0f 1e fa 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d fb 5c 0c 00 f7 d8 64 89 01 48
[    4.814732] RSP: 002b:00007fffd36da028 EFLAGS: 00000246 ORIG_RAX: 0000000000000141
[    4.818390] RAX: ffffffffffffffda RBX: 000055fb6ad3add0 RCX: 00007f471557915d
[    4.820448] RDX: 0000000000000070 RSI: 00007fffd36da030 RDI: 0000000000000005
[    4.822536] RBP: 0000000000000002 R08: 0070756f7267632f R09: 000001130000000f
[    4.826605] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000000
[    4.829312] R13: 0000000000000006 R14: 000055fb6ad3add0 R15: 00007fffd36da1e0
[    4.831792] Kernel Offset: 0x26000000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)
[    4.835316] ---[ end Kernel panic - not syncing: System is deadlocked on memory ]---

```

所以，这是一个“内核恐慌”问题。我们需要首先隔离问题，因为内核崩溃可能是由成千上万种情况引起的。如果您查看突出显示的内核崩溃消息，很明显，由于系统内存不足，已经调用了“OOM-killer”。内核试图从缓存中释放内存，甚至试图使用交换空间，但最终放弃了，内核慌了。

所以，我们已经隔离了这个问题。我们需要专注于谁在吞噬记忆。当系统有巨大的内存压力时，操作系统内存不足(OOM)机制将被调用。

在三种情况下，OOM-killer 会在引导过程中被调用:

*   系统安装的物理内存非常低。

*   设置了错误的内核调整参数。

*   一些模块有内存泄漏。

这个系统有 4.9 GB 的物理内存，不算大，但是对于 Linux 内核完成引导序列来说肯定绰绰有余。

一些模块可能有内存泄漏，但是识别这一点将是一项困难的任务。因此，我们将首先验证是否有任何与内存相关的内核调优参数设置不正确。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig67_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig67_HTML.jpg)

图 7-67

禁用 hugepage 设置

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig66_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig66_HTML.jpg)

图 7-66

内核命令行参数

1.  为此，我们将把自己放在 initramfs 中。在图 [7-66](#Fig66) 中，我们已经将`rd.break`作为内核命令行参数进行了传递。

2.  我们将在读写模式下重新挂载`sysroot`，并验证`sysctl`参数。

    ```
    switch_root:/# cat /proc/sys/vm/nr_hugepages
                   2400

    ```

3.  问题是错误地保留了大量页面。我们将根据图 [7-67](#Fig67) 禁用该设置。

重新启动后，系统能够成功引导。让我们试着理解哪里出了问题。这个系统有 4.9 GB 的内存，早期没有保留大页面。

```
# cat /proc/meminfo | grep -e MemTotal -e HugePages_Total

MemTotal:        4932916 kB
HugePages_Total:       0

# cat /proc/sys/vm/nr_hugepages
0

```

普通页面的大小是 4 KB，而大页面的大小是 2 MB，是普通页面的 512 倍。大型网页有它自己的优点，但同时也有它自己的缺点。

*   一个大页面不能被换出。

*   内核不使用大页面。

*   只有支持大页面的应用程序才能使用大页面。

有人错误地设置了 2400 个页面，并重新构建了 initramfs。

```
# echo "vm.nr_hugepages = 2400" >> /etc/sysctl.conf

     # sysctl -p
           vm.nr_hugepages = 2400

     # dracut /boot/new.img
     # reboot

```

因此，2，400 个 hugepages = 4.9 GB，这是所有安装的主内存，由于总内存被保留在 hugepages 中，内核无法使用它。因此，在引导时，当 systemd 到达阶段`sysinit.target`并执行`systemd-sysctl.service`时，服务从 initramfs 中读取`sysctl.conf`文件，并保留 4.9 GB 的 hugepages，这是内核无法使用的。所以内核本身就内存不足，系统就慌了。

### 基本目标

所以，我们到了`basic.target`。正如我们所知，目标是为了同步或分组单元。`basic.target`是后期引导服务的同步点。

```
# cat usr/lib/systemd/system/basic.target | grep -v '#'
[Unit]
Description=Basic System
Documentation=man:systemd.special(7)
Requires=sysinit.target
Wants=sockets.target timers.target paths.target slices.target
After=sysinit.target sockets.target paths.target slices.target tmp.mount

RequiresMountsFor=/var /var/tmp
Wants=tmp.mount

```

因此，当所有早期服务的单元文件`requires`、`wants`和`after`阶段成功启动时，`basic.target`将会成功。事实上，几乎所有的军种都在其单位档案中添加了`After=basic.target`。

### dracut-预安装服务

systemd 将在 initramfs 中挂载用户的根文件系统之前执行`dracut-pre-mount.service`服务。因为它是一个 dracut 服务，所以只有当用户传递了`rd.break=pre-mount` dracut 命令行参数时，它才会执行。图 [7-68](#Fig68) 显示我们已经将`rd.break=pre-mount`作为内核命令行参数传递。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig68_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig68_HTML.jpg)

图 7-68

内核命令行参数

正如你在图 [7-69](#Fig69) 中看到的，它把我们放在了紧急 shell 中，并且用户的根文件系统没有挂载在`sysroot.`是的，我说它把我们放在了紧急 shell 中，但是你会惊讶地看到，紧急 shell 只不过是 systemd 提供的一个简单的 bash shell，但是在引导还没有完成的时候。为了更好地理解紧急 shell，我们将暂停我们的引导序列一会儿，并在第 [8](08.html) 章中讨论 initramfs 的调试 shell。我们将在第 [9](09.html) 章继续暂停的 systemd 引导序列。

![../images/493794_1_En_7_Chapter/493794_1_En_7_Fig69_HTML.jpg](../images/493794_1_En_7_Chapter/493794_1_En_7_Fig69_HTML.jpg)

图 7-69

预安装钩